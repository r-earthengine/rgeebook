[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"official website book Earth Engine R. book \nintended R users wish learn use R Google Earth Engine workflow. full overview GEE API functionality, multiple real-world applications, detailed description\nrgee rgeeExtra features. majority\nexamples directly adapted original Earth Engine documentation rebuilt R.find book useful, please support :Starring rgee, rgeeExtra, rgeebook GitHub repositories.Communicating book digital media, e.g., via Twitter.Asking questions , making suggestions, even better, proposing PR Github.\nbook written Junior Calvo, Fernando Herrera, Karen Gonzales, Joselyn Inga Cesar Aybar. gratefully acknowledge financial support \n","code":""},{"path":"index.html","id":"license","chapter":"Welcome","heading":"License","text":"work licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.","code":""},{"path":"index.html","id":"other-books","chapter":"Welcome","heading":"Other books","text":"may also interested :“Advanced R” Hadley Wickham, provides profound\ndescription R syntax. book uses template.“Advanced R” Hadley Wickham, provides profound\ndescription R syntax. book uses template.“Geocomputation R” Robin Lovelace, Jakub Nowosad, Jannes Muenchow, introduces R manipulating visualizing geographic data.“Geocomputation R” Robin Lovelace, Jakub Nowosad, Jannes Muenchow, introduces R manipulating visualizing geographic data.“Spatial Data Science” Edzer Pebesma Roger Bivand, another excellent great resource geographic data focused analysis.“Spatial Data Science” Edzer Pebesma Roger Bivand, another excellent great resource geographic data focused analysis.“R Data Science” Hadley Wickham Garrett Grolemund, introduces R data science tool, particular emphasis tidyverse package.“R Data Science” Hadley Wickham Garrett Grolemund, introduces R data science tool, particular emphasis tidyverse package.","code":""},{"path":"earthengine-examples.html","id":"earthengine-examples","chapter":"earthengine-examples","heading":"earthengine-examples","text":"Many excellent articles examples use Earth Engine API can found internet. Many examples, however, written different programming languages, R, Julia, Javascript, Python. face issue, earthengine-examples created aim collect examples one place. website counts multi-programming language support. want contribute project, please see contributing guide.\n\nGo earthengine-examples\n\n","code":""},{"path":"rgee-cheatsheet.html","id":"rgee-cheatsheet","chapter":"rgee-cheatsheet","heading":"rgee-cheatsheet","text":"last time couldn’t remember specific GEE API method name?. understand! occurs us often, lose valuable time deviating official documentation. prevent happening, create rgee-cheatsheet important rgee GEE features always keep mind. want contribute, open issue official repository.","code":""},{"path":"rgee-cheatsheet.html","id":"preview-the-first-part","chapter":"rgee-cheatsheet","heading":"Preview the first part","text":"\n","code":""},{"path":"rgee-cheatsheet.html","id":"preview-the-second-part","chapter":"rgee-cheatsheet","heading":"Preview the second part","text":"\n\n\nrgee cheatsheet PDF\n\n","code":""},{"path":"overview.html","id":"overview","chapter":"Overview","heading":"Overview","text":"","code":""},{"path":"overview.html","id":"what-is-google-earth-engine","chapter":"Overview","heading":"What is Google Earth Engine?","text":"Google Earth Engine (GEE) cloud-based platform helps access high-performance computing resources processing analyzing large geospatial datasets (Golerick et al.,2017). moment, GEE supports client libraries JavaScript Python programming languages. Check official GitHub repository details: https://github.com/google/earthengine-api.client library: Sometimes known helper library, collection code help communicate effectively API. example, want invoke certain image asset GEE, must type following:However, using GEE client library, code reduced one line code!","code":"# Connecting to GEE server via POST request.\n{\n   \"functionInvocationValue\": {\n      \"functionName\": \"Image.load\",\n      \"arguments\": {\n         \"id\": {\n            \"constantValue\": \"USGS/SRTMGL1_003\"\n         }\n      }\n   }\n}\n# Connecting to GEE server via client library + web API.\nee$Image(\"USGS/SRTMGL1_003\")"},{"path":"overview.html","id":"what-is-rgee","chapter":"Overview","heading":"What is rgee?","text":"rgee simplest way using GEE within R. Using reticulate back-end, rgee connects R Python.\nTherefore, may think rgee nested wrapper. One wrapper connect R Python Earth Engine API,\nconnects Python Web REST API (see figure ).Earth Engine request created R, reticulate translate R code Python send Earth Engine Python client library, converts Python code JSON format. , GEE Platform receives JSON request Web REST API. response takes path , reverse.","code":""},{"path":"overview.html","id":"rgee-guides","chapter":"Overview","heading":"rgee Guides","text":"guides written R Rstudio. R Quickstart guide tutorials describe basic concepts example workflows help beginning users. guides several examples rgee rgeeExtra.Best Practices Debugging guides complex examples provide techniques useful overcoming errors scaling Earth Engine analyses larger areas, longer time series data. advanced Earth Engine concepts provide necessary background understanding Earth Engine service works writing effective code.remainder guides intended illustrate important concepts data types :Image, fundamental raster data type Earth Engine.ImageCollection, stack time-series images.Geometry, fundamental vector data type Earth Engine.Feature, Geometry attributes.FeatureCollection, set features.Reducer, object used compute statistics perform aggregations.Join, combine datasets (Image Feature collections) based time, location, attribute property.Array, multi-dimensional analyses.also sections machine learning, specialized sensor specific algorithms (e.g. Landsat algorithms), Rstudio addins, shinyapps.io apps, data (asset) management.","code":""},{"path":"rgeeextra.html","id":"rgeeextra","chapter":"rgeeExtra","heading":"rgeeExtra","text":"rgeeExtra R package extends following Earth Engine classes:ee$Featureee$FeatureCollectionee$Geometryee$Imageee$ImageCollectionee$Listee$NumberNew utility methods constructors added -mentioned classes order create fluid code friendly R pipe chaining. methods mandatory pre-processing processing tasks (e.g. clouds masking, shadows masking, image scaling, spectral indices computation, etc.), presented simple functions give researchers, students analysts chance analyze data far fewer lines code.Look simple example Sentinel-2 Surface Reflectance Image Collection pre-processed processed just one step:Let’s see main features eemont simple compared GEE API original methods:","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()\n\n\n# Lima, Peru\npoint <- ee$Geometry$Point(-77.04111, -12.02228)\n\n# Estimate the NDVI of a specific ee$Image\nS2 <- ee$ImageCollection('COPERNICUS/S2_SR') %>% \n   ee$ImageCollection$filterBounds(point) %>%  # Filter by geometry (EE API)\n   ee_ImageCollection_closest('2020-10-15') %>% # Get the closest image to a specific date (rgeeExtra)\n   ee_model_cloudmask(prob = 70L) %>% # Cloud mask using ee_extra algorithm.\n   ee_ImageCollection_scaleAndOffset() %>%   # Convert from integer to float (real values)\n   ee_ImageCollection_spectralIndex(c('NDVI','NDWI','BAIS2')) %>% # Compute spectral indices\n   '[['(1) # Yes rgeeExtra also support subsettings operators!\n\n# Get the band names\nnames(S2)\n\n# Get the band names\nMap$centerObject(point, 11)\nMap$addLayer(S2[[\"NDVI\"]])"},{"path":"rgeeextra.html","id":"subsettings","chapter":"rgeeExtra","heading":"Subsettings","text":"rgeeExtra also supports subsetting operators!. works similar fantastic raster R package created Robert J. Hijmans.","code":""},{"path":"rgeeextra.html","id":"rgee-style","chapter":"rgeeExtra","heading":"rgee style","text":"","code":"\n# it does not supported without dozen of lines!"},{"path":"rgeeextra.html","id":"rgeeextra-style","chapter":"rgeeExtra","heading":"rgeeExtra style","text":"","code":"\nic <- lapply(1:5, function(x) ee$Image(x)) %>% ee$ImageCollection()\nic[[1]] <- ic[[2]] # Replace an ee$Image from an ee$ImageCollection.\nic[[3]] # From the ee$ImageCollection get the image with index 3. The index starts with 1.\nic[[4:5]] # From the ee$ImageCollection get the images with index 4 and 5.\nic[[3]][[\"Mar\"]] # From the ee$ImageCollection get the images with index 3, and select the band with name \"Mar\""},{"path":"rgeeextra.html","id":"overloaded-operators","chapter":"rgeeExtra","heading":"Overloaded Operators","text":"following operators overloaded: +, -, *, /, //, %, ** , <<, >>, &, |, <, <=, ==, !=, >, >=, -, ~. (can avoid eecImage$expression() method!)","code":""},{"path":"rgeeextra.html","id":"rgee-style-1","chapter":"rgeeExtra","heading":"rgee style","text":"","code":"\nS2 <- ee$ImageCollection(\"COPERNICUS/S2_SR\")$first()\n\nscaleImage <- function(img) {\n  scaling <- img$select(\"B.*\")\n  x <- scaling$multiply(0.0001)\n  scaling <- img$select(c(\"AOT\", \"WVP\"))\n  scaling <- scaling$multiply(0.001)\n  x <- x$addBands(scaling)\n  notScaling <- img$select(\n    c(\n      \"SCL\",\n      \"TCI.*\",\n      \"MSK.*\",\n      \"QA.*\"\n    )\n  )\n  x$addBands(notScaling)\n}\n\nS2 <- scaleImage(S2)\n\nexp <- \"2.5*(N-R)/(N+(6*R)-(7.5*B)+1)\"\n\nimgDict <- list(\n  N = S2$select(\"B8\"),\n  R = S2$select(\"B4\"),\n  B = S2$select(\"B2\")\n)\n\nEVI <- S2$expression(exp, imgDict)"},{"path":"rgeeextra.html","id":"rgeeextra-style-1","chapter":"rgeeExtra","heading":"rgeeExtra style","text":"","code":"\nS2 <- ee$ImageCollection$Dataset$COPERNICUS_S2_SR$first() %>% \n  ee_ImageCollection_scaleAndOffset()\n          \nN <- S2[[\"B8\"]]\nR <- S2[[\"B4\"]]\nB <- S2[[\"B2\"]]\n\nEVI = 2.5*(N-R)/(N+(6*R)-(7.5*B)+1)"},{"path":"rgeeextra.html","id":"clouds-and-shadows-masking","chapter":"rgeeExtra","heading":"Clouds and Shadows Masking","text":"Masking clouds shadows can done using eemont just one method: maskClouds()!","code":""},{"path":"rgeeextra.html","id":"rgee-style-2","chapter":"rgeeExtra","heading":"rgee style","text":"","code":"\nds <- 'LANDSAT/LC08/C01/T1_SR'\n\nmaskCloudsShadows <- function(img) {\n  cloud_c <- 2**3\n  cloud_s <- 2**5\n  qa <- 'pixel_qa'\n  qa <- img$select(qa)\n  cm <- qa$bitwiseAnd(cloud_c)$eq(0)\n  sm <- qa$bitwiseAnd(cloud_s)$eq(0)\n  mask <- cm$And(sm)\n  img$updateMask(mask)\n}\n\nee$ImageCollection(ds)$map(maskCloudsShadows)"},{"path":"rgeeextra.html","id":"rgeeextra-style-2","chapter":"rgeeExtra","heading":"rgeeExtra style","text":"","code":"\nds <- 'LANDSAT/LC08/C01/T1_SR'\nee$ImageCollection(ds) %>% \n  ee_model_cloudmask()"},{"path":"rgeeextra.html","id":"image-scaling-and-offsetting","chapter":"rgeeExtra","heading":"Image Scaling and Offsetting","text":"Scaling offsetting can also done using eemont just one method: scale()!","code":""},{"path":"rgeeextra.html","id":"rgee-style-3","chapter":"rgeeExtra","heading":"rgee style","text":"","code":"\nlibrary(rgee)\n\nee_Initialize()\n\nscaleBands <- function(img) {\n  scaling <- img$select(c('NDVI', 'EVI', 'sur.*'))\n  x <- scaling$multiply(0.0001)\n  scaling <- img$select('.*th')\n  scaling <- scaling$multiply(0.01)\n  x <- x$addBands(scaling)\n  notScaling <- img$select(c('DetailedQA', 'DayOfYear', 'SummaryQA'))\n  x$addBands(notScaling)\n}\n\nds <- 'MODIS/006/MOD13Q1'\n\nee$ImageCollection(ds)$map(scaleBands)"},{"path":"rgeeextra.html","id":"rgeeextra-style-3","chapter":"rgeeExtra","heading":"rgeeExtra style","text":"","code":"\nds <- 'MODIS/006/MOD13Q1'\n          \nee$ImageCollection(ds) %>% \n  ee_ImageCollection_scaleAndOffset()"},{"path":"rgeeextra.html","id":"complete-preprocessing","chapter":"rgeeExtra","heading":"Complete Preprocessing","text":"complete preprocessing workflow (Masking clouds shadows, image scaling offsetting) can done using eemont just one method: preprocess()!","code":""},{"path":"rgeeextra.html","id":"rgee-style-4","chapter":"rgeeExtra","heading":"rgee style","text":"","code":"\nds <- 'LANDSAT/LC08/C01/T1_SR'\n\nmaskCloudsShadows <- function(img) {\n  cloud_c <- 2**3\n  cloud_s <- 2**5\n  qa <- 'pixel_qa'\n  qa <- img$select(qa)\n  cm <- qa$bitwiseAnd(cloud_c)$eq(0)\n  sm <- qa$bitwiseAnd(cloud_s)$eq(0)\n  mask <- cm$And(sm)\n  img$updateMask(mask)\n}\n\nscaleBands <- function(img) {\n  scaling <- img$select('B[1-7]')\n  x <- scaling$multiply(0.0001)\n  scaling <- img$select(c('B10', 'B11'))\n  scaling <- scaling$multiply(0.1)\n  x <- x$addBands(scaling)\n  notScaling <- img$select(c(\n    'sr_aerosol',\n    'pixel_qa',\n    'radsat_qa'\n  ))\n  x$addBands(notScaling)\n}\n\nee$ImageCollection(ds) %>% \n  ee$ImageCollection$map(maskCloudsShadows) %>% \n  ee$ImageCollection$map(scaleBands)"},{"path":"rgeeextra.html","id":"rgeeextra-style-4","chapter":"rgeeExtra","heading":"rgeeExtra style","text":"","code":"\nds <- 'LANDSAT/LC08/C01/T1_SR'\nee$ImageCollection(ds) %>% \n    ee_ImageCollection_preprocess()"},{"path":"rgeeextra.html","id":"spectral-indices","chapter":"rgeeExtra","heading":"Spectral Indices","text":"need compute several spectral indices? Use ee_ImageCollection_spectralIndex() ee_Image_spectralIndex functions! \nindices taken Awesome Spectral Indices.","code":""},{"path":"rgeeextra.html","id":"rgee-style-5","chapter":"rgeeExtra","heading":"rgee style","text":"","code":"\nscaleBands <- function(img) {\n  scaling <- img$select(\"B[1-7]\")\n  x <- scaling$multiply(0.0001)\n  scaling <- img$select(c(\"B10\", \"B11\"))\n  scaling <- scaling$multiply(0.1)\n  x <- x$addBands(scaling)\n  notScaling <- img$select(c(\n    \"sr_aerosol\",\n    \"pixel_qa\",\n    \"radsat_qa\"\n  ))\n  x$addBands(notScaling)\n}\n\naddIndices <- function(img) {\n  x <- c(\"B5\", \"B4\")\n  a <- img$normalizedDifference(x)\n  a <- a$rename(\"NDVI\")\n  x <- c(\"B5\", \"B3\")\n  b <- img$normalizedDifference(x)\n  b <- b$rename(\"GNDVI\")\n  x <- c(\"B3\", \"B6\")\n  c <- img$normalizedDifference(x)\n  c <- b$rename(\"NDSI\")\n  img$addBands(c(a, b, c))\n}\n\nee$ImageCollection(ds) %>%\n  ee$ImageCollection$map(scaleImage) %>%\n  ee$ImageCollection$map(addIndices)"},{"path":"rgeeextra.html","id":"rgeeextra-style-5","chapter":"rgeeExtra","heading":"rgeeExtra style","text":"list available indices can retrieved running:Information indices can also checked:","code":"\nds <- 'LANDSAT/LC08/C01/T1_SR'\n          \nee$ImageCollection(ds) %>% \n  ee_ImageCollection_scaleAndOffset() %>% \n  ee_ImageCollection_spectralIndex(c('NDVI', 'GNDVI', 'NDSI'))\nee_list_spectral_indices()\nindices <- ee_spectral_indices() \nindices$BAIS2$formula\nindices$BAIS2$reference"},{"path":"rgeeextra.html","id":"closest-image-to-a-specific-date","chapter":"rgeeExtra","heading":"Closest Image to a Specific Date","text":"Struggling get closest image specific date? solution: closest() method!","code":""},{"path":"rgeeextra.html","id":"rgee-style-6","chapter":"rgeeExtra","heading":"rgee style","text":"","code":"\nds <- 'COPERNICUS/S5P/OFFL/L3_NO2'\n\nxy <- c(-76.21, 3.45)\npoi <- ee$Geometry$Point(xy)\n\ndate <- ee$Date('2020-10-15')\ndate <- date$millis()\n\nsetTimeDelta <- function(img) {\n  prop <- 'system:time_start'\n  prop <- img$get(prop)\n  prop <- ee$Number(prop)              \n  delta <- prop$subtract(date)\n  delta <- delta$abs()              \n  img$set('dateDist', delta)\n}\n\n                  \nee$ImageCollection(ds) %>% \n  ee$ImageCollection$filterBounds(poi) %>% \n  ee$ImageCollection$map(setTimeDelta) %>% \n  ee$ImageCollection$sort('dateDist') %>% \n  ee$ImageCollection$first()"},{"path":"rgeeextra.html","id":"rgeeextra-style-6","chapter":"rgeeExtra","heading":"rgeeExtra style","text":"","code":"\nds <- 'COPERNICUS/S5P/OFFL/L3_NO2'\n          \nxy <- c(-76.21, 3.45)\npoi <- ee$Geometry$Point(xy)\n\nee$ImageCollection(ds) %>% \n    ee$ImageCollection$filterBounds(poi) %>% \n    ee_ImageCollection_closest('2020-10-15')"},{"path":"visualization.html","id":"visualization","chapter":"Visualization","heading":"Visualization","text":"section requires next libraries:","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()"},{"path":"visualization.html","id":"introduction","chapter":"Visualization","heading":"Introduction","text":"Map$addLayer(…) can used visualize image. add layer (ee$Image) map without settings, rgee automatically allocates first three bands red (R), green (G), blue (B), order. default stretch determined band data type (example, floats stretched [0,1], whereas 16-bit data stretched [0-65536]), may may appropriate. may specify visualization settings Map$addLayer(...) create desired visualization effects. parameters follows:","code":""},{"path":"visualization.html","id":"rgb-composites","chapter":"Visualization","heading":"RGB composites","text":"following example illustrates style Landsat 8 image false-color composite:example, band B5 assigned red, B4 assigned green, B3 assigned blue. result look something like figure bellow.\nFigure N°01: Landsat 8 false color composite San Francisco bay area, California, USA.\n","code":"\n# Load an image.\nlandsat <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\n# Define the visualization parameters.\nvizParams <- list(\n  bands = c(\"B5\", \"B4\", \"B3\"),\n  min = 0,\n  max = 0.5,\n  gamma = c(0.95, 1.1, 1)\n)\n# Center the map and display the image.\nMap$setCenter(lon = -122.1899, lat = 37.5010, zoom = 10) # San Francisco Bay\nMap$addLayer(landsat, vizParams, \"false color composite\")"},{"path":"visualization.html","id":"color-palettes","chapter":"Visualization","heading":"Color palettes","text":"Set palette argument expressed list CSS-style color strings display single band image color (See reference information). following example illustrates use colors cyan (‘00FFFF’) blue (‘0000FF’) render Normalized Difference Water Index (NDWI) image:example, note min max parameters indicate range pixel values palette applied. Intermediate values linearly stretched. Also note define shown parameter FALSE, results visibility layer added map. can always turned using Layer Manager upper left corner map. result look something like Figure 2.\nFigure N°02: Landsat 8 NDWI, San Francisco bay area, USA. area Figure 1. Cyan low values, blue high values.\n","code":"\n# Load an image.\nlandsat <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\n# Create an NDWI image.\nndwi <- landsat$normalizedDifference(c(\"B3\", \"B5\"))\n# define visualization parameters and display image.\nndwiViz <- list(\n  min = 0.5,\n  max = 1,\n  palette = c(\"00FFFF\", \"0000FF\")\n)\nMap$addLayer(\n  eeObject = ndwi,\n  visParams = ndwiViz,\n  name = \"NDWI\",\n  shown = FALSE\n)"},{"path":"visualization.html","id":"masking","chapter":"Visualization","heading":"Masking","text":"can use image$updateMask(…) set opacity individual pixels based pixels mask image non-zero. Pixels equal zero mask excluded computations opacity set 0 display. following example uses NDWI threshold update mask NDWI layer created previously:\nFigure N°03: Landsat 8 NDWI, area Figure 2, masked values greater 0,4.\n","code":"\n# Mask the non-watery parts of the image, where NDWI < 0.4.\nndwiMasked <- ndwi$updateMask(ndwi$gte(0.4))\nMap$addLayer(ndwiMasked, ndwiViz, \"NDWI masked\")"},{"path":"visualization.html","id":"visualization-images","chapter":"Visualization","heading":"Visualization images","text":"Use image$visualize(…) method convert image 8-bit RGB image display export. example, convert false-color composite NDWI 3-band display images, use:","code":"\n# Load an image.\nlandsat <- ee$Image('LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318')\n# Create visualization layers.\nimageRGB <- landsat$visualize(\n  list(\n    bands = list(\"B5\", \"B4\", \"B3\"),\n    max = 0.5\n  )\n)\nndwiRGB <- ndwiMasked$visualize(\n  list(\n    min = 0.5,\n    max = 1,\n    palette = c('00FFFF', '0000FF')\n  )\n)"},{"path":"visualization.html","id":"mosaicking","chapter":"Visualization","heading":"Mosaicking","text":"can use masking imageCollection$mosaic(…) achieve various cartographic effects. mosaic() method renders layers output image according order input collection. following example uses mosaic() combine masked NDWI false color composite obtain new visualization:example, observe list two visualization images provided ImageCollection constructor. order list determines order images rendered map. result look something like Figure 3.\nFigure N°04: Mosaic Landsat 8 false color composite NDWI. San Francisco bay area, USA.\n","code":"\n# Mosaic the visualization layers and display (or export).\nmosaic <- ee$ImageCollection(list(imageRGB, ndwiRGB))$mosaic()\nMap$addLayer(eeObject = mosaic, list(), name = \"mosaic\")"},{"path":"visualization.html","id":"integration-with-other-r-packages","chapter":"Visualization","heading":"Integration with other R packages","text":"Map$addLayer(…) creates leaflet object\nfollowing extra attributes: tokens, name, opacity, shown, min, max, palette, legend.\nextra data help users customize interactive maps /integrate Map$addLayer R packages {mapview}, {mapedit} {leaflet}.{leaflet}: R package binding (develop Rstudio) leaflet open-source JavaScript library mobile-friendly interactive maps.\nFigure N°05: Map$addLayer {leaflet} integration\n{mapview}: R package develop Tim Appelhans provides functions quickly conveniently create interactive visualisations R spatial data. support popular\nR package spatial data ({sp}, {sf}, {stars}, {raster}).\nFigure N°06:Map$addLayer {mapview} integration.\n{mapedit}: adds spatial data edition functionality leaflet interactive maps (Similar Code Editor geometry tool).\nFigure N°07:Map$addLayer {mapedit} integration.\n","code":"\n# Load an image.\nlandsat <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\n# Define the visualization parameters.\nvizParams <- list(\n  bands = c(\"B5\", \"B4\", \"B3\"),\n  min = 0,\n  max = 0.5,\n  gamma = c(0.95, 1.1, 1)\n)\n# Center the map and display the image.\nMap$setCenter(lon = -122.1899, lat = 37.5010, zoom = 10) # San Francisco Bay\nm1 <- Map$addLayer(landsat, vizParams, \"false color composite\")\nm1$rgee\n#> $tokens\n#> [1] \"https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/6f68ea5563f0787171eef294011e5b1a-54a29dea5a564831913fb1c8c1653628/tiles/{z}/{x}/{y}\"\n#> \n#> $name\n#> [1] \"false color composite\"\n#> \n#> $opacity\n#> [1] 1\n#> \n#> $shown\n#> [1] TRUE\n#> \n#> $min\n#> [1] NA\n#> \n#> $max\n#> [1] NA\n#> \n#> $palette\n#> $palette[[1]]\n#> [1] NA\n#> \n#> \n#> $legend\n#> [1] FALSE\n# Load an image.\nlandsat <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\n\n# Define the visualization parameters.\nvizParams <- list(\n  bands = c(\"B5\", \"B4\", \"B3\"),\n  min = 0,\n  max = 0.5,\n  gamma = c(0.95, 1.1, 1)\n)\n\n# Center the map and display the image.\nMap$setCenter(lon = -122.1899, lat = 37.5010, zoom = 10) # San Francisco Bay\nm1 <- Map$addLayer(landsat, vizParams, \"false color composite\")\n\n# Integrate with leaflet\nleaflet() %>%\n  addTiles() %>%\n  setView(-122.1899, 37.5010, 9) %>%\n  addTiles(\n    urlTemplate = m1$rgee$tokens,\n    layerId = \"leaflet_false_color\",\n    options = leaflet::tileOptions(opacity = 1)\n  )\n# Load an image.\nlandsat <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\n\n# Define the visualization parameters.\nvizParams <- list(\n  bands = c(\"B5\", \"B4\", \"B3\"),\n  min = 0,\n  max = 0.5,\n  gamma = c(0.95, 1.1, 1)\n)\n\n# Center the map and display the image.\nMap$setCenter(lon = -122.1899, lat = 37.5010, zoom = 10) # San Francisco Bay\nm1 <- Map$addLayer(landsat, vizParams, \"false color composite\")\n\n# Integrate with mapview\nstp <- st_sfc(st_point(c(-122.27234, 37.46941)), crs = 4326)\nmapview(stp, m1)\n# Load an image.\nlandsat <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\n\n# Define the visualization parameters.\nvizParams <- list(\n  bands = c(\"B5\", \"B4\", \"B3\"),\n  min = 0,\n  max = 0.5,\n  gamma = c(0.95, 1.1, 1)\n)\n\n# Center the map and display the image.\nMap$setCenter(lon = -122.1899, lat = 37.5010, zoom = 10) # San Francisco Bay\nm1 <- Map$addLayer(landsat, vizParams, \"false color composite\")\n\n# Integrate with mapedit\nmy_geom <- editMap(m1)$drawn"},{"path":"visualization.html","id":"map-operators","chapter":"Visualization","heading":"Map Operators","text":"version 1.0.5, rgee support two map operators:m1 + m2: Overlay layers.\nFigure N°08: Overlay map example\nm1|m2: Side side view.\nFigure N°08: Side side example\n","code":"\n# Load an image.\nlandsat <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\nndwi <- landsat$normalizedDifference(c(\"B3\", \"B5\"))\nndwiMasked <- ndwi$updateMask(ndwi$gte(0.4))\n\n# Define the visualization parameters.\nvizParams <- list(\n  bands = c(\"B5\", \"B4\", \"B3\"),\n  min = 0,\n  max = 0.5,\n  gamma = c(0.95, 1.1, 1)\n)\nndwiViz <- list(\n  min = 0.5,\n  max = 1,\n  palette = c(\"00FFFF\", \"0000FF\")\n)\n\n# Center the map and display the image.\nMap$setCenter(lon = -122.1899, lat = 37.5010, zoom = 10) # San Francisco Bay\nm1 <- Map$addLayer(landsat, vizParams, \"false color composite\")\nm2 <- Map$addLayer(ndwiMasked, ndwiViz, \"NDWI masked\")\nm1 + m2\nm1 | m2"},{"path":"r-quickstart.html","id":"r-quickstart","chapter":"R Quickstart","heading":"R Quickstart","text":"section requires next libraries:","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()"},{"path":"r-quickstart.html","id":"get-started-with-earth-engine","chapter":"R Quickstart","heading":"Get Started with Earth Engine","text":"Get Started guide intended quick way start programming Earth Engine R API. introductory look R -depth exercises Earth Engine API, see tutorials. recommended R coding style, see R Style Guide.Google Earth Engine allows users run algorithms georeferenced imagery vectors stored Google’s infrastructure. Google Earth Engine API provides library functions may applied data display analysis. Earth Engine’s public data catalog contains large amount publicly available imagery vector datasets. Private assets can also created users’ personal folders.","code":""},{"path":"r-quickstart.html","id":"how-to-use-these-docs","chapter":"R Quickstart","heading":"How to use these docs","text":"Earth Engine documentation designed people familiar geospatial data analysis. docs primarily structured data type. example, left side navigation contains links sections pages important data types Image, ImageCollection, Feature, FeatureCollection, Geometry, Reducer, Join Array. guide describes enough types get started. also sections machine learning, specialized sensor specific algorithms (e.g. Landsat algorithms), public facing apps shinyapps.io important details Earth Engine internal workings. diving , start !","code":""},{"path":"r-quickstart.html","id":"earth-engine-data-structures","chapter":"R Quickstart","heading":"Earth Engine data structures","text":"two fundamental geographic data structures Earth Engine Image Feature corresponding raster vector data types, respectively. Images composed bands list properties. Features composed Geometry list properties. stack images (e.g. image time series) handled ImageCollection. collection features handled FeatureCollection. fundamental data structures Earth Engine include List, Array, Date, Number String (learn basic data types tutorial. important remember server-side objects manipulated way client-side R objects (learn ).","code":""},{"path":"r-quickstart.html","id":"earth-engine-algorithms","chapter":"R Quickstart","heading":"Earth Engine algorithms","text":"several ways run operations API:Calling methods attached objects.Calling algorithms.Calling rgee specific functions.Defining new functions.Use rgee Rstudio addins get access documentation. example, Image class add() method:","code":""},{"path":"r-quickstart.html","id":"using-rgee","chapter":"R Quickstart","heading":"Using rgee","text":"","code":"\nimage3 <- image1$add(image2)"},{"path":"r-quickstart.html","id":"using-rgeeextra","chapter":"R Quickstart","heading":"Using rgeeExtra","text":"method adds bands image2 bands image1. ee$Algorithms category contains list currently supported algorithms specialized domain specific processing. example, create topographic layers input Digital Elevation Model (DEM):rgee specific functions include Map ee$batch$Export methods, control layers added map panel exported Google Drive, respectively. Functions can also created R usingAs illustrated Mapping section, user defined functions useful creating custom functionality modifying elements collection using:following sections illustrate concepts various simple use cases.Notation used guides:Static methods called Earth Engine class (example ee$Image) written Image$staticMethod(). Methods called instance class written image$instanceMethod(). lowercase image means variable named image refers instance ee$Image class.","code":"\nimage3 <- image1 + image2\nterrainImage <- ee$Algorithms$Terrain(dem)\nmyFunction <- function(args) {\n  # do something\n  return(something)\n}\ncollection2 <- collection1$map(aFunction)"},{"path":"r-quickstart.html","id":"hello-world---r","chapter":"R Quickstart","heading":"‘Hello World’ - R","text":"Printing information console basic task getting information object, displaying numeric result computation, displaying object metadata helping debugging. iconic ‘Hello World!’ example R :Copy line RStudio Code Editor click Run. Note output displayed Console tab. remote sensing relevant example, following prints metadata Landsat 8 image:Carefully inspect output console see metadata available Landsat images.","code":"\nprint('Hello world!')\nimg <- ee$Image('LANDSAT/LC08/C01/T1/LC08_044034_20140318')\nee_print(img)"},{"path":"r-quickstart.html","id":"adding-data-to-the-map","chapter":"R Quickstart","heading":"Adding data to the map","text":"addition printing information console, adding data Map way visualize geographic data. Use Map$addLayer() . following example, Image instantiated (find images covered later) using ee$Image(), added map Map$addLayer() map centered image:\nsecond parameter Map$centerObject() zoom level, higher numbers indicate larger scale (zoomed ). parameters Map functions described depth rgee documentation: help(Map) help(R6Map). appearance image unsatisfactory, configure display parameters additional argument Map$addLayer(). example:Observe visualization parameters defined object literal, includes list bands display, minimum maximum digital number gamma value. (Learn Landsat bands . Learn image visualization ).Use Map$addLayer() add features feature collections map. example,","code":"\n## Load an image.\nimage <- ee$Image('LANDSAT/LC08/C01/T1/LC08_044034_20140318')\n\n## Center the map on the image.\nMap$centerObject(image, 9)\n\n## Display the image.\nMap$addLayer(image)\n## Load the image from the archive.\nimage <- ee$Image('LANDSAT/LC08/C01/T1/LC08_044034_20140318')\n\n## Define visualization parameters in an object literal.\nvizParams <- list(\n  bands = c('B5', 'B4', 'B3'),\n  min = 5000, \n  max = 15000, \n  gamma = 1.3\n)\n\n## Center the map on the image and display.\nMap$centerObject(image, 9)\nMap$addLayer(image, vizParams, 'Landsat 8 false color')\ncounties <- ee$FeatureCollection('TIGER/2016/Counties')\nMap$addLayer(counties, {},'counties')"},{"path":"r-quickstart.html","id":"finding-images-image-collections-and-feature-collections","chapter":"R Quickstart","heading":"Finding images, image collections and feature collections","text":"Images, image collections, feature collections discoverable searching Earth Engine Data Catalog. example, entering ‘Landsat 8’ search field results list raster datasets. (complete listing Earth Engine datasets Earth Engine Data Catalog). rgee add special attribute Dataset ee$Image, ee$ImageCollection, ee$FeatureCollections objects. Use ...$Dataset easy get access EE Data Catalog.Search Earth Engine Data CatalogAlternatively, copy collection ID paste code. example, choose first result ‘Landsat 8’ search copy ID follows:Since collection many images spanning Earth land surface, finding individual image collection requires filtering order narrow search. Alternatively, collection images can reduced single image using compositing mosaicking techniques. filtering compositing (see Reducing) next sections.Feature collections also available Data Catalog. representation smaller image collections, find international, census, watershed, protected areas boundaries, name . Learn importing vector datasets .","code":"\nee$Image$Dataset$...\nee$ImageCollection$Dataset$...\nee$FeatureCollection$Dataset$...\nee$Image$Dataset$USGS_SRTMGL1_003 %>% \n  ee_utils_dataset_display()\ncollection <- ee$ImageCollection('LANDSAT/LC08/C01/T1')"},{"path":"r-quickstart.html","id":"filtering-and-sorting","chapter":"R Quickstart","heading":"Filtering and Sorting","text":"often necessary filter collection space /time order limit number results. example, consider task sorting Landsat 8 scene collection order find cloud-free scene San Francisco. First, necessary define region interest. point often useful . Press Ctrl click near center area interest, atuomatically copy coordinates, construct ee$Point using:Construct start end dates:Filter Landsat 8 collection using point dates, sort using metadata property (discovered inspection Landsat 8 scene metadata):collection can safely inspected using `ee_print. (collection many images, printing either slow, time , return error). Observe images collection List stored ‘features’ property ImageCollection. ID image collection can copied Image constructor . Alternatively, get first image (lowest cloud cover):","code":"\n\" lon: -118.12500 | lat: 63.52866 | zoom: 1 \"\npoint <- ee$Geometry$Point(-118.12500, 63.52866)\nstart <- ee$Date('2014-06-01')\nfinish <- ee$Date('2014-10-01')\nfilteredCollection <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1\") %>% \n  ee$ImageCollection$filterDate(start, finish) %>% \n  ee$ImageCollection$filterBounds(point) %>% \n  ee$ImageCollection$sort('CLOUD_cOVER')"},{"path":"r-quickstart.html","id":"using-rgee-1","chapter":"R Quickstart","heading":"using rgee","text":"","code":"\nfirst <- filteredCollection$first()"},{"path":"r-quickstart.html","id":"using-rgeeextra-1","chapter":"R Quickstart","heading":"using rgeeExtra","text":"Access complete Earth Engine filtering functionality using filter() ee$Filter argument. (filterBounds() filterDate() methods used shortcuts). example, following creates Filter, uses filter FeatureCollection displays result:","code":"\nfirst <- filteredCollection[[1]]\n## Load a feature collection.\nfeatureCollection <- ee$FeatureCollection('TIGER/2016/States')\n\n## Filter the collection.\nfilteredFC <- featureCollection %>% \n  ee$FeatureCollection$filter(\n    ee$Filter$eq('NAME', 'California')\n  )\n\n## Display the collection.\nMap$addLayer(filteredFC, {}, 'California')"},{"path":"r-quickstart.html","id":"band-math","chapter":"R Quickstart","heading":"Band math","text":"Perform mathematical operations images using Image methods. may include band recombinations (spectral indices), image differencing mathematical operations multiplication constant. example, compute difference Normalized Difference Vegetation Index (NDVI) images 20 years apart:","code":""},{"path":"r-quickstart.html","id":"using-rgee-2","chapter":"R Quickstart","heading":"using rgee","text":"","code":"\n## This function gets NDVI from Landsat 5 imagery.\ngetNDVI <- function(image) {\n  return(image$normalizedDifference('B4', 'B3'))\n}\n\n## Load two Landsat 5 images, 20 years apart.\nimage1 = ee$Image('LANDSAT/LT05/C01/T1_TOA/LT05_044034_19900604')\nimage2 = ee$Image('LANDSAT/LT05/C01/T1_TOA/LT05_044034_20100611')\n\n## Compute NDVI from the scenes.\nndvi1 = getNDVI(image1)\nndvi2 = getNDVI(image2)\n\n## Compute the difference in NDVI.\nndviDifference = ndvi2$subtract(ndvi1)"},{"path":"r-quickstart.html","id":"using-rgeeextra-2","chapter":"R Quickstart","heading":"using rgeeExtra","text":"Notice use user defined function example. functions next section.","code":"\n## This function gets NDVI from Landsat 5 imagery.\ngetNDVI <- function(image) {\n  (image[[\"B4\"]] - image[[\"B3\"]])/(image[[\"B4\"]] + image[[\"B3\"]])\n}\n\n## Load two Landsat 5 images, 20 years apart.\nimage1 <- ee$Image('LANDSAT/LT05/C01/T1_TOA/LT05_044034_19900604')\nimage2 <- ee$Image('LANDSAT/LT05/C01/T1_TOA/LT05_044034_20100611')\n\n## Compute NDVI from the scenes.\nndvi1 <- getNDVI(image1)\nndvi2 <- getNDVI(image2)\n\n## Compute the difference in NDVI.\nndviDifference = ndvi2 - ndvi1"},{"path":"r-quickstart.html","id":"mapping-what-to-do-instead-of-a-for-loop","chapter":"R Quickstart","heading":"Mapping (what to do instead of a for-loop)","text":"Use map() iterate items collection. (loops right way Earth Engine avoided). map() function can applied ImageCollection, FeatureCollection List accepts function argument. argument function element collection mapped. useful modifying every element collection way, example adding. example, following code adds NDVI band every image ImageCollection:","code":""},{"path":"r-quickstart.html","id":"using-rgee-3","chapter":"R Quickstart","heading":"Using rgee","text":"","code":"\n## This function gets NDVI from Landsat 8 imagery.\naddNDVI <- function(image) {\n  return(image$addBands(image$normalizedDifference('B5', 'B4')))\n}\n\n## Load the Landsat 8 raw data, filter by location and date.\nee_geom <- ee$Geometry$Point(-122.262, 37.8719)\ncollection <- ee$ImageCollection('LANDSAT/LC08/C01/T1') %>% \n  ee$ImageCollection$filterBounds(ee_geom) %>% \n  ee$ImageCollection$filterDate('2014-06-01', '2014-10-01')\n\n## Map the function over the collection.\nndviCollection <- collection$map(addNDVI)"},{"path":"r-quickstart.html","id":"using-rgeeextra-3","chapter":"R Quickstart","heading":"Using rgeeExtra","text":"Another common task adding new property (‘attribute’ ‘field’) features FeatureCollection. following example, new property computation involving two existing attributes:Note cast ee$Number required property value recognized number order use add() method. type collection can changed map(). example:Note added property (foo) feature created image centroid. final line, cast makes resultant collection recognizable FeatureCollection.","code":"\n## This function gets NDVI from Landsat 8 imagery.\naddNDVI <- function(image) {\n  ndvi <- (image[[\"B5\"]] - image[[\"B4\"]])/(image[[\"B5\"]] + image[[\"B4\"]])\n  image$addBands(ndvi)\n}\n\n## Load the Landsat 8 raw data, filter by location and date.\nee_geom <- ee$Geometry$Point(-122.262, 37.8719)\ncollection <- ee$ImageCollection('LANDSAT/LC08/C01/T1') %>% \n  ee$ImageCollection$filterBounds(ee_geom) %>% \n  ee$ImageCollection$filterDate(\"2014-06-01\", \"2014-10-01\")\n\n## Map the function over the collection.\nndviCollection <- collection$map(addNDVI)\n## This function creates a new property that is the sum of two existing properties.\naddField <- function(feature) {\n  sum <- ee$Number(feature$get('property1'))$add(feature$get('property2'))\n  feature$set(sum = sum)\n}\n\n## Create a FeatureCollection from a list of Features.\nfeatures <- ee$FeatureCollection(c(\n  ee$Feature(ee$Geometry$Point(-122.4536, 37.7403),\n    list(property1 = 100, property2 = 100)),\n  ee$Feature(ee$Geometry$Point(-118.2294, 34.039),\n    list(property1 = 200, property2 = 200))\n))\n## Map the function over the collection.\nfeatureCollection <- features$map(addField)\n\n## Print a selected property of one Feature.\nprint(featureCollection$first()$get('sum')$getInfo())\n\n## Print the entire FeatureCollection.\nee_print(featureCollection)\n## This function returns the image centroid as a new Feature.\ngetGeom <- function(image) {\n  ee$Feature(image$geometry()$centroid(), list(foo = 1))\n}\n\n## Load a Landsat 8 collection.\nee_geom <- ee$Geometry$Point(-122.262, 37.8719)\ncollection <- ee$ImageCollection('LANDSAT/LC08/C01/T1') %>% \n  ee$ImageCollection$filterBounds(ee_geom) %>% \n  ee$ImageCollection$filterDate('2014-06-01', '2014-10-01')\n\n## Map the function over the ImageCollection.\nfeatureCollection <- ee$FeatureCollection(collection$map(getGeom))\n\n## Print the collection.\nee_print(featureCollection)"},{"path":"r-quickstart.html","id":"reducing","chapter":"R Quickstart","heading":"Reducing","text":"Reducing way aggregate data time, space, bands, arrays data structures Earth Engine. Various methods exist purpose API. example, make composite ImageCollection, use reduce() reduce images collection one Image. simple example creating median composite five least cloudy scenes Landsat 8 collection defined earlier:","code":"\n## Load a Landsat 8 collection.\ncollection <- ee$ImageCollection('LANDSAT/LC08/C01/T1') %>% \n  ## Filter by date and location.\n  ee$ImageCollection$filterBounds(ee$Geometry$Point(-122.262, 37.8719)) %>% \n  ee$ImageCollection$filterDate('2014-01-01', '2014-12-31') %>% \n  ## Sort by increasing cloudiness.\n  ee$ImageCollection$sort('CLOUD_COVER')"},{"path":"r-quickstart.html","id":"using-rgee-4","chapter":"R Quickstart","heading":"Using rgee","text":"","code":"\n## Compute the median of each pixel for each band of the 5 least cloudy scenes.\nmedian <- collection$limit(5)$reduce(ee$Reducer$median())"},{"path":"r-quickstart.html","id":"using-rgeeextra-4","chapter":"R Quickstart","heading":"Using rgeeExtra","text":"Reducing also way get statistics image regions defined Feature FeatureCollection. Suppose task compute mean pixel values within area interest. Use reduceRegion() purpose. example:Learn reducers Reducers doc.","code":"\n## Compute the median of each pixel for each band of the 5 least cloudy scenes.\nmedian <- collection[[1:5]]$reduce(ee$Reducer$median())\n## Load and display a Landsat TOA image.\nimage <- ee$Image('LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318')\n\n## Create an arbitrary rectangle as a region and display it.\nregion <- ee$Geometry$Rectangle(-122.2806, 37.1209, -122.0554, 37.2413)\n\n## Get a dictionary of means in the region.  Keys are bandnames.\nmean <- image$reduceRegion(\n  reducer = ee$Reducer$mean(),\n  geometry = region,\n  scale = 30\n)\n\nMap$addLayer(\n  eeObject = image,\n  visParams = list(bands = c(\"B4\", \"B3\", \"B2\"), max = 0.5), \n  name = \"SF\"\n) + \nMap$addLayer(region, list(color=\"red\"), name = \"ROI\")"},{"path":"r-quickstart.html","id":"masking-1","chapter":"R Quickstart","heading":"Masking","text":"Every pixel ee$Image value mask ranges 0 (data) 1. Masked pixels (mask == 0) treated data. Pixels 0 < mask ≤ 1 value, weighted mask numerical computations.can make pixels transparent exclude analysis using masks. Pixels masked mask value zero. Continuing image differencing example, use mask display areas increased decreased NDVI difference interval:","code":""},{"path":"r-quickstart.html","id":"using-rgee-5","chapter":"R Quickstart","heading":"Using rgee","text":"","code":"\n## This function gets NDVI from Landsat 5 imagery.\ngetNDVI <- function(image) {\n  image$normalizedDifference(c('B4', 'B3'))\n}\n\n## Load two Landsat 5 images, 20 years apart.\nimage1 <- ee$Image('LANDSAT/LT05/C01/T1_TOA/LT05_044034_19900604')\nimage2 <- ee$Image('LANDSAT/LT05/C01/T1_TOA/LT05_044034_20100611')\n\n## Compute NDVI from the scenes.\nndvi1 <- getNDVI(image1)\nndvi2 <- getNDVI(image2)\n\n## Compute the difference in NDVI.\nndviDifference = ndvi2$subtract(ndvi1)\n## Load the land mask from the SRTM DEM.\nlandMask <- ee$Image('CGIAR/SRTM90_V4')$mask()\n\n## Update the NDVI difference mask with the land mask.\nmaskedDifference <- ndviDifference$updateMask(landMask)\n\n## Display the masked result.\nvizParams <- list(\n  min = -0.5, \n  max = 0.5, \n  palette = c('FF0000', 'FFFFFF', '0000FF')\n)\nMap$setCenter(-122.2531, 37.6295, 9)\nMap$addLayer(maskedDifference, vizParams, 'NDVI difference')"},{"path":"r-quickstart.html","id":"using-rgeeextra-5","chapter":"R Quickstart","heading":"Using rgeeExtra","text":"example, note mask NDVI difference updated land mask updateMask(). sets mask NDVI difference pixels land mask wherever NDVI difference mask non-zero.Masking also useful excluding data analysis. Consider reduceRegion() example Reducing section. Suppose task compute seasonal mean NDVI Santa Clara county, CA, excluding cloudy pixels. following example demonstrates multiple concepts: filtering, mapping, reducing use cloud mask:","code":"\n## This function gets NDVI from Landsat 5 imagery.\ngetNDVI <- function(image) {\n  (image[[\"B4\"]] - image[[\"B3\"]])/(image[[\"B4\"]] + image[[\"B3\"]])\n}\n\n## Load two Landsat 5 images, 20 years apart.\nimage1 <- ee$Image('LANDSAT/LT05/C01/T1_TOA/LT05_044034_19900604')\nimage2 <- ee$Image('LANDSAT/LT05/C01/T1_TOA/LT05_044034_20100611')\n\n## Compute NDVI from the scenes.\nndvi1 <- getNDVI(image1)\nndvi2 <- getNDVI(image2)\n\n## Compute the difference in NDVI.\nndviDifference <- ndvi2 - ndvi1\n\n## Load the land mask from the SRTM DEM.\nlandMask <- ee$Image('CGIAR/SRTM90_V4')$mask()\n\n## Update the NDVI difference mask with the land mask.\nmaskedDifference <- ndviDifference$updateMask(landMask)\n\n## Display the masked result.\nvizParams <- list(\n  min = -0.5, \n  max = 0.5, \n  palette = c('FF0000', 'FFFFFF', '0000FF')\n)\nMap$setCenter(-122.2531, 37.6295, 9)\nMap$addLayer(maskedDifference, vizParams, 'NDVI difference')\n## This function gets NDVI from a Landsat 8 image.\naddNDVI <- function(image) {\n  return(image$addBands(image$normalizedDifference(c('B5', 'B4'))))\n}\n\n## This function masks cloudy pixels.\ncloudMask <- function(image) {\n  clouds <- ee$Algorithms$Landsat$simpleCloudScore(image)$select('cloud')\n  return(image$updateMask(clouds$lt(10)))\n}\n\n## Load a Landsat collection, map the NDVI and cloud masking functions over it.\nee_geom <- ee$Geometry$Point(-122.262, 37.8719)\ncollection <- ee$ImageCollection('LANDSAT/LC08/C01/T1_TOA') %>% \n  ee$ImageCollection$filterBounds(ee_geom) %>% \n  ee$ImageCollection$filterDate('2014-03-01', '2014-05-31') %>% \n  ee$ImageCollection$map(addNDVI) %>% \n  ee$ImageCollection$map(cloudMask)\n\n## Reduce the collection to the mean of each pixel and display.\nmeanImage <- collection$reduce(ee$Reducer$mean())\nvizParams <- list(\n  bands = c('B5_mean', 'B4_mean', 'B3_mean'),\n  min = 0, \n  max = 0.5)\n\n\n## Load a region in which to compute the mean and display it.\ncounties <- ee$FeatureCollection('TIGER/2016/Counties')\nsantaClara <- ee$Feature(counties$filter(ee$Filter$eq('NAME', 'Santa Clara'))$first())\n\n## Get the mean of NDVI in the region.\nmean <- meanImage$select('nd_mean')$reduceRegion(\n  reducer = ee$Reducer$mean(),\n  geometry = santaClara$geometry(),\n  scale = 30\n)\n\n## Print mean NDVI for the region.\nprint('Santa Clara spring mean NDVI:', mean$get('nd_mean')$getInfo())\n\n\n# Display maps\nMap$addLayer(meanImage, vizParams, 'mean') +\nMap$addLayer(santaClara)"},{"path":"coding-best-practices.html","id":"coding-best-practices","chapter":"Coding Best Practices","heading":"Coding Best Practices","text":"section requires next libraries:doc describes coding practices intended maximize chance success complex expensive Earth Engine computations.","code":"\nlibrary(rgee)\n\nee_Initialize()"},{"path":"coding-best-practices.html","id":"avoid-mixing-client-functions-and-objects-with-server-functions-and-objects","chapter":"Coding Best Practices","heading":"Avoid mixing client functions and objects with server functions and objects","text":"Earth Engine server objects objects constructors start ee (e.g. ee$Image, ee$Reducer) methods objects server functions. object constructed manner client object. Client objects may come R Earth Engine client (e.g. Map) R language (e.g. date, data.frame, c(), list()).avoid unintended behavior, mix client server functions script discussed . See page -depth explanation client vs. server Earth Engine. following example illustrates dangers mixing client server functionality:\n  Error — code doesn’t work!Can spot error? Note table$size() server method server\nobject can used client-side functionality seq_len function.situation may want use -loops display results\nMap, since Map object methods client-side.\n  Good — Use client functions display Earth Engine spatial objects.Conversely, map() server function client functionality won’t work\ninside function passed map(). example:\n  Error — code doesn’t work!\n  Good — Use map() set().can also filter() collection based computed existing properties\nprint() result. Note can print collection \n5000 elements. get “Collection query aborted accumulating \n5000 elements” error, filter() limit() collection printing.","code":"\n# Won't work.\nfor (i in seq_len(table$size())) {\n  print('No!') \n}\nl8_ts <- sprintf(\n  \"LANDSAT/LC08/C01/T1/LC08_044034_%s\",\n  c(\"20140318\", \"20140403\",\"20140419\",\"20140505\")\n)\ndisplay_l8ts <- list()\nfor (l8 in l8_ts) {\n  ee_l8 <- ee$Image(l8)\n  display_l8ts[[l8]] <- Map$addLayer(ee_l8)\n}\nMap$centerObject(ee_l8)\nReduce('+', display_l8ts)\ntable <- ee$FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n# Error:\nfoobar <- table$map(function(f) {\n  print(f); # Can't use a client function here.\n  # Can't Export, either.\n})\ntable <- ee$FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n# Do something to every element of a collection.\nwithMoreProperties = table$map(function(f) {\n  # Set a property.\n  f$set(\"area_sq_meters\", f$area())\n})\nprint(withMoreProperties$first()$get(\"area_sq_meters\")$getInfo())"},{"path":"coding-best-practices.html","id":"avoid-converting-to-list-unnecessarily","chapter":"Coding Best Practices","heading":"Avoid converting to list unnecessarily","text":"Collections Earth Engine processed using optimizations broken converting collection List Array type. Unless need random access collection elements (.e. need get ’th element collection), use filters collection access individual collection elements. following example illustrates difference type conversion (recommended) filtering (recommended) access element collection:\n  Bad — Don’t convert list unnecessarily!Note can easily trigger errors converting collection list unnecessarily. safer way use filter():\n  Good — Use filter().Note use filters early possible analysis.","code":"\ntable <- ee$FeatureCollection('USDOS/LSIB_SIMPLE/2017');\n# Do NOT do this!!\nlist <- table$toList(table$size())\nprint(list$get(13)$getInfo()) # User memory limit exceeded.\nprint(table$filter(ee$Filter$eq('country_na', 'Niger'))$first()$getInfo())"},{"path":"coding-best-practices.html","id":"avoid-ee.algorithms.if","chapter":"Coding Best Practices","heading":"Avoid ee.Algorithms.If()","text":"use ee.Algorithms.() implement branching logic, especially mapped function. following example illustrates, ee.Algorithms.() can memory intensive recommended:\n  Bad — Don’t use ():Note second argument map() TRUE. means mapped\nfunction may return nulls dropped resultant collection.\ncan useful (without ()), easiest solution use \nfilter:\n  Good — Use filter().shown tutorial, functional programming approach using filters correct way apply one logic elements collection another logic elements collection.","code":"\ntable <- ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n# Do NOT do this!\nveryBad = table$map(function(f) {\n  ee$Algorithms$If(\n    condition = ee$String(f$get('country_na'))$compareTo('Chad')$gt(0),\n    trueCase = f,      # Do something.\n    falseCase = NULL   # Do something else.\n  )\n}, TRUE)\nprint(veryBad$getInfo()) # User memory limit exceeded.\n# If() may evaluate both the true and false cases.\nprint(table$filter(ee$Filter$eq('country_na', 'Chad')))"},{"path":"coding-best-practices.html","id":"avoid-reproject","chapter":"Coding Best Practices","heading":"Avoid reproject()","text":"Don’t use reproject unless absolutely necessary. One reason might want use reproject() force Map display computations happen specific scale can examine results desired scale analysis. next example, patches hot pixels computed count pixels patch computed. Run example click one patches. Note count pixels differs reprojected data data reprojected.reason discrepancy scale analysis set Code Editor zoom level. calling reproject() set scale computation instead Map display. Use reproject() extreme caution reasons described doc.","code":"\nl8sr <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_SR\")\nsf <- ee$Geometry$Point(c(-122.405, 37.786))\nMap$centerObject(sf, 13)\n# A reason to reproject - counting pixels and exploring interactively.\nimage <- l8sr$filterBounds(sf)$\n  filterDate(\"2019-06-01\", \"2019-12-31\")$\n  first()\nMap$addLayer(image, list(bands = \"B10\", min = 2800, max = 3100), \"image\")\nhotspots <- image$select(\"B10\")$\n  gt(3100)$\n  selfMask()$\n  rename(\"hotspots\")\nobjectSize <- hotspots$connectedPixelCount(256)\n# Beware of reproject!  Don't zoom out on reprojected data.\nreprojected <- objectSize$reproject(hotspots$projection())\nMap$addLayer(objectSize, list(min = 1, max = 256), \"Size No Reproject\", FALSE) +\nMap$addLayer(reprojected, list(min = 1, max = 256), \"Size Reproject\", FALSE)"},{"path":"coding-best-practices.html","id":"filter-and-select-first","chapter":"Coding Best Practices","heading":"Filter and select() first","text":"general, filter input collections time, location /metadata prior anything else collection. Apply selective filters less selective filters. Spatial /temporal filters often selective. example, note select() filter() applied map():","code":"\nimages <- ee$ImageCollection(\"COPERNICUS/S2_SR\")\nsf <- ee$Geometry$Point(c(-122.463, 37.768))\n# Expensive function to reduce the neighborhood of an image.\nreduceFunction <- function(image) {\n  image$reduceNeighborhood(\n    reducer = ee$Reducer$mean(),\n    kernel = ee$Kernel$square(4)\n  )\n}\nbands <- list(\"B4\", \"B3\", \"B2\")\n# Select and filter first!\nreasonableComputation <- images$select(bands)$\n  filterBounds(sf)$\n  filterDate(\"2018-01-01\", \"2019-02-01\")$\n  filter(ee$Filter$lt(\"CLOUDY_PIXEL_PERCENTAGE\", 1))$\n  aside(ee_print)$ # Useful for debugging.\n  map(reduceFunction)$\n  reduce('mean')$\n  rename(bands)\nviz <- list(bands = bands, min = 0, max = 10000)\nMap$addLayer(reasonableComputation, viz, \"resonableComputation\")"},{"path":"coding-best-practices.html","id":"use-updatemask-instead-of-mask","chapter":"Coding Best Practices","heading":"Use updateMask() instead of mask()","text":"difference updateMask() mask() former logical () argument (new mask) existing image mask whereas mask() simply replaces image mask argument. danger latter can unmask pixels unintentionally. example, goal mask pixels less equal 300 meters elevation. can see (zoom ), using mask() causes lot pixels become unmasked, pixels don’t belong image interest:","code":"\nl8sr <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_SR\")\nsf <- ee$Geometry$Point(c(-122.40554461769182, 37.786807309873716))\naw3d30 <- ee$Image(\"JAXA/ALOS/AW3D30_V1_1\")\nMap$centerObject(sf, 7)\nimage <- l8sr$filterBounds(sf)$filterDate(\"2019-06-01\", \"2019-12-31\")$first()\nvis <- list(bands = c(\"B4\", \"B3\", \"B2\"), min = 0, max = 3000)\nMap$addLayer(image, vis, \"image\", FALSE)\nmask <- aw3d30$select(\"AVE\")$gt(300)\nMap$addLayer(mask, {}, 'mask', FALSE)\n# NO!  Don't do this!\nbadMask <- image$mask(mask)\nMap$addLayer(badMask, vis, \"badMask\")\ngoodMask <- image.updateMask(mask)\nMap$addLayer(goodMask, vis, \"goodMask\", FALSE)"},{"path":"coding-best-practices.html","id":"combine-reducers","chapter":"Coding Best Practices","heading":"Combine reducers","text":"need multiple statistics (e.g. mean standard deviation) single input (e.g. image region), efficient combine reducers. example, get image statistics, combine reducers follows:example, note mean reducer combined standard deviation reducer sharedInputs true enable single pass input pixels. output dictionary, name reducer appended band name. get mean SD images (example normalize input image), can turn values image use regexes extract means SDs individually demonstrated example.","code":"\nimage <- ee$Image('COPERNICUS/S2/20150821T111616_20160314T094808_T30UWU')\n# Get mean and SD in every band by combining reducers.\nstats <- image$reduceRegion(\n  reducer = ee$Reducer$mean()$combine(\n    reducer2 = ee$Reducer$stdDev(),\n    sharedInputs = TRUE\n  ),\n  geometry = ee$Geometry$Rectangle(c(-2.15, 48.55, -1.83, 48.72)),\n  scale = 10,\n  bestEffort = TRUE # Use maxPixels if you care about scale.\n)\nprint(stats$getInfo())\n# Extract means and SDs to images.\nmeansImage <- stats$toImage()$select('.*_mean')\nsdsImage <- stats$toImage()$select('.*_stdDev')"},{"path":"coding-best-practices.html","id":"use-export","chapter":"Coding Best Practices","heading":"Use Export","text":"computations result “User memory limit exceeded” “Computation timed ” errors Code Editor, computations may able succeed using Export. timeouts longer allowable memory footprint larger running batch system (exports run). (approaches may want try first detailed debugging doc). Continuing previous example, suppose dictionary returned error. obtain results something like:Note link embedded asset name, reproducibility. Also note want export toAsset, need supply geometry, can anything, example image centroid, small cheap compute. (.e. don’t use complex geometry don’t need ).See debugging page examples using Export resolve Computation timed many concurrent aggregations. See doc details exporting general.","code":"\nlink <- '86836482971a35a5e735a17e93c23272'\ntask <- ee$batch$Export$table$toDrive(\n  collection = ee$FeatureCollection(ee$Feature(NULL, stats)),\n  description = paste0(\"exported_stats_demo_\", link),\n  fileFormat = \"CSV\"\n)\n# Using rgee I/O\ntask <- ee_table_to_drive(\n  collection = ee$FeatureCollection(ee$Feature(NULL, stats)),\n  description = paste0(\"exported_stats_demo_\", link),\n  fileFormat = \"CSV\"\n)\ntask$start()\nee_monitoring(task)\nexported_stats <- ee_drive_to_local(task = task,dsn = \"exported_stats.csv\")\nread.csv(exported_stats)"},{"path":"coding-best-practices.html","id":"if-you-dont-need-to-clip-dont-use-clip","chapter":"Coding Best Practices","heading":"If you don’t need to clip, don’t use clip() ","text":"Using clip() unnecessarily increase computation time. Avoid clip() unless ’s necessary analysis. ’re sure, don’t clip. example bad use clip:\n  Bad — Don’t clip inputs unnecessarily!Clipping input images can skipped entirely, region specified reduceRegion() call:\n  Good — Specify region output.computation times , Export example.","code":"\ntable <- ee$FeatureCollection('USDOS/LSIB_SIMPLE/2017')\nl8sr <- ee$ImageCollection('LANDSAT/LC08/C01/T1_SR')\nchad <- table$filter(ee$Filter$eq('country_na', 'Chad'))$first()\n# Do NOT clip unless you need to.\nunnecessaryClip <- l8sr$\n  select('B4')$                           # Good.\n  filterBounds(chad$geometry())$          # Good.\n  filterDate('2019-01-01', '2019-12-31')$ # Good.\n  map(function(image) {\n    image$clip(chad$geometry())   # NO! Bad! Not necessary.\n  })$\n  median()$\n  reduceRegion(\n    reducer = ee$Reducer$mean(),\n    geometry = chad$geometry(),\n    scale = 30,\n    maxPixels = 1e10\n  )\nprint(unnecessaryClip$getInfo())\nnoClipNeeded <- l8sr$\n  select('B4')$                          # Good.\n  filterBounds(chad$geometry())$          # Good.\n  filterDate('2019-01-01', '2019-12-31')$ # Good.\n  median()$\n  reduceRegion(\n    reducer = ee$Reducer$mean(),\n    geometry = chad$geometry(), # Geometry is specified here.\n    scale = 30,\n    maxPixels = 1e10\n  )\nprint(noClipNeeded$getInfo())"},{"path":"coding-best-practices.html","id":"if-you-need-to-clip-with-a-complex-collection-use-cliptocollection","chapter":"Coding Best Practices","heading":"If you need to clip with a complex collection, use clipToCollection()","text":"really need clip something, geometries want use clipping collection, use clipToCollection():use featureCollection.geometry() featureCollection.union() \nlarge /complex collections, can memory intensive.","code":"\necoregions <- ee$FeatureCollection('RESOLVE/ECOREGIONS/2017')\nimage <- ee$Image('JAXA/ALOS/AW3D30_V1_1')\ncomplexCollection <- ecoregions$\n  filter(\n    ee$Filter$eq(\n      'BIOME_NAME',\n      'Tropical & Subtropical Moist Broadleaf Forests'\n    )\n  )\nMap$addLayer(complexCollection, {}, 'complexCollection')\nclippedTheRightWay <- image$select('AVE')$\n  clipToCollection(complexCollection)\nMap$addLayer(clippedTheRightWay, {}, 'clippedTheRightWay', FALSE)"},{"path":"coding-best-practices.html","id":"dont-use-a-complex-collection-as-the-region-for-a-reducer","chapter":"Coding Best Practices","heading":"Don’t use a complex collection as the region for a reducer","text":"need spatial reduction reducer pools inputs multiple regions FeatureCollection, don’t supply featureCollection.geometry() geometry input reducer. Instead, use clipToCollection() region large enough encompass bounds collection. example:","code":"\necoregions <- ee$FeatureCollection('RESOLVE/ECOREGIONS/2017')\nimage <- ee$Image('JAXA/ALOS/AW3D30_V1_1')\ncomplexCollection <- ecoregions$filter(\n  ee$Filter$eq('BIOME_NAME', 'Tropical & Subtropical Moist Broadleaf Forests')\n)\nclippedTheRightWay <- image$select('AVE')$clipToCollection(complexCollection)\nMap$addLayer(clippedTheRightWay, {}, 'clippedTheRightWay')\nreduction <- clippedTheRightWay$reduceRegion(\n  reducer = ee$Reducer$mean(),\n  geometry = ee$Geometry$Rectangle(\n    coords = c(-179.9, -50, 179.9, 50),  # Almost global.\n    geodesic = FALSE\n  ),\n  scale = 30,\n  maxPixels = 1e12\n)\nprint(reduction$getInfo()) # If this times out, export it."},{"path":"coding-best-practices.html","id":"use-a-non-zero-errormargin","chapter":"Coding Best Practices","heading":"Use a non-zero errorMargin","text":"possibly expensive geometry operations, use largest error margin possible given required precision computation. error margin specifies maximum allowable error (meters) permitted operations geometries (e.g. reprojection). Specifying small error margin can result need densify geometries (coordinates), can memory intensive. ’s good practice specify large error margin possible computation:","code":"\necoregions <- ee$FeatureCollection(\"RESOLVE/ECOREGIONS/2017\")\ncomplexCollection <- ecoregions$limit(10)\nMap$centerObject(complexCollection)\nMap$addLayer(complexCollection)\nexpensiveOps <- complexCollection$map(function(f) {\n  f$buffer(10000, 200)$bounds(200)\n})\nMap$addLayer(expensiveOps, {}, 'expensiveOps')"},{"path":"coding-best-practices.html","id":"dont-use-a-ridiculously-small-scale-with-reducetovectors","chapter":"Coding Best Practices","heading":"Don’t use a ridiculously small scale with reduceToVectors()","text":"want convert raster vector, use appropriate scale. Specifying small scale can substantially increase computation cost. Set scale high possible give required precision. example, get polygons representing global land masses:previous example, note use non-geodesic polygon use global reductions.","code":"\netopo <- ee$Image('NOAA/NGDC/ETOPO1')\n# Approximate land boundary.\nbounds <- etopo$select(0)$gt(-100)\n# Non-geodesic polygon.\nalmostGlobal <- ee$Geometry$Polygon(\n  coords = list(\n    c(-180, -80),\n    c(180, -80),\n    c(180, 80),\n    c(-180, 80),\n    c(-180, -80)\n  ),\n  proj = \"EPSG:4326\",\n  geodesic = FALSE\n)\nMap$addLayer(almostGlobal, {}, \"almostGlobal\")\nvectors <- bounds$selfMask()$reduceToVectors(\n  reducer = ee$Reducer$countEvery(),\n  geometry = almostGlobal,\n  # Set the scale to the maximum possible given\n  # the required precision of the computation.\n  scale = 50000\n)\nMap$addLayer(vectors, {}, \"vectors\")"},{"path":"coding-best-practices.html","id":"dont-use-reducetovectors-with-reduceregions","chapter":"Coding Best Practices","heading":"Don’t use reduceToVectors() with reduceRegions()","text":"Don’t use FeatureCollection returned reduceToVectors() input reduceRegions(). Instead, add bands want reduce calling reduceToVectors():Note ways reducing pixels one image within zones another include reduceConnectedCommponents() /grouping reducers.","code":"\netopo <- ee$Image('NOAA/NGDC/ETOPO1')\nmod11a1 <- ee$ImageCollection('MODIS/006/MOD11A1')\n# Approximate land boundary.\nbounds <- etopo$select(0)$gt(-100)\n# Non-geodesic polygon.\nalmostGlobal <- ee$Geometry$Polygon(\n  coords = list(c(-180, -80), c(180, -80), c(180, 80), c(-180, 80), c(-180, -80)),\n  proj = \"EPSG:4326\",\n  geodesic = FALSE\n)\nlst <- mod11a1$first()$select(0)\nmeans <- bounds$selfMask()$addBands(lst)$reduceToVectors(\n  reducer = ee$Reducer$mean(),\n  geometry = almostGlobal,\n  scale = 1000,\n  maxPixels = 1e10\n)\nprint(means$limit(10)$getInfo())"},{"path":"coding-best-practices.html","id":"use-fastdistancetransform-for-neighborhood-operations","chapter":"Coding Best Practices","heading":"Use fastDistanceTransform() for neighborhood operations","text":"convolution operations, fastDistanceTransform() may efficient reduceNeighborhood() convolve(). example, erosion /dilation binary inputs:","code":"\naw3d30 <- ee$Image(\"JAXA/ALOS/AW3D30_V1_1\")\n# Make a simple binary layer from a threshold on elevation.\nmask <- aw3d30$select(\"AVE\")$gt(300)\nMap$setCenter(-122.0703, 37.3872, 11)\nMap$addLayer(mask, {}, \"mask\")\n# Distance in pixel units.\ndistance <- mask$fastDistanceTransform()$sqrt()\n# Threshold on distance (three pixels) for a dilation.\ndilation <- distance$lt(3)\nMap$addLayer(dilation, {}, \"dilation\")\n# Do the reverse for an erosion.\nnotDistance <- mask$Not()$fastDistanceTransform()$sqrt()\nerosion <- notDistance$gt(3)\nMap$addLayer(erosion, {}, 'erosion')"},{"path":"coding-best-practices.html","id":"use-the-optimizations-in-reduceneighborhood","chapter":"Coding Best Practices","heading":"Use the optimizations in reduceNeighborhood()","text":"need perform convolution can’t use fastDistanceTransform(), use optimizations reduceNeighborhood().","code":"\nl8raw <- ee$ImageCollection('LANDSAT/LC08/C01/T1_RT')\ncomposite <- ee$Algorithms$Landsat$simpleComposite(l8raw)\nbands <- c('B4', 'B3', 'B2')\noptimizedConvolution <- composite$select(bands)$reduceNeighborhood(\n  reducer = ee$Reducer$mean(),\n  kernel = ee$Kernel$square(3),\n  optimization = \"boxcar\" # Suitable optimization for mean.\n)$rename(bands)\nviz <- list(bands = bands, min = 0, max = 72)\nMap$setCenter(-122.0703, 37.3872, 11)\nMap$addLayer(composite, viz, \"composite\") +\nMap$addLayer(optimizedConvolution, viz, \"optimizedConvolution\")"},{"path":"coding-best-practices.html","id":"dont-sample-more-data-than-you-need","chapter":"Coding Best Practices","heading":"Don’t sample more data than you need","text":"Resist urge increase training dataset size unnecessarily. Although increasing amount training data effective machine learning strategy circumstances, can also increase computational cost corresponding increase accuracy. (understanding increase training dataset size, see reference). following example demonstrates requesting much training data can result dreaded “Computed value large” error:\n  Bad — Don’t sample much data!better approach start moderate amount data tune hyperparameters classifier determine can achieve desired accuracy:\n  Good — Tune hyperparameters.example, classifier already accurate, ’s much tuning . might want choose smallest tree possible (.e. largest minLeafPopulation) still required accuracy.","code":"\nl8raw <- ee$ImageCollection('LANDSAT/LC08/C01/T1_RT')\ncomposite <- ee$Algorithms$Landsat$simpleComposite(l8raw)\nlabels <- ee$FeatureCollection('projects/google/demo_landcover_labels')\n# No!  Not necessary.  Don't do this:\nlabels <- labels$map(function(f){f$buffer(100000, 1000)})\nbands <- c('B2', 'B3', 'B4', 'B5', 'B6', 'B7')\ntraining <- composite$select(bands)$sampleRegions(\n  collection = labels,\n  properties = list(\"landcover\"),\n  scale = 30\n)\nclassifier <- ee$Classifier$smileCart()$train(\n  features = training,\n  classProperty = \"landcover\",\n  inputProperties = bands\n)\nprint(classifier$explain()) # Computed value is too large\nl8raw <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_RT\")\ncomposite <- ee$Algorithms$Landsat$simpleComposite(l8raw)\nlabels <- ee$FeatureCollection(\"projects/google/demo_landcover_labels\")\n# Increase the data a little bit, possibly introducing noise.\nlabels <- labels$map(function(f) {f$buffer(100, 10)})\nbands <- c('B2', 'B3', 'B4', 'B5', 'B6', 'B7')\ndata <- composite$select(bands)$sampleRegions(\n  collection = labels,\n  properties = list(\"landcover\"),\n  scale = 30\n)\n# Add a column of uniform random numbers called 'random'.\ndata <- data$randomColumn()\n# Partition into training and testing.\ntraining <- data$filter(ee$Filter$lt(\"random\", 0.5))\ntesting <- data$filter(ee$Filter$gte(\"random\", 0.5))\n# Tune the minLeafPopulation parameter.\nminLeafPops <- ee$List$sequence(1, 10)\naccuracies <- minLeafPops$map(\n  ee_utils_pyfunc(\n    function(p) {\n      classifier <- ee$Classifier$smileCart(minLeafPopulation = p)$\n        train(\n          features = training,\n          classProperty = \"landcover\",\n          inputProperties = bands\n        )\n      \n      testing$\n        classify(classifier)$\n        errorMatrix(\"landcover\", \"classification\")$\n        accuracy()\n    }\n  )\n)\nminLeafPopulation_array <- accuracies$getInfo()\nplot(\n  x = minLeafPopulation_array,\n  type = \"b\", \n  col = \"blue\",\n  lwd = 2,\n  ylab = \"accuracy\",\n  xlim = c(0,10),\n  xlab = \"value\",\n  main = \"Hyperparameter tunning (minLeafPopulation)\"\n)"},{"path":"coding-best-practices.html","id":"export-intermediate-results","chapter":"Coding Best Practices","heading":"Export intermediate results","text":"Suppose objective take samples relatively complex computed image. often efficient Export image toAsset(), load exported image, sample. example:example, note imagery exported float. Don’t export double precision unless absolutely necessary.export completed, reload asset proceed sampling . Note small sample small test area run first, debugging. shown succeed, take larger sample export . large samples typically need exported. expect samples available interactively (example print()) useable (example input classifier) without exporting first.","code":"\nimage <- ee$Image('UMD/hansen/global_forest_change_2018_v1_6')\ngeometry <- ee$Geometry$Polygon(\n  coords = list(\n    c(-76.64069800085349, 5.511777325802095),\n    c(-76.64069800085349, -20.483938229362376),\n    c(-35.15632300085349, -20.483938229362376),\n    c(-35.15632300085349, 5.511777325802095)\n  ),\n  proj =  \"EPSG:4326\",\n  geodesic =  FALSE\n)\ntestRegion <- ee$Geometry$Polygon(\n  coords = list(\n    c(-48.86726050085349, -3.0475996402515717),\n    c(-48.86726050085349, -3.9248707849303295),\n    c(-47.46101050085349, -3.9248707849303295),\n    c(-47.46101050085349, -3.0475996402515717)\n  ),\n  proj = \"EPSG:4326\",\n  geodesic = FALSE\n)\n# Forest loss in 2016, to stratify a sample.\nloss <- image$select(\"lossyear\")\nloss16 <- loss$eq(16)$rename(\"loss16\")\n# Cloud masking function.\nmaskL8sr <- function(image) {\n  cloudShadowBitMask <- bitwShiftL(1, 3)\n  cloudsBitMask <- bitwShiftL(1, 5)\n  qa <- image$select('pixel_qa')\n  mask <- qa$bitwiseAnd(cloudShadowBitMask)$eq(0)$\n    And(qa$bitwiseAnd(cloudsBitMask)$eq(0))\n  \n  image$updateMask(mask)$\n    divide(10000)$\n    select(\"B[0-9]*\")$\n    copyProperties(image, list(\"system:time_start\"))\n}\ncollection <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_SR\")$map(maskL8sr)\n# Create two annual cloud-free composites.\ncomposite1 <- collection$filterDate('2015-01-01', '2015-12-31')$median()\ncomposite2 <- collection$filterDate('2017-01-01', '2017-12-31')$median()\n# We want a strtatified sample of this stack.\nstack <- composite1$addBands(composite2)$float() # Export the smallest size possible.\n# Export the image.  This block is commented because the export is complete.\n# link <- \"0b8023b0af6c1b0ac7b5be649b54db06\"\n# desc <- paste0(ee_get_assethome(), \"/Logistic_regression_stack_\", link)\n# \n# #ee_image_info(stack)\n# task <- ee_image_to_asset(\n#   image = stack,\n#   description = link,\n#   assetId = desc,\n#   region = geometry,\n#   scale = 100,\n#   maxPixels = 1e10\n# )\n  \n# Load the exported image.\nexportedStack <- ee$Image(\n  \"projects/google/Logistic_regression_stack_0b8023b0af6c1b0ac7b5be649b54db06\"\n)\n# Take a very small sample first, to debug.\ntestSample <- exportedStack$addBands(loss16)$stratifiedSample(\n  numPoints = 1,\n  classBand = \"loss16\",\n  region = testRegion,\n  scale = 30,\n  geometries = TRUE\n)\nprint(testSample$getInfo()) # Check this in the console.\n# Take a large sample.\nsample <- exportedStack$addBands(loss16)$stratifiedSample(\n  numPoints = 10000,\n  classBand = \"loss16\",\n  region = geometry,\n  scale = 30\n)\n# Export the large sample..."},{"path":"coding-best-practices.html","id":"join-vs.-map-filter","chapter":"Coding Best Practices","heading":"Join vs. map-filter","text":"Suppose want join collections based time, location metadata property. Generally, efficiently accomplished join. following example spatio-temporal join Landsat 8 Sentinel-2 collections:Although try join first (Export needed), occasionally filter() within map() can also effective, particularly large collections.","code":"\ns2 <- ee$ImageCollection(\"COPERNICUS/S2\")$\n  filterBounds(ee$Geometry$Point(c(-2.0205, 48.647)))\nl8 <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_SR\")\njoined <- ee$Join$saveAll(\"landsat\")$apply(\n  primary = s2,\n  secondary = l8,\n  condition = ee$Filter$And(\n    ee$Filter$maxDifference(\n      difference = 1000 * 60 * 60 * 24, # One day in milliseconds\n      leftField = \"system:time_start\",\n      rightField = \"system:time_start\"\n    ),\n    ee$Filter$intersects(\n      leftField = \".geo\",\n      rightField = \".geo\"\n    )\n  )\n)\nprint(joined$first()$getInfo())\ns2 <- ee$ImageCollection(\"COPERNICUS/S2\")$\n  filterBounds(ee$Geometry$Point(c(-2.0205, 48.647)))\nl8 <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_SR\")\nmappedFilter <- s2$map(function(image) {\n  date <- image$date()\n  landsat <- l8$\n    filterBounds(image$geometry())$\n    filterDate(date$advance(-1, \"day\"), date$advance(1, \"day\"))\n    # Return the input image with matching scenes in a property.\n  image$set(\n    list(\n      landsat = landsat,\n      size = landsat$size()\n    )\n  )\n})$filter(ee$Filter$gt(\"size\", 0))\nprint(mappedFilter$first()$getInfo())"},{"path":"coding-best-practices.html","id":"reduceregion-vs.-reduceregions-vs.-for-loop","chapter":"Coding Best Practices","heading":"reduceRegion() vs. reduceRegions() vs. for-loop","text":"Calling reduceRegions() large complex\nFeatureCollection input may result dreaded “Computed value\nlarge” error. One potential solution map reduceRegion()\nFeatureCollection instead. Another potential solution \nuse (gasp) -loop. Although strongly discouraged Earth\nEngine described , , reduceRegion() can implemented -loop perform large reductions.Suppose objective obtain mean pixels (statistic) feature FeatureCollection image ImageCollection. following example compares three approaches previously described:Note first() thing collection printed, debugging purposes. expect complete result available interactively: ’ll need Export. Also note -loops used extreme caution last resort. Finally, -loop requires manually obtaining size input collection hardcoding appropriate locations. sounds unclear , don’t use -loop.","code":"\n# Table of countries.\ncountriesTable <- ee$FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\")\n# Time series of images.\nmod13a1 <- ee$ImageCollection(\"MODIS/006/MOD13A1\")\n# MODIS vegetation indices (always use the most recent version).\nband <- \"NDVI\"\nimagery <- mod13a1$select(band)\n# Option 1: reduceRegions()\ntestTable <- countriesTable$limit(1) # Do this outside map()s and loops.\ndata <- imagery$map(function(image) {\n  image$reduceRegions(\n    collection = testTable,\n    reducer = ee$Reducer$mean(),\n    scale = 500\n  )$map(function(f) {\n    f$set(\n      list(\n        time = image$date()$millis(),\n        date = image$date()$format()\n      )\n    )\n  })\n})$flatten()\nprint(data$first()$getInfo())\n# Option 2: mapped reduceRegion()\ndata <- countriesTable$map(function(feature) {\n  imagery$map(\n    function(image) {\n      ee$Feature(\n        feature$geometry()$centroid(100),\n        image$reduceRegion(\n          reducer = ee$Reducer$mean(),\n          geometry = feature$geometry(),\n          scale = 500\n        )\n      )$set(\n        list(\n          time = image$date()$millis(),\n          date = image$date()$format()\n        )\n      )$copyProperties(feature)\n    }\n  )\n})$flatten()\nprint(data$first()$getInfo())\n# Option 3: for-loop (WATCH OUT!)\nsize <- countriesTable$size()\nprint(size$getInfo()) # 312\ncountriesList <- countriesTable$toList(1) # Adjust size.\ndata <- ee$FeatureCollection(list()) # Empty table.\nfor (j in (seq_len(countriesList$length()$getInfo()) - 1)) {\n  feature <- ee$Feature(countriesList$get(j))\n  # Convert ImageCollection > FeatureCollection\n  fc <- ee$FeatureCollection(\n    imagery$map(\n      function(image) {\n        ee$Feature(\n          feature$geometry()$centroid(100),\n          image$reduceRegion(\n            reducer = ee$Reducer$mean(),\n            geometry = feature$geometry(),\n            scale = 500\n          )\n        )$set(\n          list(\n            time = image$date()$millis(),\n            date = image$date()$format()\n          )\n        )$copyProperties(feature)\n      }\n    )\n  )\n  data <- data$merge(fc)\n}\nprint(data$first()$getInfo())"},{"path":"coding-best-practices.html","id":"use-forward-differencing-for-neighbors-in-time","chapter":"Coding Best Practices","heading":"Use forward differencing for neighbors in time","text":"Suppose temporally sorted ImageCollection (.e. time series) want compare image previous (next) image. Rather use iterate() purpose, may efficient use array-based forward differencing. following example uses method de-duplicate Sentinel-2 collection, duplicates defined images day year:","code":"\nsentinel2 <- ee$ImageCollection(\"COPERNICUS/S2\")\nsf <- ee$Geometry$Point(c(-122.47555371521855, 37.76884708376152))\ns2 <- sentinel2$\n  filterBounds(sf)$\n  filterDate(\"2018-01-01\", \"2019-12-31\")\nwithDoys <- s2$map(function(image) {\n  ndvi <- image$normalizedDifference(c(\"B4\", \"B8\"))$rename(\"ndvi\")\n  date <- image$date()\n  doy <- date$getRelative(\"day\", \"year\")\n  time <- image$metadata(\"system:time_start\")\n  doyImage <- ee$Image(doy)$\n    rename(\"doy\")$\n    int()\n  \n  ndvi$\n    addBands(doyImage)$\n    addBands(time)$\n    clip(image$geometry()) # Appropriate use of clip.\n})\narray <- withDoys$toArray()\ntimeAxis <- 0\nbandAxis <- 1\ndedup <- function(array) {\n  time <- array$arraySlice(bandAxis, -1)\n  sorted <- array$arraySort(time)\n  doy <- sorted$arraySlice(bandAxis, -2, -1)\n  left <- doy$arraySlice(timeAxis, 1)\n  right <- doy$arraySlice(timeAxis, 0, -1)\n  mask <- ee$Image(ee$Array(list(list(1))))$\n    arrayCat(left$neq(right), timeAxis)\n  array$arrayMask(mask)\n}\ndeduped <- dedup(array)\n# Inspect these outputs to confirm that duplicates have been removed.\nprint(array$reduceRegion(\"first\", sf, 10)$getInfo())\nprint(deduped$reduceRegion(\"first\", sf, 10)$getInfo())"},{"path":"debugging.html","id":"debugging","chapter":"Debugging","heading":"Debugging","text":"Earth Engine unlike traditional image processing, GIS desktop software used geospatial data analysis. Algorithms create Earth Engine run Google cloud, distributed many computers. Debugging can challenging errors can occur either client-side JavaScript code server-side execution coded instructions, result scaling problems well syntactic logical errors. bits program running somewhere cloud available inspect, unless ask . document presents debugging strategies, tools solutions help resolve common errors debug Earth Engine scripts.","code":""},{"path":"debugging.html","id":"client-side-errors","chapter":"Debugging","heading":"Client-side errors","text":"Despite syntactically correct JavaScript, may errors associated consistency logic script. following examples demonstrate errors using variable method don’t exist:\n  Error — code doesn’t work!first error informs bandNames variable defined scope ’s referenced. solution, set variable, provide list argument bands parameter. second error demonstrates happens non-existent selfAnalyze() function called. Since isn’t real method images, error tells ’s function. cases, error descriptive problem.","code":"\n# Load a Sentinel-2 image.\nimage <- ee$Image('USGS/SRTMGL1_003')\n\ndisplay <- image$visualize(list(bands = bandNames, min = 0, max = 9000))\n# Error in py_resolve_dots(list(...)) : object 'bandNames' not found\n\n# Error: image.selfAnalyze is not a function\nsilly <- image$selfAnalyze()\n# Error in py_get_attr_impl(x, name, silent) : AttributeError: 'Image' object has no attribute 'selfAnalyze'"},{"path":"debugging.html","id":"casting","chapter":"Debugging","heading":"Casting","text":"“...function” error may result Earth Engine knowing type variable. Common manifestations problem result :something object returned first() (type elements collection unknown).something object returned first() (type elements collection unknown).something object returned get() (type element stored property unknown).something object returned get() (type element stored property unknown).something function argument (function) type argument unknown.\nexample former:something function argument (function) type argument unknown.\nexample former:\n  Error — code doesn’t work!solution cases cast object unknown type constructor known type. Continuing previous example, solution cast ee$Image:\n  Good — Use cast!(’s worth noting can safely call method Element ’s Earth Engine thinks ).","code":"\ncollection <- ee$ImageCollection('MODIS/051/MOD44B')\n\ndate <- collection$first()$date()\n# Error: collection$first(...).date is not a function\ndate <- ee$Image(collection$first())$date()"},{"path":"debugging.html","id":"avoid-mixing-client-and-server-functions","chapter":"Debugging","heading":"Avoid mixing client and server functions","text":"following example less obvious:\n  Error — code doesn’t wantSupposing author code intended add 2 every pixel image, right way . Specifically, code wrongly mixes server-side object (image) client-side JavaScript operator (+). results may surprising. first case, printing nonsense, JavaScript perform requested operation (+) converting image 2 strings, concatenating . resultant string unintended. second case, adding nonsense map, cryptic g.eeObject.name function error displayed object added map, nonsense, string, EE object. avoid possibly unintended results uninformative errors, don’t mix server objects functions JavaScript objects, primitives functions. solution example use server function:\n  Good — use server function!detailed explanation client vs. server Earth Engine, see page /tutorial.","code":"\n# Don't mix EE objects and JavaScript objects:\nimage <- ee$Image('USGS/SRTMGL1_003')\nnonsense <- image + 2\n\n# You can print this, but it's not what you were hoping for.\nprint(nonsense)\n\n# Error: g.eeObject.name is not a function\nMap$addLayer(nonsense)\nMap$addLayer(image$add(2))"},{"path":"debugging.html","id":"server-side-errors","chapter":"Debugging","heading":"Server-side errors","text":"Despite logical consistency client JavaScript, may bugs become apparent run time server. following example demonstrates happens trying get band doesn’t exist:\n  Error — code doesn’t work!example, error informs band named nonBand. possibly obvious solution specify band name exist. can discover band names printing image inspecting console, printing list band names returned image.bandNames().","code":"\n# Load a Sentinel-2 image.\ns2image <- ee$Image('COPERNICUS/S2/20160625T100617_20160625T170310_T33UVR')\n\nee_print(s2image$select('nonBand'))\n# Error in py_call_impl(callable, dots$args, dots$keywords) : EEException: Image.select: Pattern 'nonBand' did not match any bands."},{"path":"debugging.html","id":"immutability","chapter":"Debugging","heading":"Immutability","text":"Server-side objects create Earth Engine immutable. (ee$Object server side Object). means want make change object, save changed state new variable. example, won’t work set property Sentinel-2 image:\n  Error — code doesn’t want!example, s2image$set() returns copy image new property, image stored s2image variable unchanged. need save image returned s2image$set() new variable. example:\n  Good — capture result variable!","code":"\ns2image <- ee$Image('COPERNICUS/S2/20160625T100617_20160625T170310_T33UVR')\ns2image$set('myProperty', 'This image is not assigned to a variable');\n\n# This will not result in an error, but will not find 'myProperty'.\nprint(s2image$get('myProperty')$getInfo()) # NULL\ns2image = s2image$set('myProperty', 'OK')\nprint(s2image$get('myProperty')$getInfo()) # OK"},{"path":"debugging.html","id":"mapped-functions","chapter":"Debugging","heading":"Mapped functions","text":"Another context client server functions don’t mix mapped functions. Specifically, operations specified mapped function run cloud, client functions print(), getInfo() method Map, Export won’t work mapped functions. example:\n  Error — code doesn’t work!somewhat cryptic error results process Earth Engine uses turn code set instructions can run Google servers. Specifically, means Earth Engine can’t find server-side function called print(), isn’t one. generally, client-side functions control structures used operate argument image passed mapped function. avoid error, avoid use client-side functions mapped functions. See page learn distinction client server functions.Mapped functions additional requirements, must met avoid errors. example, mapped functions must return something. Although Code Editor detects problem issues error, specific mapped functions run server:\n  Error — code doesn’t work!possibly obvious solution return something. can’t return just type thing. Specifically, functions mapped ImageCollection FeatureCollection must return Image Feature. example, can’t return date function mapped ImageCollection:\n  Error — code doesn’t work!avoid , return input image new property set. , need list dates images collection, can use aggregate_array():\n  Good — set property!","code":"\ncollection <- ee$ImageCollection('MODIS/051/MOD44B')\n\n# Error: A mapped function's arguments cannot be used in client-side operations\nbadMap3 <- collection$map(function(image) {\n  print(image$getInfo())\n  return(image)\n})\ncollection <- ee$ImageCollection('MODIS/051/MOD44B')\n\n# Error: User-defined methods must return a value.\nbadMap1 <- collection$map(function(image) {\n  # Do nothing.\n})\ncollection <- ee$ImageCollection('MODIS/006/MOD44B')\n\nbadMap2 <- collection$map(function(image) {\n  return(image$date())\n})\n\nprint(badMap2$getInfo())\n# Error: Collection.map: A mapped algorithm must return a Feature or Image.\ncollection <- ee$ImageCollection('MODIS/006/MOD44B')\n\nokMap2 <- collection$map(function(image) {\n  image$set('date', image$date())\n})\nee_print(okMap2)\n\n# Get a list of the dates.\ndatesList <- okMap2$aggregate_array('date')\ndatesList$getInfo()"},{"path":"earth-engine-in-rstudio.html","id":"earth-engine-in-rstudio","chapter":"Earth Engine in Rstudio","heading":"Earth Engine in Rstudio","text":"section requires next libraries:RStudio popular R-based integrated development environment (IDE). includes console, syntax-highlighting editor supports direct code execution, well tools plotting, history, debugging, workspace management. combining Rstudio rgee, users can quickly effortlessly construct complex geospatial processes. following features available:R code editor.Map display visualizing geospatial datasets.API reference documentation (Using ee_help addin).Git-based Script Manager (Git tab).Console output (Console tab).Task Manager handle long-running queries using ee_manage_* functions.Search data archive saved scripts.Geometry drawing tools, using rgee **mapedit**.","code":"\nlibrary(rgee)\n\nee_Initialize()"},{"path":"earth-engine-in-rstudio.html","id":"gee-api-reference-documentation","chapter":"Earth Engine in Rstudio","heading":"GEE API reference documentation","text":"GEE API quite extensive users can easily get overwhelmed. code effectively, users need \ntool allows browse documentation without leaving Rstudio IDE. Aware situation, **ee_help** function added rgee \ndisplay GEE documentation R-style format.\nee_help really helpful, single keystroke, similar Rstudio’s helper (just pressing F1!), \nmake process even easier. functionality implemented rgee \nRstudio addin. activate feature, go\nTools -> Modify keyword shortcuts.\n(1) type browser ee_help, (2) click Shortcut column, finally (3) press F3 another desired keyword.\nterminating Rstudio session now able display documentation just \nsingle keystroke (just pressing F3!).","code":"\nee$Image()$geometry()$centroid %>% ee_help()\nee$Image()$geometry() %>% ee_help()\nee$Image %>% ee_help()\nee$Image %>% ee_help(browser = TRUE)"},{"path":"r-and-python-requirements.html","id":"r-and-python-requirements","chapter":"R and Python requirements","heading":"R and Python requirements","text":"rgee requires R Python third-party packages, making installation \nlittle tricky. Installation R packages simple thanks Rtools.Install CRAN :Install development versions github withHowever, certain issues may arise users try set Python environment. \nnutshell, rgee Python requirements :Python environment (PYENV).Install PYENV: numpy earthengine-apiThe ee_install built-function \nbest way set previous Python prerequisite. short, performs following tasks: (1) create Python environment, (2) Set environment variable named “EARTHENGINE PYTHON” saves Python interpreter path global .Renviron (let rgee search next time try initialize Earth Engine), (3) install package requirements previously created environment. Users want utilize Python environment may alternatively run:Note PYENV set must Earth Engine Python API numpy installed. use miniconda/anaconda mandatory Windows users, Linux MacOS users also use virtualenv. See reticulate documentation details. Another option, accessible exclusively MacOS Linux, simply modify Python PATH variable:However, rgee::ee_install_upgrade reticulate::py_install work set Python ENV. R session may need terminated installation process.","code":"\ninstall.packages(\"rgee\")\nlibrary(remotes)\ninstall_github(\"r-spatial/rgee\")\n# IMPORTANT: Change 'py_path' argument according to your own Python PATH\n## For Anaconda users - Windows OS\n## Anaconda users must need to run “where anaconda” in console.\nwin_py_path = paste0(\n    \"C:/Users/UNICORN/AppData/Local/Programs/Python/\",\n    \"Python37/python.exe\"\n)\nee_install_set_pyenv(\n  py_path = win_py_path,\n  py_env = NULL # Change it for your own Python ENV\n)\n\n## For Anaconda users - MacOS users\n## Anaconda users must need to run “where anaconda” in console.\nee_install_set_pyenv(\n  py_path = \"/Users/UNICORN/opt/anaconda3/bin/python\",\n  py_env = NULL # Change it for your own Python ENV\n)\n\n## For Miniconda users - Windows OS\nwin_py_path = paste0(\n    \"C:/Users/UNICORN/AppData/Local/r-miniconda/envs/rgee/\",\n    \"python.exe\"\n)\nee_install_set_pyenv(\n  py_path = win_py_path,\n  py_env = \"rgee\" # Change it for your own Python ENV\n)\n\n## For Miniconda users - Linux/MacOS users\nunix_py_path = paste0(\n    \"/home/UNICORN/.local/share/r-miniconda/envs/\",\n    \"rgee/bin/python3\"\n)\nee_install_set_pyenv(\n  py_path = unix_py_path,\n  py_env = \"rgee\" # Change it for your own Python ENV\n)\n\n## For virtualenv users - Linux/MacOS users\nee_install_set_pyenv(\n  py_path = \"/home/UNICORN/.virtualenvs/rgee/bin/python\",\n  py_env = \"rgee\" # Change it for your own Python ENV\n)\n\n## For Python root user - Linux/MacOS users\nee_install_set_pyenv(\n  py_path = \"/usr/bin/python3\",\n  py_env = NULL, \n  Renviron = \"global\" # Save ENV variables in the global .Renv file\n)\n\nee_install_set_pyenv(\n  py_path = \"/usr/bin/python3\",\n  py_env = NULL, \n  Renviron = \"local\" # Save ENV variables in a local .Renv file\n)\nrgee::ee_install_set_pyenv(\n  py_path = \"/usr/bin/python3\",\n  py_env = NULL\n)"},{"path":"r-and-python-requirements.html","id":"rgee-initialization","chapter":"R and Python requirements","heading":"rgee Initialization","text":"installing R Python requirements, users can now initialize Earth Engine. Take account R, contrast Javascript Python, supports three distinct Google APIs:Google Earth EngineGoogle DriveGoogle Cloud StorageThe Google Drive Google Cloud Storage APIs help seamlessly transfer finished EE task results local environment. Use following instructions establish GEE account conjunction Google Drive Google Cloud Storage:verifying Google account granting permission, led authentication token. token copied pasted R terminal. Please consider Google Cloud Storage credential must associated services account key. details, see rgee vignette. verification process necessary ; , rgee keeps credentials system .","code":"\nlibrary(rgee)\n\n# Initialize just Earth Engine\nee_Initialize()\n\n# Initialize Earth Engine and GD\nee_Initialize(drive = TRUE)\n\n# Initialize Earth Engine and GCS\nee_Initialize(gcs = TRUE)\n\n# Initialize Earth Engine, GD and GCS\nee_Initialize(drive = TRUE, gcs = TRUE)"},{"path":"sync-gcs-and-rgee.html","id":"sync-gcs-and-rgee","chapter":"sync GCS and rgee","heading":"sync GCS and rgee","text":"tutorial explains integrate rgee Google Cloud Storage (GCS) step step. rgee, GCS used intermediary container massive downloading/uploading files flexible Google Drive. today’s date (December 2021), GCS free uses less 0.5 GB.","code":""},{"path":"sync-gcs-and-rgee.html","id":"create-a-service-account-key","chapter":"sync GCS and rgee","heading":"1. Create a Service Account Key","text":"bulk GCS & rgee sync issues related creation service accounts key (SaK) enough privileges \nwriting/reading GCS buckets. order create, configure locally store SaK, perform follow:","code":""},{"path":"sync-gcs-and-rgee.html","id":"create-a-google-cloud-platform-gcp-account","chapter":"sync GCS and rgee","heading":"Create a Google Cloud Platform (GCP) account","text":"Go https://cloud.google.com/, create account. add address credit card.","code":""},{"path":"sync-gcs-and-rgee.html","id":"create-a-new-project","chapter":"sync GCS and rgee","heading":"Create a new project","text":"Go console.first time using GCP, assigned project named first project. want create new project (OPTIONAL). First, click ‘first project’ top blue bar, just right ‘Google Cloud Platform’, ‘NEW PROJECT’.Create project desired name.","code":""},{"path":"sync-gcs-and-rgee.html","id":"activate-gcs-api","chapter":"sync GCS and rgee","heading":"Activate GCS API","text":"default, GCS API activated. Make sure typing “Cloud Storage API” search browser.Click ‘Enable APIs Services’ (API turned ). green checkmark image means\nAPI activated!","code":""},{"path":"sync-gcs-and-rgee.html","id":"set-up-a-service-account","chapter":"sync GCS and rgee","heading":"Set up a service account","text":"Now going create service account. service account used ‘sign ’ applications require one many GCP services. case, rgee (app) needs account GCS admin privileges. create service account, search ‘Cloud Storage’ browser, click ‘Cloud Storage’ product.Click ‘settings’.Click ‘INTEROPERABILITY’, click ‘CREATE KEY SERVICE ACCOUNT’.Click ‘CREATE NEW ACCOUNT’.Set name (1), define Storage Admin (DON’T FORGET STEP!!) role (3).","code":""},{"path":"sync-gcs-and-rgee.html","id":"create-and-download-a-sak-as-a-json-file.","chapter":"sync GCS and rgee","heading":"Create and download a SaK as a json file.","text":"create service account, download Service account Key use GCS outside Google Cloud Platform console. SaK just JSON file public/private RSA keys. First, click small edit icon bottom right (three horizontal lines). , go API & Services click credentials.next page, click service account name.\n, select JSON format, click ‘create’.\nprompt save file window. Save file hard drive. can change name something memorable like (keep “.json” extension). Also, please take note stored . Now done Google Cloud Console can finally start working RStudio.","code":""},{"path":"sync-gcs-and-rgee.html","id":"copy-the-sak-in-your-system","chapter":"sync GCS and rgee","heading":"2. Copy the SaK in your system","text":"rgee v.1.2.9000 added ee_utils_sak_copy ee_utils_sak_validate help validate store SaK. Please run follow properly set SaK system.ee_utils_sak_validate evaluate rgee SaK can: (1) create buckets, (2) write objects, (3) read objects, (4) connect GEE GCS. retrieve error, ee_Initialize(..., gcs = TRUE) work like charm!. next step create GCS bucket. Consider bucket name set must globally unique. words, two buckets can exist name Google Cloud Storage.","code":"\n# remotes::install_github(\"r-spatial/rgee\") Install rgee v.1.3\nlibrary(rgee)\nee_Initialize(\"csaybar\")\nSaK_file <- \"/home/csaybar/Downloads/SaK_rgee.json\" # PUT HERE THE FULLNAME OF YOUR SAK.\n# Assign the SaK to a EE user.\nee_utils_sak_copy(\n  sakfile =  SaK_file,\n  users = c(\"csaybar\", \"ryali93\") # Unlike GD, we can use the same SaK for multiple users.\n)\n# Validate your SaK\nee_utils_sak_validate()\nlibrary(rgee)\nlibrary(jsonlite)\nlibrary(googleCloudStorageR)\nee_Initialize(\"csaybar\", gcs = TRUE)\n# Create your own container\nproject_id <- ee_get_earthengine_path() %>% \n  list.files(., \"\\\\.json$\", full.names = TRUE) %>% \n  jsonlite::read_json() %>% \n  '$'(project_id) # Get the Project ID\ngoogleCloudStorageR::gcs_create_bucket(\"CHOOSE_A_BUCKET_NAME\", projectId = project_id)"},{"path":"sync-gcs-and-rgee.html","id":"error-cannot-insert-legacy-acl-for-an-object-when-uniform-bucket-level-access-is-enabled","chapter":"sync GCS and rgee","heading":"3. ERROR: Cannot insert legacy ACL for an object when uniform bucket-level access is enabled","text":"common issue related control access buckets. GCS offers two systems granting users permission access buckets objects: IAM (recommended, used Google Cloud services) Access Control Lists (ACL) (legacy access control system, available GCS).use Google Cloud Platform console create bucket, use Uniform access (IAM used alone manage permissions) default.contrary use googleCloudStorageR::gcs_create_bucket, use fine-grained access (IAM ACLs manage permissions).important?. important, create bucket using first option error message arise: “insert legacy ACL object uniform bucket-level access enabled. Read https://cloud.google.com/storage/docs/uniform-bucket-level-access”.happens due googleCloudStorageaR default expects buckets created fine-grained access (ACL support, see cloudyr/googleCloudStorageR#111).\navoid issue, rgee v.1.3 opt change default predefinedAcl argument ‘private’ ‘bucketLevel’. simple change avoid users dealing access control issues. However, reason user needs change access control policy (maybe reduce data exposure), rgee v.1.2.0 rgee GCS functions (sf_as_ee, local_to_gcs, raster_as_ee, stars_as_ee) support predefinedAcl argument (Thanks @jsocolar).","code":"\ndemo_data <- data.frame(a = 1:10, b = 1:10)\n# Bad --------------------------------------------------\ngoogleCloudStorageR::gcs_upload(\n  file = demo_data,\n  name = \"demo_data.csv\",\n  bucket = \"demo_0002\" # Bucket with uniform control access\n)\n#  Error: Insert legacy ACL for an object when uniform bucket-level access\n#  is enabled. Read more at https://cloud.google.com/storage/docs/uniform-bucket-level-access\n# Good -------------------------------------------------\ngoogleCloudStorageR::gcs_upload(\n  file = demo_data,\n  name = \"demo_data.csv\",\n  bucket = \"demo_0002\", # Bucket with uniform control access\n  predefinedAcl = \"bucketLevel\"\n)"},{"path":"sync-gcs-and-rgee.html","id":"error-in-earth-engine-servers-unable-to-write-to-bucket-demo_0001-permission-denied.","chapter":"sync GCS and rgee","heading":"4. ERROR in Earth Engine servers: Unable to write to bucket demo_0001 (permission denied).","text":"error arises GEE tries send exported task results EE USER enough privileges write/read bucket. occur successfully configured SaK local system?. Well, SaK ensures smooth connection local environment GCS, GEE GCS.instance, imagine access 2 Google user accounts, one personal one work (example, call David Cesar). accounts access GEE. David creates SaK sends Cesar. result action, Cesar David can work together bucket, downloading creating GCS objects (Local <-> GCS). David tries use ee_as_raster(..., via='gcs') (GEE -> GCS -> Local), GEE recognize owner bucket David allow procedure (GEE -> GCS) thanks SaK problem send information local environment (GCS -> Local). However, Cesar tries , get error passing information GEE -> GCS GEE know Cesar David SaK local system.error quite easy fix. Just go bucket Google Cloud Platform console.Click ‘PERMISSIONS’, click ‘ADD’.Finally, add Google user account EE USER. forget add ‘STORAGE ADMIN’ role!","code":"\nlibrary(rgee)\nee_Initialize(gcs = TRUE)\n# Define an image.\nimg <- ee$Image(\"LANDSAT/LC08/C01/T1_SR/LC08_038029_20180810\")$\n  select(c(\"B4\", \"B3\", \"B2\"))$\n  divide(10000)\n# Define an area of interest.\ngeometry <- ee$Geometry$Rectangle(\n  coords = c(-110.8, 44.6, -110.6, 44.7),\n  proj = \"EPSG:4326\",\n  geodesic = FALSE\n)\nimg_03 <- ee_as_raster(\n  image = img,\n  region = geometry,\n  container = \"demo_0001\",\n  via = \"gcs\",\n  scale = 1000\n)\n# ERROR in Earth Engine servers: Unable to write to bucket demo_0001 (permission denied)."},{"path":"sync-gcs-and-rgee.html","id":"conclusion","chapter":"sync GCS and rgee","heading":"5. Conclusion","text":"Setting SaK GCS can quite frustrating definitely worth !. still problems setting SaK, feel free clearly detail problem rgee issues.","code":""},{"path":"integrate-rmarkdown-and-rgee.html","id":"integrate-rmarkdown-and-rgee","chapter":"Integrate Rmarkdown and rgee","heading":"Integrate Rmarkdown and rgee","text":"","code":""},{"path":"integrate-rmarkdown-and-rgee.html","id":"the-problem","chapter":"Integrate Rmarkdown and rgee","heading":"1. The problem","text":"GEE offers --fly computation rendering EE spatial objects:However, interactive map service temporary, disappearing short period time (~ 4 hours). makes Map$addLayer unusable report generation. vignette, learn create permanent interactive map.","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\nee_Initialize()\nimg <- ee$Image$Dataset$CGIAR_SRTM90_V4\nMap$addLayer(log1p(img), list(min = 0, max = 7))"},{"path":"integrate-rmarkdown-and-rgee.html","id":"a-tentative-workaround","chapter":"Integrate Rmarkdown and rgee","heading":"2. A tentative workaround","text":"Instead using GEE API creating interactive maps, use titiler. titiler creates web map tiles dynamically based COG (STAC) resources. Since exported EE task retrieve images can return COG, just move results storage web service HTTP GET range requests.Fortunately, GCS counts feature, manage move results GCS, work already done :)","code":"GET /OBJECT_NAME HTTP/1.1\nHost: BUCKET_NAME.storage.googleapis.com\nContent-Length: 0\nAuthorization: AUTHENTICATION_STRING\nRange: bytes=BYTE_RANGE\nIf-Match: ENTITY_TAG\nIf-Modified-Since: DATE\nIf-None-Match: ENTITY_TAG\nIf-Unmodified-Since: DATE"},{"path":"integrate-rmarkdown-and-rgee.html","id":"show-me-the-code","chapter":"Integrate Rmarkdown and rgee","heading":"3. Show me the code","text":"First, load rgee googleCloudStorageR initialize EE API. must correctly configured service account key, check tutorial “integrate Google Cloud Storage rgee”.Define study area.Select ee$Image, instance, Landsat-8 image.Move l8img EE GCS.Titiler needs resources downloadable anyone. Therefore, recommend work GCS buckets fine-grained access. way, can decide individually objects make public. hand, decide work buckets uniform access, expose entire bucket!. code makes specific object bucket public internet.Finally, use Map$addLayer display COG resource. default, Map$addLayer use open endpoint: https://api.cogeo.xyz/docs.prefer use titiler syntax, set parameter\ntitiler_viz_convert FALSE.","code":"\nlibrary(rgee)\nlibrary(googleCloudStorageR)\n# Init the EE API\nee_Initialize(\"csaybar\", gcs = TRUE)\n# Validate your SaK\n# ee_utils_sak_validate(bucket = \"rgee_examples\")\n# Define an study area\nEE_geom <- ee$Geometry$Point(c(-70.06240, -6.52077))$buffer(5000)\nl8img <- ee$ImageCollection$Dataset$LANDSAT_LC08_C02_T2_L2 %>% \n  ee$ImageCollection$filterDate('2021-06-01', '2021-12-01') %>% \n  ee$ImageCollection$filterBounds(EE_geom) %>% \n  ee$ImageCollection$first()\ngcs_l8_name  <- \"l8demo2\" # name of the image in GCS.\nBUCKET_NAME <- \"rgee_examples\" # set here your bucket name\ntask <- ee_image_to_gcs(\n  image = l8img$select(sprintf(\"SR_B%s\",1:5)),\n  region = EE_geom,\n  fileNamePrefix = gcs_l8_name,\n  timePrefix = FALSE,\n  bucket = BUCKET_NAME,\n  scale = 10,\n  formatOptions = list(cloudOptimized = TRUE) # Return a COG rather than a TIFF file.\n)\ntask$start()\nee_monitoring()\n# Make PUBLIC the GCS object \ngoogleCloudStorageR::gcs_update_object_acl(\n  object_name = paste0(gcs_l8_name, \".tif\"),\n  bucket = BUCKET_NAME,\n  entity_type = \"allUsers\"\n)\nimg_id <- sprintf(\"https://storage.googleapis.com/%s/%s.tif\", BUCKET_NAME, gcs_l8_name)\nvisParams <- list(bands=c(\"SR_B4\",\"SR_B3\",\"SR_B2\"), min = 8000, max = 20000, nodata = 0)\nMap$centerObject(img_id)\nMap$addLayer(\n  eeObject = img_id, \n  visParams = visParams,\n  name = \"My_first_COG\",\n  titiler_server = \"https://api.cogeo.xyz/\"\n)\nvisParams <- list(expression = \"B4,B3,B2\", rescale = \"8000, 20000\", resampling_method = \"cubic\")\nMap$addLayer(\n  eeObject = img_id, \n  visParams = visParams,\n  name = \"My_first_COG\",\n  titiler_server = \"https://api.cogeo.xyz/\",\n  titiler_viz_convert = FALSE\n)"},{"path":"deploy-rgee-shiny-apps.html","id":"deploy-rgee-shiny-apps","chapter":"Deploy rgee Shiny apps","heading":"Deploy rgee Shiny apps","text":"Google Earth Engine (GEE) allows users create apps three different approaches: user tokens, service accounts client-side authentication. tutorial, get focus first option.","code":""},{"path":"deploy-rgee-shiny-apps.html","id":"what-is-an-ee-user-token-eetk","chapter":"Deploy rgee Shiny apps","heading":"What is an EE user token (EEtk)?","text":"EEtk 100-character text string (OAuth2 credential) stored local system used identify authenticate users (See Figure ). words, permit connect EE Web REST API local system.rgee authentication procedure triggered internally ee_Initialize. function search ‘credentials’ file (stores EEtk) path: ~/.config/earthengine/.file exists, Oauth2 Credential object created using refresh token grant. refresh token must come Google account registered GEE Bad Request error invoked. Oauth2 Credential successfully loaded, dynamically passed EE methods (See Initialize) order realize independent calls Web REST API. realize, credentials file crucial interact EE API exist system, simply possible use rgee.","code":"\nlibrary(rgee)\nsprintf(\"%s/credentials\", dirname(rgee::ee_get_earthengine_path()))"},{"path":"deploy-rgee-shiny-apps.html","id":"deploying-a-simple-rgee-shiny-app-on-shinyapps.io","chapter":"Deploy rgee Shiny apps","heading":"Deploying a simple rgee shiny app on shinyapps.io","text":"Deploying rgee application can bit tricky, must perform following task:Install R packages.Install Python third-party packages.Set credentials file path ~/.config/earthengine/.first step automatically accomplished shinyapps.io. hand, second third steps need configure manually virtual machine. make process straightforward create shiny_rgee template.use shiny_rgee template, first download running terminal:Load rgeeApp.Rproj modify .Renviron file according personal token user information. available shinyapps profile https://www.shinyapps.io/admin/#/tokens..RenvironFinally run deploy.R file.couple minutes, app available shinyapps.io.\nSee live demo https://cesar-aybar.shinyapps.io/rgee_app_demo/.","code":"git clone https://github.com/csaybar/shiny_rgee_template.git    SHINY_ACC_NAME=\"your_account_name\"\n    TOKEN=\"a_token_you_got_from_shinyapps.io\"\n    SECRET=\"a_secret_you_recieved_fromshinyapps.io\"\n    MASTERNAME=\"name_of_the_shiny_app\"\nlibrary(reticulate)\nlibrary(rsconnect)\nlibrary(rgee)\n# 1. Create the credentials file\nee_Initialize()\n# 2. Copy credentials file to the project folder\nfile_credentials <- sprintf(\"%s/credentials\", dirname(rgee::ee_get_earthengine_path()))\nfile.copy(file_credentials, to = \".\")\n# 3. Set ShinyApps account info\n# FIRST MODIFY LOCAL .Renviron!!\nerror_on_missing_name <- function(name){\n  var <- Sys.getenv(name, unset=NA)\n  if(is.na(var)){\n    stop(paste0(\"cannot find \",name),call. = FALSE)\n  }\n  gsub(\"\\\"\", '',var)\n}\nsetAccountInfo(name   = error_on_missing_name(\"SHINY_ACC_NAME\"),\n               token  = error_on_missing_name(\"TOKEN\"),\n               secret = error_on_missing_name(\"SECRET\"))\n# 4. Run the application\ndeployApp(\n  appFiles = c(\"app.R\", \"utils.R\", \"credentials\"),\n  appTitle = \"rgee_app_demo\",\n  lint = FALSE\n)\n# 5. Delete EE credentials file\nfile.remove(\"credentials\")"},{"path":"comparing-rgee-vs-python-and-javascript.html","id":"comparing-rgee-vs-python-and-javascript","chapter":"Comparing rgee vs Python and Javascript","heading":"Comparing rgee vs Python and Javascript","text":"section requires next libraries:R, Python JavaScript APIs access server-side functionality, client-side expressions (learn client vs. server) can vary language syntax differences. Earth Engine Python API rgee share modules, classes, functions, methods. words, logic syntax (just change . $) execution time just fast. However, keep mind syntactic differences may exist certain situations. following table includes list common syntax differences ’ll encounter working R API relative Python JavaScript API.","code":"\nlibrary(rgee)\n\nee_Initialize()"},{"path":"comparing-rgee-vs-python-and-javascript.html","id":"function-definition","chapter":"Comparing rgee vs Python and Javascript","heading":"Function definition","text":"JavaScriptPythonR","code":"function myFun(arg) {\n  return arg;\n}\n\nvar myFun = function(arg) {\n  return arg;\n};def my_fun(arg):\n  return arg\nmy_fun <- function(arg){\n  return(arg)\n}"},{"path":"comparing-rgee-vs-python-and-javascript.html","id":"anonymous-function-mapping","chapter":"Comparing rgee vs Python and Javascript","heading":"Anonymous function mapping","text":"JavaScriptPythonR","code":"var foo = col.map(function(arg) {\n  return arg;\n});foo = col.map(lambda arg: arg)\nfoor <- lapply(col, function(arg) arg)"},{"path":"comparing-rgee-vs-python-and-javascript.html","id":"variable-definition","chapter":"Comparing rgee vs Python and Javascript","heading":"Variable definition","text":"JavaScriptPythonR","code":"var myVar = 'var';my_var = 'var'\nmy_var <- 'var'"},{"path":"comparing-rgee-vs-python-and-javascript.html","id":"logical-operators","chapter":"Comparing rgee vs Python and Javascript","heading":"Logical operators","text":"JavaScriptPythonR","code":"var match = such.and(that);\nvar match = such.or(that);\nvar match = such.not(that);match = such.And(that)\nmatch = such.Or(that)\nmatch = such.Not(that)\nmatch <- such$And(that)\nmatch <- such$Or(that)\nmatch <- such$Not(that)"},{"path":"comparing-rgee-vs-python-and-javascript.html","id":"multi-line-method-chain","chapter":"Comparing rgee vs Python and Javascript","heading":"Multi-line method chain","text":"JavaScriptPythonR","code":"var foo = my.really()\n              .reallyLong()\n              .methodChain();foo = (my.really()\n       .reallyLong()\n       .methodChain())\nfoo = my %>% \n  really() %>% \n  reallyLong() %>% \n  methodChain()"},{"path":"comparing-rgee-vs-python-and-javascript.html","id":"dictionary-keys","chapter":"Comparing rgee vs Python and Javascript","heading":"Dictionary keys","text":"JavaScriptPythonR","code":"var dic = {'key': value};\nvar dic = {key: value};dic = {'key': value}\ndic <- list(key = value)"},{"path":"comparing-rgee-vs-python-and-javascript.html","id":"dictionary-object-access","chapter":"Comparing rgee vs Python and Javascript","heading":"Dictionary object access","text":"JavaScriptPythonR","code":"var value = dic.key;\nvar value = dic['key'];value = dic['key']\nvalue <- dic[['key']]"},{"path":"comparing-rgee-vs-python-and-javascript.html","id":"function-argument-definition","chapter":"Comparing rgee vs Python and Javascript","heading":"Function argument definition","text":"JavaScriptPythonR","code":"// Positional arguments.\nvar foo = fun(argX, argY, argZ);\n// Keyword arguments object.\nvar foo = fun({y: argY});# Positional arguments.\nfoo = fun(arg_x, arg_y, arg_z)\n# Keyword arguments dictionary.\nfoo = fun(**{'y': arg_y})\n# Keyword arguments.\nfoo = fun(x=arg_x, z=arg_z)\n# Positional arguments.\nfoo <- fun(arg_x, arg_y, arg_z)\n\n# Keyword arguments.\nfoo <- fun(x=arg_x, z=arg_z)"},{"path":"comparing-rgee-vs-python-and-javascript.html","id":"boolean","chapter":"Comparing rgee vs Python and Javascript","heading":"Boolean","text":"JavaScriptPythonR","code":"    var t = true;\nvar f = false;t = True\nf = False\nt <- TRUE\nf <- FALSE"},{"path":"comparing-rgee-vs-python-and-javascript.html","id":"boolean-1","chapter":"Comparing rgee vs Python and Javascript","heading":"Boolean","text":"JavaScriptPythonR","code":"var na = null;na = None\nna <- NULL"},{"path":"comparing-rgee-vs-python-and-javascript.html","id":"comment","chapter":"Comparing rgee vs Python and Javascript","heading":"Comment","text":"JavaScriptPythonR","code":"//#\n#"},{"path":"extra-considerations.html","id":"extra-considerations","chapter":"Extra considerations","heading":"Extra considerations","text":"Differences R Python syntax may also cause errors certain circumstances. identified four common cases. discussed detail .","code":""},{"path":"extra-considerations.html","id":"the-map-message-error-in-list-ee-objects","chapter":"Extra considerations","heading":"1. The map message error in List EE objects","text":"issue happens map method used : (1) running reticulate version\nlower < 1.14 (please update !); (2) leading ee$List objects. instance:code perfectly valid rgee produce error. problem easily solved adding function ee_utils_pyfunc. permit wrap R functions send reticulate. Let’s see:","code":"\nmylist = ee$List$sequence(10)\nmylist$map(function(x) ee$Number(x)$add(1))\n#> Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: Evaluation error: argument \"x\" is missing, with no default.\n#> \n#> Detailed traceback: \n#>   File \"/home/aybarpc01/.virtualenvs/r-reticulate/lib/python3.7/site-packages/ee/apifunction.py\", line 205, in <lambda>\n#>     return lambda *args, **kwargs: func.call(*args, **kwargs)  # pylint: disable=unnecessary-lambda\n#>   File \"/home/aybarpc01/.virtualenvs/r-reticulate/lib/python3.7/site-packages/ee/function.py\", line 67, in call\n#>     return self.apply(self.nameArgs(args, kwargs))\n#>   File \"/home/aybarpc01/.virtualenvs/r-reticulate/lib/python3.7/site-packages/ee/function.py\", line 80, in apply\n#>     result = computedobject.ComputedObject(self, self.promoteArgs(named_args))\n#>   File \"/home/aybarpc01/.virtualenvs/r-reticulate/lib/python3.7/site-packages/ee/function.py\", line 107, in promoteArgs\n#>     promoted_args[name] = Function._promoter(args[name], spec['type'])\n#>   File \"/home/aybarpc01/.virtualenvs/r-reticulate/lib/python3.7/site-packages/ee/__init__.py\", line 242, in _Promote\n#>     return CustomFunction.create(arg, 'Object', ['Object'] * args_count)\n#>   File \"/home/aybarpc01/.virtualenvs/r-reticulate/lib/python3.7/site-packages/ee/customfunction.py\", line 121, in create\n#>     return CustomFunction(signature, func)\n#>   File \"/home/aybarpc01/.virtualenvs/r-reticulate/lib/python3.7/site-packages/ee/customfunction.py\", line 47, in __init__\n#>     self._body = body(*variables)\n#>   File \"/home/aybarpc01/R/x86_64-pc-linux-gnu-library/3.6/reticulate/python/rpytools/call.py\", line 21, in python_function\n#>     raise RuntimeError(res[kErrorKey])\nmylist = ee$List$sequence(0,10)\nmynewlist = mylist$map(\n  ee_utils_pyfunc(\n    function(x) ee$Number(x)$add(1)   \n  )\n)\nmynewlist$getInfo()\n#>  [1]  1  2  3  4  5  6  7  8  9 10 11"},{"path":"extra-considerations.html","id":"do-not-forget-the-l","chapter":"Extra considerations","heading":"2. Do not forget the L","text":"define number R, generates value double precision default.\nhappen Python since creates int value default.PythonRBut matter? Let’s explain example:PythonRUsers need take consideration arguments \nEarth Engine methods strict admit integer values. \ncreation integers R quite simple; just need add \nletter L end number employ function .integer.\ncorrect code R :","code":"type(1)\n#> <class 'int'>\nclass(1)\n#> [1] \"numeric\"ee.Initialize()\nand_bitwise = ee.Number(32).bitwiseAnd(100)\nand_bitwise.getInfo()\n#> 32and_bitwise = ee$Number(32)$bitwiseAnd(100) #caution: silent error\nand_bitwise$getInfo()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/home/aybarpc01/.local/lib/python3.7/site-packages/ee/computedobject.py\", line 95, in getInfo\n    return data.computeValue(self)\n  File \"/home/aybarpc01/.local/lib/python3.7/site-packages/ee/data.py\", line 490, in computeValue\n    return send_('/value', ({'json': obj.serialize(), 'json_format': 'v2'}))\n  File \"/home/aybarpc01/.local/lib/python3.7/site-packages/ee/data.py\", line 1186, in send_\n    raise ee_exception.EEException(json_content['error']['message'])\nee.ee_exception.EEException: Number.bitwiseAnd: Bitwise operands must be integer only.\nand_bitwise = ee$Number(32L)$bitwiseAnd(100L)\nand_bitwise$getInfo()\n#> [1] 32"},{"path":"extra-considerations.html","id":"be-careful-with-eedate","chapter":"Extra considerations","heading":"3. Be careful with ee$Date","text":"problem also appears due differences design R \nPython programming languages. Currently, R supports integer data\ntype 32 bits. integers can count 2 billion. Unfortunately,\nrange insufficient deal Google Earth\nEngine timestamp\nsaved milliseconds since UNIX epoch.PythonRThe problems ee$Date just appear last mile (Python R \nvice-versa, reticulate), severe treated\ncare. rgee implements two functions deal Earth Engine\ndates: eedate_to_rdate rdate_to_eedate.","code":"my_date = ee.Date('1990-01-01')\nmy_date.getInfo()\n#> {'type': 'Date', 'value': 631152000000} # greater than 2 billion\nmy_date <- ee$Date('1990-01-01')\nmy_date$getInfo()\n#> $type\n#> [1] \"Date\"\n#> \n#> $value\n#> [1] -208192512\n# Era5 dataset\nera_img <- ee$ImageCollection(\"ECMWF/ERA5/DAILY\")$\n  filterDate(\"2019-01-01\", \"2019-12-31\")$\n  first()\n# Extracting init date\nee_date <- era_img$get('system:time_start')\nee_date$getInfo() # Silent error\n#> [1] 112573440\needate_to_rdate(ee_date = ee_date, timestamp = TRUE)\n#> [1] 1.546301e+12"},{"path":"extra-considerations.html","id":"take-into-consideration-reserved-words-in-r","chapter":"Extra considerations","heading":"4. Take into consideration reserved words in R","text":"reserved word word used identifier, name\nvariable function. According ?reserved, reserved words R’s parser\n: , else, repeat, , function, , , next, break, TRUE, FALSE, NULL,\nInf, NaN, NA, NA_integer_, NA_real_, NA_complex_, NA_character_. words,\none part Earth Engine API repeat.can find repeat \nmethod Earth Engine List object. See ee$List$repeat(value, count):avoid error use backticks/quotation marks:","code":"ee_list <- ee$List(1:10)\nee_list$repeat(10,2)$getInfo()\n#> Error: unexpected 'repeat' in \"ee_list$repeat\"\nee_list <- ee$List(1:10)\nee_list$'repeat'(10,2)$getInfo()\n#> 10 10"},{"path":"overview-1.html","id":"overview-1","chapter":"Overview","heading":"Overview","text":"","code":""},{"path":"overview-1.html","id":"tutorials","chapter":"Overview","heading":"Tutorials","text":"","code":""},{"path":"overview-1.html","id":"self-paced-tutorials","chapter":"Overview","heading":"Self-paced tutorials","text":"tutorials introduction using Earth Engine R API advanced geospatial analysis. tutorials assume programming background, although assume willingness learn R programming. Use links get started tutorials use menus left jump section interest.Introduction R Earth EngineIntroduction Earth Engine R APIIntroduction Global Forest Change datasetsIntroduction JRC Global Surface Water dataset","code":""},{"path":"overview-1.html","id":"video-tutorials","chapter":"Overview","heading":"Video tutorials","text":"Visit Video Tutorials page view lectures hands-trainings presented Earth Engine User Summits Earth Outreach digital events.","code":""},{"path":"introduction-to-r-for-earth-engine.html","id":"introduction-to-r-for-earth-engine","chapter":"Introduction to R for Earth Engine","heading":"Introduction to R for Earth Engine","text":"tutorial covers just enough R get started writing Earth Engine scripts. thorough R tutorials, see Mozilla developer resources. introduction programming, examples R, see Eloquent R. suggestions R coding style, see Google R Style Guide. tutorial, ’re going write R Earth Engine Rstudio. getting started, use Rstudio guide get familiar Rstudio environment.","code":""},{"path":"introduction-to-r-for-earth-engine.html","id":"hello-word","chapter":"Introduction to R for Earth Engine","heading":"Hello Word","text":"Time write first code R Earth Engine! Rstudio, copy following Code Editor:Click Run observe ‘Hello world!’ printed Console tab. line R statement. Earth Engine programs made set statements like one. can prevent code running without deleting commenting . One ways comment code putting two forward numerals ## code don’t want run. example:’s good practice put lots comments code, describe ’re trying . ’s also good delete commented code doesn’t anything anymore. practices improve code readability.","code":"\nprint('Hello World!')\n# print('Hello World!')"},{"path":"introduction-to-r-for-earth-engine.html","id":"basic-javascript-data-type","chapter":"Introduction to R for Earth Engine","heading":"Basic JavaScript data type","text":"","code":""},{"path":"introduction-to-r-for-earth-engine.html","id":"strings","chapter":"Introduction to R for Earth Engine","heading":"Strings","text":"Using variables store objects primitives helps code readability. example, variable stores string object defined single ’ double \" quotes (don’t mix ), single quotes preferred. Make new string store variable called greetString:","code":"\n# Use single (or double) quotes to make a string.\ngreetString <- ee$String('Ahoy there!')\n# Use parentheses to pass arguments to functions.\npaste0(greetString$getInfo())"},{"path":"introduction-to-r-for-earth-engine.html","id":"numbers","chapter":"Introduction to R for Earth Engine","heading":"Numbers","text":"Note variables defined keyword var. Variables can also store numbers:example, observe print() given two arguments separated commas, argument printed different line.","code":"\n# Designate a number in Google Earth Engine.\nnumber <- ee$Number(42)\nprint(paste0(\"The answer is: \", ee$Number(number)$getInfo()))"},{"path":"introduction-to-r-for-earth-engine.html","id":"list","chapter":"Introduction to R for Earth Engine","heading":"List","text":"Define lists square brackets ee$List. list numbers, example:Lists can also store strings objects. example:","code":"\n# Use square ee$List to make a list.\nlistOfNumbers <- ee$List(c(0, 1, 1, 2, 3, 5))\nlistOfNumbers$getInfo()\ncat(\"List of numbers:\", listOfNumbers$getInfo())\n# Make a list of strings.\nlistOfStrings <- ee$List(c(\"a\", \"b\", \"c\", \"d\"))\nlistOfStrings$getInfo()\ncat(\"List of strings:\", listOfStrings$getInfo())"},{"path":"introduction-to-r-for-earth-engine.html","id":"dictionary","chapter":"Introduction to R for Earth Engine","heading":"Dictionary","text":"Objects R dictionaries key: value pairs. Make object (dictionary) using curly brackets {}, example:Note can get value dictionary supplying key. example shows R objects. Later ’ll learn dictionaries Earth Engine server.","code":"# Use curly brackets {} to make a dictionary of key:value pairs.\nobject <- {\n  foo <- 'bar',\n  baz <- 13,\n  stuff <- ['this', 'that', 'the other thing']\n}\nprint('Dictionary:', object)\n# Access dictionary items using square brackets.\nprint('Print foo:', object['foo'])\n# Access dictionary items using dot notation.\nprint('Print stuff:', object.stuff)"},{"path":"introduction-to-r-for-earth-engine.html","id":"functions","chapter":"Introduction to R for Earth Engine","heading":"Functions","text":"Functions another way improve code readability reusability grouping sets operations. Define function function keyword. Function names start letter pair parentheses end. Functions often take parameters tell function . parameters go inside parentheses (). set statements making function go inside curly brackets. return keyword indicates function output . several ways declare function, ’ll use something like :Let’s consider lines one one. first line creates new function assigns variable myFunction. variable named anything. defines call function later. terms parentheses function name (.e. parameter1, parameter2, parameter3) parameter names named anything well, though ’s good practice give unique names different code outside function. Whatever name , names function use refer values passed function called. value parameter ’s passed function called argument. Although functions can use variables declared outside function (global variables), function arguments visible outside function. Functions can take many parameters need, even zero. ’s simple example function just returns argument:example user-defined function. also lots built-Earth Engine functions. Explore Code Editor Docs tab learn built-functions. ’s simple example Earth Engine function:","code":"myFunction <- function(parameter1, parameter2, parameter3) {\n  statement\n  statement\n  statement\n  return statement\n}# The reflect function takes a single parameter: element.\nreflect <- function(element) {\n#Return the argument.\n  return element\n}\nprint('A good day to you!', reflect('Back at you!'))\naString <- ee$Algorithms$String(42)"},{"path":"introduction-to-r-for-earth-engine.html","id":"earth-engine-objects","chapter":"Introduction to R for Earth Engine","heading":"Earth Engine Objects","text":"Now ’re comfortable R, learn put objects R primitives Earth Engine containers sending server processing Google.","code":""},{"path":"introduction-to-r-for-earth-engine.html","id":"strings-1","chapter":"Introduction to R for Earth Engine","heading":"Strings","text":"example, define string, put ee$String() container sent Earth Engine:Think ee$Thing container thing exists server. example, string defined first, put container. can also define container contents . example:Although first argument print() just string client, second argument actually sent server evaluated, sent back.","code":"\n# Define a string, then put it into an EE container.\naString <- \"To the cloud!\"\neeString <- ee$String(aString)\neeString$getInfo()\ncat(\"Where to?\", eeString$getInfo())\n# Define a string that exists on the server.\nserverString <- ee$String(\"This is on the server.\")\nserverString$getInfo()\ncat(\"String on the server:\", serverString$getInfo())"},{"path":"introduction-to-r-for-earth-engine.html","id":"numbers-1","chapter":"Introduction to R for Earth Engine","heading":"Numbers","text":"Use ee$Number() create number objects server. example, use Math$E R method create constant value server:ee$String() ee$Number() methods constructors. constructor takes argument (possibly parameters), puts container, returns container contents Earth Engine object can manipulate code. constructor starting ee returns Earth Engine object.","code":"# Define a number that exists on the server.\nserverNumber <- ee$Number(exp(1))\nserverNumber$getInfo()\ncat(\"e =\", serverNumber$getInfo()))"},{"path":"introduction-to-r-for-earth-engine.html","id":"methods-on-earth-engine-objects","chapter":"Introduction to R for Earth Engine","heading":"Methods on Earth Engine objects","text":"Note ’ve created Earth Engine object, use Earth Engine methods process . example, can’t use R’s Math$log() process Earth Engine object. use equivalent method defined ee$Number:example, log() method ee$Number object. (Use Docs tab left side code editor see list methods every Earth Engine object type, example ee.Number > log()). Note methods Earth Engine objects return Earth Engine objects.","code":"\n# Use a built-in function to perform an operation on the number.\nlogE <- serverNumber$log()\nlogE$getInfo()\ncat(\"log(e)=\", logE$getInfo())"},{"path":"introduction-to-r-for-earth-engine.html","id":"list-1","chapter":"Introduction to R for Earth Engine","heading":"List","text":"make JavaScript list ee$List object server, can put JavaScript literal container numbers strings. Earth Engine also provides server-side convenience methods making sequences numbers. example:Since ee$List objects exist server, use Earth Engine provided functions interact . example, get something list, use get() method ee$List object:","code":"\n# Make a sequence the hard way.\neeList <- ee$List(c(1, 2, 3, 4, 5))\n# Make a sequence the easy way!\nsequence <- ee$List$sequence(1, 5)\nsequence$getInfo()\ncat(\"Sequence:\", sequence$getInfo())\n# Use a method on an ee.List to extract a value.\nvalue <- sequence$get(2)\nvalue$getInfo()\ncat('Value at index 2:', value$getInfo())"},{"path":"introduction-to-r-for-earth-engine.html","id":"casting-1","chapter":"Introduction to R for Earth Engine","heading":"Casting","text":"Sometimes, Earth Engine doesn’t know type object gets returned method. , programmer, know value variable previous example number object. try use add() method ee.Number, ’ll get error like:common get() function, return sorts Earth Engine objects. correct , use ee.Number constructor cast result:","code":"\n# Cast the return value of get() to a number.\nprint('No error:', ee$Number(value)$add(3))"},{"path":"introduction-to-r-for-earth-engine.html","id":"dictionaries","chapter":"Introduction to R for Earth Engine","heading":"Dictionaries","text":"can construct Earth Engine Dictionary R object, strings, numbers lists. construction time, can use R functionality initialize Earth Engine object. case ee.Dictionary constructed directly R literal object:example, observe ee.Dictionary, must use methods ee.Dictionary get values (unlike JavaScript dictionary previous lesson). Specifically, get(key) returns value associated key. Since type object returned get() anything, ’re going anything object print , need cast right type. Also note keys() method returns ee.List.","code":"# Make a Dictionary on the server.\ndictionary <- ee$Dictionary({\n  e <- Math.E,\n  pi <- Math.PI,\n  phi <- (1 + Math.sqrt(5)) / 2\n})\n\n# Get some values from the dictionary.\nprint('Euler:', dictionary.get('e'))\nprint('Pi:', dictionary.get('pi'))\nprint('Golden ratio:', dictionary.get('phi'))\n\n# Get all the keys:\nprint('Keys: ', dictionary$keys())"},{"path":"introduction-to-r-for-earth-engine.html","id":"dates","chapter":"Introduction to R for Earth Engine","heading":"Dates","text":"Date objects way Earth Engine represents time. previous examples, important distinguish R Date object Earth Engine ee$Date object. Construct ee$Date string, R Date, using static methods provided ee$Date class. (See Date section Docs tab details). example illustrates construction dates strings JavaScript date representing milliseconds since midnight January 1, 1970:Dates useful filtering collections, specifically arguments filterDate() method. See section Get Started page information sorting collections.","code":"\n# Define a date in Earth Engine.\ndate <- ee$Date('2015-12-31')\ndate$getInfo()\needate_to_rdate(date, timestamp = TRUE)\nrdate_to_eedate(date, timestamp = TRUE)\n\n# Get the current time using the R Date$now() method.\nnow <- Date$now()\nprint('Milliseconds since January 1, 1970', now)\n\n# Initialize an ee$Date object.\neeNow <- ee$Date(now)\nprint('Now:', eeNow)"},{"path":"introduction-to-r-for-earth-engine.html","id":"digression-passing-parameters-by-name","chapter":"Introduction to R for Earth Engine","heading":"Digression: passing parameters by name","text":"Arguments Earth Engine methods can passed order, example create ee$Date year, month day, can pass parameters fromYMD() static method order year, month, day:Alternatively, can pass parameters name, order. might code, can improve readability reusability. pass parameters name, pass R object keys object names method parameters values arguments method. example:Note names object properties (keys) match names specified ee.Date.fromYMD() docs. Also note object passed argument can saved variable reuse, illustrated R object example.now enough introduction R start using Earth Engine! See Client vs. Server page detailed explanation R vs. Earth Engine objects.next section, learn Functional programming concepts effectively use -loops, /else conditions iterations Earth Engine.","code":"\naDate <- ee$Date$fromYMD(2017, 1, 13)\naDate$getInfo()\needate_to_rdate(date, timestamp = TRUE)\nrdate_to_eedate(date, timestamp = TRUE)\ntheDate <- ee$Date$fromYMD(\n  day = 13,\n  month = 1,\n  year = 2017\n)\ntheDate$getInfo()\needate_to_rdate(theDate, timestamp = TRUE)\nrdate_to_eedate(theDate, timestamp = TRUE)"},{"path":"introduction-to-r-for-earth-engine.html","id":"functional-programming-concepts","chapter":"Introduction to R for Earth Engine","heading":"Functional Programming Concepts","text":"","code":""},{"path":"introduction-to-r-for-earth-engine.html","id":"introduction-to-functional-programming","chapter":"Introduction to R for Earth Engine","heading":"Introduction to functional programming","text":"Earth Engine uses parallel processing system carry computation across large number machines. enable processing, Earth Engine takes advantage standard techniques commonly used functional languages, referential transparency lazy evaluation, significant optimization efficiency gains.main concept sets functional programming apart procedural programming absence side effects. means functions write doesn’t rely update data outside function. see examples , possible re-structure problem can solved using functions without side-effects - much better suited executed parallel.","code":""},{"path":"introduction-to-r-for-earth-engine.html","id":"for-loops","chapter":"Introduction to R for Earth Engine","heading":"For Loops","text":"use -loops discouraged Earth Engine. results can achieved using map() operation specify function can independently applied element. allows system distribute processing different machines.example illustrates take list numbers create another list squares number using map():","code":"# This generates a list of numbers from 1 to 10.\nmyList <- ee$List$sequence(1, 10)\n\n# The map() operation takes a function that works on each element independently\n# and returns a value. You define a function that can be applied to the input.\ncomputeSquares <- function(number) {\n#We define the operation using the EE API.\n  return ee$Number(number)$pow(2)\n}\n\n# Apply your function to each item in the list by using the map() function.\nsquares <- myList$map(computeSquares)\nprint(squares)  # [1, 4, 9, 16, 25, 36, 49, 64, 81]"},{"path":"introduction-to-r-for-earth-engine.html","id":"ifelse-conditions","chapter":"Introduction to R for Earth Engine","heading":"If/Else Conditions","text":"Another common problem faced new users used procedural programming paradigm proper use /else conditional operators Earth Engine. , API provide ee.Algorithms.() algorithm, use strongly discouraged favor functional approach using map() filters. Earth Engine uses deferred execution, means evaluation expression delayed realized value actually required. cases, type execution model evaluate true false alternatives ee.Algorithms.() statement. can lead extra computation memory usage, depending expressions resources required execute .Say want solve variant example, task compute squares odd numbers. functional approach solving without /else conditions, demonstrated :paradigm especially applicable working collections. wanted apply different algorithm collection based conditions, preferred way first filter collection based condition, map() different function subsets. allows system parallelize operation. example:","code":"# The following function determines if a number is even or odd.  The mod(2)\n# function returns 0 if the number is even and 1 if it is odd (the remainder\n# after dividing by 2).  The input is multipled by this remainder so even\n# numbers get set to 0 and odd numbers are left unchanged.\ngetOddNumbers <- function(number) {\n  number <- ee$Number(number)   # Cast the input to a Number so we can use mod.\n  remainder <- number$mod(2)\n  return number$multiply(remainder)\n}\n\nnewList <- myList$map(getOddNumbers)\n\n# Remove the 0 values.\noddNumbers <- newList$removeAll([0])\n\nsquares <- oddNumbers$map(computeSquares)\nprint(squares)  # [1, 9, 25, 49, 81]collection <- ee$ImageCollection('LANDSAT/LC08/C01/T1_TOA')\n\n# Divide the collection into 2 subsets and apply a different algorithm on them.\nsubset1 <- collection$filter(ee$Filter$lt('SUN_ELEVATION', 40))\nsubset2 <- collection$filter(ee$Filter$gte('SUN_ELEVATION', 40))\n\nprocessed1 <- subset1$map(function(image) {\n  return image$multiply(2)\n})\nprocessed2 <- subset2\n\n# Merge the collections to get a single collection.\nfinal <- processed1$merge(processed2)\nprint('Original collection size', collection$size())\nprint('Processed collection size', final$size())"},{"path":"introduction-to-r-for-earth-engine.html","id":"cumulative-iteration","chapter":"Introduction to R for Earth Engine","heading":"Cumulative Iteration","text":"may need sequential operation, result iteration used subsequent iteration. Earth Engine provides iterate() method tasks. Remember iterate() executed sequential manner hence slow large operations. Use able use map() filters achieve desired output.good demonstration iterate() creation Fibonacci number sequence. , number series sum previous 2 numbers. iterate() function takes 2 arguments, function (algorithm) starting value. function gets passed 2 values, current value iteration, result previous iteration. following example demonstrates implement fibonacci sequence Earth Engine.Now good understanding javascript concepts, can see API Tutorial introduction geospatial functionality Earth Engine API.","code":"algorithm <- function(current, previous) {\n  previous <- ee$List(previous)\n  var n1 <- ee$Number(previous$get(-1))\n  var n2 <- ee$Number(previous$get(-2))\n  return previous$add(n1$add(n2))\n}\n\n# Compute 10 iterations.\nnumIteration <- ee$List$repeat(1, 10)\nstart <- [0, 1]\nsequence <- numIteration$iterate(algorithm, start)\nprint(sequence)  # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]"},{"path":"the-earth-engine-api.html","id":"the-earth-engine-api","chapter":"The Earth Engine API","heading":"The Earth Engine API","text":"Welcome introductory tutorial Google Earth Engine R API. tutorial provides examples use Earth Engine analyze geospatial raster vector data. end tutorial, seen basic functionality Earth Engine API.","code":""},{"path":"the-earth-engine-api.html","id":"prerequisites","chapter":"The Earth Engine API","heading":"Prerequisites","text":"Signup Earth Engine. accepted, receive email additional information.unfamiliar R, check R Earth Engine tutorial proceeding.’re familiar R Rstudio, visit next section learn visualizing images image bands","code":""},{"path":"the-earth-engine-api.html","id":"visualizing-images-and-image-bands","chapter":"The Earth Engine API","heading":"Visualizing Images and Image Bands","text":"Now ’re ready begin writing R Earth Engine , start copying following code Code Editor:Click Run button top Rstudio observe gray image appears map. Don’t worry, ’ll make look better soon.","code":"\n## Instantiate an image with the Image constructor.\nimage <- ee$Image(\"CGIAR/SRTM90_V4\")\n\n## Zoom to a location.\nMap$setCenter(-112.8598, 36.2841, 9) ## Center on the Grand Canyon.\n\n## Display the image on the map.\nMap$addLayer(image)"},{"path":"the-earth-engine-api.html","id":"image-constructor","chapter":"The Earth Engine API","heading":"Image Constructor","text":"first new thing example image constructor ee$Image(). argument provided constructor string ID image Earth Engine data catalog.discover image ID, search Earth Engine Data Catalog using search tool. example, type ‘elevation’ search field note list rasters returned. Click ‘SRTM Digital Elevation Data Version 4’ entry see information dataset. right side dataset description Image ID field. Observe image ID example copied image ID shown dataset description.","code":""},{"path":"the-earth-engine-api.html","id":"configuring-the-map","chapter":"The Earth Engine API","heading":"Configuring the Map","text":"second new part example Map$setCenter() call. method Map object, represents Map display Rstudio, centers map given longitude, latitude (decimal degrees) zoom level 1 zoomed map shows entire Earth’s surface. Larger numbers zoom .","code":""},{"path":"the-earth-engine-api.html","id":"adding-a-layer-to-the-map","chapter":"The Earth Engine API","heading":"Adding a layer to the Map","text":"last line example says: use Map object’s addLayer() method add image map display Rstudio.Congratulations! ’ve created first Earth Engine script. next section, ’ll learn make image look little better.","code":""},{"path":"the-earth-engine-api.html","id":"digression-images-in-earth-engine","chapter":"The Earth Engine API","heading":"Digression: Images in Earth Engine","text":"Images Earth Engine (see page details) made one bands. band image name, pixel values, pixel resolution, projection. ’ll soon discover, SRTM image one band: ‘elevation’.add image map using Map$addLayer(), Earth Engine needs determine map values image band(s) colors display. single-band image added map, default Earth Engine displays band grayscale, minimum value assigned black, maximum value assigned white. don’t specify minimum maximum , Earth Engine use default values. example, image just added map displayed grayscale image stretched full range data, signed 16-bit integer [-32768, 32767]. (float bands stretched [0, 1] byte bands stretched [0, 255] default).can discover data type image printing inspecting image object Console tab. example, paste following previous code:click run, note object appears console.","code":"\ncat(\"SRTM image\", unlist(image$getInfo()))"},{"path":"the-earth-engine-api.html","id":"customizing-layer-visualization","chapter":"The Earth Engine API","heading":"Customizing layer visualization","text":"change way data stretched, can provide another parameter Map$addLayer() call. Specifically, second parameter, visParams, lets specify minimum maximum values display. Suppose experimentation, determine data stretched [0, 3000]. display image using range, use:Note visParams parameter object, properties specifying min max. Note third parameter Map$addLayer() name layer displayed Layer manager. result look something like Figure. Hover mouse Layers box left see effect renaming layer.Figure: Elevation image grayscale, stretched [0, 3000].display single band using color palette, add palette property visParams object:result look something like Figure .Figure: Elevation image color ramp blue red, stretched [0, 3000].","code":"\nMap$addLayer(\n  image,\n  list(min = 0, max = 3000),\n  \"custom visualization\"\n)\nMap$addLayer(\n  image,\n  list(min = 0, max = 3000, palette = c(\"blue\", \"green\", \"red\")),\n  \"custom palette\"\n)"},{"path":"the-earth-engine-api.html","id":"digression-palettes","chapter":"The Earth Engine API","heading":"Digression: Palettes","text":"Palettes let set color scheme single-band images. palette comma delimited list color strings linearly interpolated maximum minimum values visualization parameters (defaults according band type, described previously). example, pixels less equal minimum displayed first color list; pixels greater equal maximum displayed last color list. Intermediate colors linearly stretched intermediate pixel values.colors defined using web standard CSS color value scheme (see external reference learn ). Colors can specified name hexadecimal strings indicating combination red, green blue. lowest value three positions 00 (representing decimal number 0), highest FF (representing decimal number 255). string ‘000000’ represents color black, ‘FFFFFF’ white, ‘FF0000’ red, ‘00FF00’ green, ‘0000FF’ blue. See Color palettes section detail. stretches possible using Styled Layer Descriptors, described Styled Layer Descriptors section.Later tutorial, ’ll learn display multi-band imagery. first, visit next page learn performing computations images.","code":""},{"path":"the-earth-engine-api.html","id":"computations-using-images","chapter":"The Earth Engine API","heading":"Computations using Images","text":"Now know load display image, ’s time apply computation . example, can compute slope terrain, passing SRTM elevation image slope method ee$Terrain package.Note code ee$Terrain$slope(srtm), srtm image provided argument slope algorithm. result look something like Figure.Figure: Slope image.","code":"\n## Load the SRTM image.\nsrtm <- ee$Image(\"CGIAR/SRTM90_V4\")\n\n## Apply an algorithm to an image.\nslope <- ee$Terrain$slope(srtm)\n\n## Display the result.\nMap$setCenter(-112.8598, 36.2841, 9) ## Center on the Grand Canyon.\nMap$addLayer(\n  slope,\n  list(min = 0, max = 60),\n  \"slope\"\n)"},{"path":"the-earth-engine-api.html","id":"image-math","chapter":"The Earth Engine API","heading":"Image math","text":"also methods ee$Image class can invoked image object. example, suppose ’d like math using image bands (sometimes called band math map algebra). example, may interested trigonometric operations aspect image. accomplish , first convert aspect image radians, call sin() . Reusing srtm image.result look something like Figure . ’s worth taking closer look aspect$divide(180)$multiply(pi)$sin() code. chaining multiple methods like , code says, ‘divide aspect 180, multiply result π, finally take sin’. can perform complex mathematical operations images combining methods manner.Figure: Sin terrain aspect.","code":"\n## Get the aspect (in degrees).\naspect <- ee$Terrain$aspect(srtm)\n\n## Convert to radians, compute the sin of the aspect.\nsinImage <- aspect$divide(180)$multiply(pi)$sin()\n\n## Display the result.\nMap$addLayer(\n  sinImage,\n  list(min = -1, max = 1),\n  \"sin\"\n)"},{"path":"the-earth-engine-api.html","id":"image-statistics","chapter":"The Earth Engine API","heading":"Image statistics","text":"Another useful class operations images involves computing pixel statistics image regions, raster-vector overlays. compute statistics Earth Engine, use reducer represented classes ee$Reducer package.example, suppose ’re interested mean elevation region.Next, get mean pixel value polygon using following code:several things note . First, observe reduceRegion() method available Image objects learn reducing regions . Second, method arguments provided R object passed single argument. (Specifically, keys object names method parameters. values arguments method). Third, reducer parameter specifies type statistic compute geometry parameter specifies region compute statistic. scale parameter pixel size meters use. avoid ambiguity, always specify scale reductions Earth Engine may able automatically determine appropriate scale inputs. (Learn scale Earth Engine).Lastly, return value reduceRegion() dictionary keys band names values pixel statistics bands. get() method dictionary returns value corresponding key provided argument. case, srtm image one band, ‘elevation’, example code gets statistic dictionary prints .run code, get error looks like:Fear ! several things can resolve error. reduceRegion() method check make sure consider whether really want include many pixels computation. intended prevent accidentally something silly, like trying compute mean every one-meter pixel world (don’t ). resolve error, either set bestEffort parameter TRUE adding bestEffort: TRUE dictionary parameters, set maxPixels parameter value higher default 10 million pixels, . bestEffort TRUE, Earth Engine automatically recompute scale maxPixels exceeded.","code":"\npolygon <- ee$Geometry$Polygon(\n  list(\n    c(3.807648573314655, 51.280649018952),\n    c(3.807648573314655, 50.42759747456426),\n    c(5.653351698314655, 50.42759747456426),\n    c(5.653351698314655, 51.280649018952)\n  ), NULL, FALSE\n)\n\n## Compute the mean elevation in the polygon.\nmeanDict <- srtm$reduceRegion(\n  reducer = ee$Reducer$mean(),\n  geometry = polygon,\n  scale = 90\n)\n\n## Get the mean from the dictionary and print it.\nmean <- meanDict$get(\"elevation\")\ncat(\"Mean elevation: \", mean$getInfo())\npolygon <- ee$Geometry$Polygon(\n  list(c(-5, 40), c(65, 40), c(65, 60), c(-5, 60), c(-5, 60))\n)\n\n## Compute the mean elevation in the polygon.\nmeanDict <- srtm$reduceRegion(\n  reducer = ee$Reducer$mean(),\n  geometry = polygon,\n  bestEffort = TRUE,\n  scale = 90\n)\n\n## Get the mean from the dictionary and print it.\nmean <- meanDict$get(\"elevation\")\ncat(\"Mean elevation\", mean$getInfo())"},{"path":"the-earth-engine-api.html","id":"digression-scale-in-earth-engine","chapter":"The Earth Engine API","heading":"Digression: Scale in Earth Engine","text":"previous example, scale set approximately native resolution SRTM image. can discover native resolution image :specify scale smaller native resolution, Earth Engine happily resample input image using nearest neighbor, include smaller pixels computation. set scale larger, Earth Engine use input pixels aggregated version input (.e. get pixels higher level image pyramid). Learn Earth Engine handles scale doc.far, ’ve working single image single band. next section, ’ll learn multi-band images image collections.","code":"\nscale <- srtm$projection()$nominalScale()\ncat(\"SRTM scale in meters\", scale$getInfo())"},{"path":"the-earth-engine-api.html","id":"image-collections","chapter":"The Earth Engine API","heading":"Image Collections","text":"image collection refers set Earth Engine images. example, collection Landsat 8 images ee$ImageCollection. Like SRTM image working , image collections also ID. single images, can discover ID image collection searching Earth Engine data catalog looking details page dataset. example, search ‘landsat 8 toa’ click first result, correspond USGS Landsat 8 Collection 1 Tier 1 TOA Reflectance dataset. Copy ID image collection constructor:","code":"\nl8 <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_TOA\")"},{"path":"the-earth-engine-api.html","id":"filtering-image-collections","chapter":"The Earth Engine API","heading":"Filtering image collections","text":"’s worth noting collection represents every Landsat 8 scene collected, Earth. Often useful extract single image, subset images, test algorithms. way limit collection time space filtering . example, filter collection images cover particular location, first define area interest point (line polygon). , filter l8 collection get images intersect point, add second filter limit collection images acquired 2015:, filterBounds() filterDate() shortcut methods general filter() method image collections, takes ee.Filter() argument. argument filterBounds() point definied arguments filterDate() two dates, expressed strings.Note can see filtered collections ee_get_date_ic(). can’t print 5000 things , couldn’t, example, print entire l8 collection. one way discover ID individual image. Another, programmatic way get individual images analysis sort collection order get recent, oldest, optimal image relative metadata property. can use CLOUD_COVER property get least cloudy image 2015 area interest:’re now ready display image!","code":"\npoint <- ee$Geometry$Point(-77.67416408465883, -9.157901605369615)\n\nspatialFiltered <- l8$filterBounds(point)\nee_get_date_ic(spatialFiltered)\n\ntemporalFiltered <- spatialFiltered$filterDate(\"2015-01-01\", \"2015-12-31\")\nee_get_date_ic(temporalFiltered)\n# This will sort from least to most cloudy.\nsorted <- temporalFiltered$sort(\"CLOUD_COVER\")\n\n# Get the first (least cloudy) image.\nscene <- sorted$first()"},{"path":"the-earth-engine-api.html","id":"digression-displaying-rgb-images","chapter":"The Earth Engine API","heading":"Digression: Displaying RGB images","text":"multi-band image added map, Earth Engine chooses first three bands image displays red, green, blue default, stretching according data type, described previously. Usually, won’t . example, add Landsat image (scene previous example) map, result unsatisfactory:Note first, map centered image zoom scale 8. image displayed empty object ({}) visParams parameter. result, image displayed default visualization: first three bands map R, G, B, respectively, stretched [0, 1] since bands float data type. means coastal aerosol band (‘B1’) rendered red, blue band (‘B2’) rendered green, green band (‘B3’) rendered blue. render image true-color composite, need tell Earth Engine use Landsat 8 bands ‘B4’, ‘B3’, ‘B2’ R, G, B, respectively. Specify bands use bands property visParams object. Learn Landsat bands reference.also need provide min max values suitable displaying reflectance typical Earth surface targets. Although lists can used specify different values band, ’s sufficient specify 0.3 max use default value zero min parameter. Combining visualization parameters one object displaying:result look something like Figure. Note code assigns object visualization parameters variable possible future use. ’ll soon discover, object useful visualize image collections!Figure: Landsat 8 TOA reflectance image true-color composite, stretched [0, 0.3].Try playing visualizing different bands. Another favorite combination ‘B5’, ‘B4’, ‘B3’ called false-color composite. interesting false-color composites described .Since Earth Engine designed large-scale analyses, limited working just one scene. Now ’s time display whole collection RGB composite!","code":"\nMap$centerObject(scene, 8)\nMap$addLayer(\n  scene,\n  {},\n  \"default RGB\"\n)\nvisParams <- list(bands = c(\"B4\", \"B3\", \"B2\"), max = 0.3)\nMap$addLayer(\n  scene,\n  visParams, \n  \"true-color composite\"\n)"},{"path":"the-earth-engine-api.html","id":"displaying-image-collections","chapter":"The Earth Engine API","heading":"Displaying image collections","text":"Adding image collection map similar adding image map, use Map$addLayers. example, using MODIS images collection dataset collection visParams object defined previously,Figure: MODIS Combined 16-Day EVINote now can zoom see continuous mosaic MODIS imagery collected (.e. land).","code":"\ndataset <- ee$ImageCollection(\"MODIS/MCD43A4_006_EVI\")$\n  filter(ee$Filter$date(\"2018-04-01\", \"2018-05-01\"))\n\ncolorized <- dataset$select(\"EVI\")\ncolorizedVis <- list(\n  min = 0.0,\n  max = 1.0,\n  palette = c(\n    \"FFFFFF\", \"CE7E45\", \"DF923D\", \"F1B555\", \"FCD163\", \"99B718\", \"74A901\",\n    \"66A000\", \"529400\", \"3E8601\", \"207401\", \"056201\", \"004C00\", \"023B01\",\n    \"012E01\", \"011D01\", \"011301\"\n  )\n)\nMap$setCenter(-7.03125, 31.0529339857, 2)\nMap$addLayers(eeObject = colorized, visParams = colorizedVis, name = \"Colorized\")"},{"path":"the-earth-engine-api.html","id":"compositing-masking-and-mosaicking","chapter":"The Earth Engine API","heading":"Compositing, Masking, and Mosaicking","text":"Landsat 8 TOA reflectance collection loaded variable called l8, saw following code:One problems composite ’s full clouds.","code":"\nl8 <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_TOA\")\nlandsat2016 <- l8$filterDate(\"2016-01-01\", \"2016-12-31\")"},{"path":"the-earth-engine-api.html","id":"compositing-with-reducers","chapter":"The Earth Engine API","heading":"Compositing with Reducers","text":"first introduced reducers getting statistics image region. spatial reduction. Reducing image collection image temporal reduction collection represents images time. type Reducer use defines Earth Engine handles overlapping pixels. Landsat 8 visits spot Earth every 16 days. means 6 month period, approximately 12 images (scenes overlap). pixel map derived stack pixels - one image collection displayed.Merely adding collection map results selecting recent pixel - one latest image stack. behavior may altered, using Earth Engine reducers. example, rather take recent pixel stack, Earth Engine can instructed pick median value stack. benefit removing clouds (high value) shadows (low value). image collection reduced using median reducer, composite value median band, time. example, using Landsat scenes 2016:new thing code median() method applied image collection. Like filtering methods, shortcut general reduce() method image collections takes ee$Reducer() argument. considering reducer image collection, note output image, reducers non-numeric outputs, example histogram toList reducers, won’t work image collection.Figure: Landsat 8 median composite.zoom median composite, see something like next figure. look considerably better composite made previously. point, ’s worth stepping back considering ’s done make median composite. Earth Engine loaded entire Landsat 8 collection continental south american, calculated median every pixel. ’s lot data! course, compute annual medians, first filtering collection, ’ve done previously. point download imagery make composite, big project. Earth Engine, get result seconds!Learn compositing mosaicking .","code":"\n# Get the median over time, in each band, in each pixel.\nmedian <- l8$filterDate(\"2016-01-01\", \"2016-12-31\")$median()\n\n# Make a handy variable of visualization parameters.\nvisParams <- list(bands = c(\"B4\", \"B3\", \"B2\"), max = 0.3)\n\n# Display the median composite.\nMap$addLayer(median, visParams, \"median\")"},{"path":"the-earth-engine-api.html","id":"masking-2","chapter":"The Earth Engine API","heading":"Masking","text":"Although median composite improvement recent-value composite, may want mask parts image. Masking pixels image makes pixels transparent excludes analysis. pixel band image mask. mask value 0 transparent. mask value 0 rendered. mask image set using call like image1$mask(image2). call takes values image2 makes mask image1. pixels image2 value 0 made transparent image1.example, suppose like mask water pixels median composite. water mask can created using dataset described Hansen et al. (2013) Earth Engine data catalog. (Learn Hansen et al. dataset tutorial). dataset, water value 2, land value 1, ‘data’ value 0. Use bit logic create mask image zeros ’s land:couple new things code worth mentioning detail. First, select() function useful extracting bands interest image. , select band care : datamask. next new thing logical operator eq() stands “equals.” use eq(1) create binary image pixels value 1 datamask band (water data) get value 0 resulting image.result masking, pixels median composite land (according Hansen et al. dataset) visible, water (nodata) transparent excluded analysis maskedComposite image.","code":"\n# Load or import the Hansen et al. forest change dataset.\nhansenImage <- ee$Image(\"UMD/hansen/global_forest_change_2020_v1_8\")\n\n# Select the land/water mask.\ndatamask <- hansenImage$select(\"datamask\")\n\n# Create a binary mask.\nmask <- datamask$eq(1)\n\n# Update the composite mask with the water mask.\nmaskedComposite <- median$updateMask(mask)\nMap$addLayer(maskedComposite, visParams, \"masked\")"},{"path":"the-earth-engine-api.html","id":"mosaicking-1","chapter":"The Earth Engine API","heading":"Mosaicking","text":"combining concepts image collections, logical operators, masking compositing, can achieve interesting cartographic results. example, suppose want image land pixels displayed true-color pixels displayed blue, can something like:’s lot going code, let’s dissect . First, use () logical operator invert mask made earlier. Specifically, () turns zeros ones non-zeros zeros. ’s completely correct call variable water includes nodata pixels well, ’s OK present cartographic context. next thing mask “water” . results image water pixels 1’s everything else masked. final step combine images mosaic(). Since mosaic() works image collection, pass list images want combine image collection constructor, call mosaic() final step. order images list important. Specifically, output image contain last unmasked pixel stack images input collection. case, works water layer last (top) image collection, contains un-masked pixels water occurs.Note images collection visualization images. call [visualize()](https://developers.google.com/earth-engine/apidocs/ee-image-visualize) image, gets turned 3-band, 8-bit image according visualization parameters pass . default visualization parameters work fine 3-band, 8-bit images, don’t need visualization parameters add image map. result look like Figure 7.point, ’ve seen ways visualize image collections recent-value composites, methods compositing image collections using reducers, methods making custom composites masking mosaicking collection images. next page, learn add vegetation index every image collection use index make “greenest pixel” composite.","code":"\n# Make a water image out of the mask.\nwater <- mask$Not()\n\n# Mask water with itself to mask all the zeros (non-water).\nwater <- water$mask(water)\n\n# Make an image collection of visualization images.\nmosaic <- ee$ImageCollection(list(\n  median$visualize(bands = c(\"B4\", \"B3\", \"B2\"), max = 0.3),\n  water$visualize(palette = \"000044\")\n))$mosaic()\n\n# Display the mosaic.\nMap$addLayer(\n  mosaic,\n  {},\n  \"custom mosaic\"\n)"},{"path":"the-earth-engine-api.html","id":"ndvi-mapping-a-function-over-a-collection-quality-mosaicking","chapter":"The Earth Engine API","heading":"NDVI, Mapping a Function over a Collection, Quality Mosaicking","text":"Previously, learned get individual Landsat scenes something like , l8 point imports representing Landsat 8 TOA collection area--interest geometry:Suppose now want compute Normalized Difference Vegetation Index (NDVI) image Landsat image. Vegetation reflects light near-infrared (NIR) part electromagnetic spectrum absorbs light red part (Learn NIR reflectance vegetation). NDVI uses create single value roughly reflecting photosynthetic activity occurring pixel. calculation (NIR - red) / (NIR + red). results number 1 -1, pixels high photosynthetic activity high NDVI. one way compute NDVI Earth Engine:result look something like figure. Note use select() function learned previous section masking get NIR red bands, compute NDVI using image mathematical operators also seen section Image math. Finally, display image palette. used color names instead hex strings palette. (See external reference CSS color details.)Figure: NDVI single Landsat scene. Blue low green high NDVI.normalized difference operation ubiquitous remote sensing, shortcut function ee$Image useful simplifying code previous example:","code":"\n# Define a point of interest. Use the UI Drawing Tools to import a point\n# geometry and name it \"point\" or set the point coordinates with the\n# ee$Geometry$Point() function as demonstrated here.\npoint <- ee$Geometry$Point(c(-122.292, 37.9018))\n\n# Import the Landsat 8 TOA image collection.\nl8 <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_TOA\")\n\n# Get the least cloudy image in 2015.\nimage <- ee$Image(\n  l8$filterBounds(point)$\n    filterDate(\"2015-01-01\", \"2015-12-31\")$\n    sort(\"CLOUD_COVER\")$\n    first()\n)\n# Compute the Normalized Difference Vegetation Index (NDVI).\nnir <- image$select(\"B5\")\nred <- image$select(\"B4\")\nndvi <- nir$subtract(red)$divide(nir$add(red))$rename(\"NDVI\")\n\n# Display the result.\nMap$centerObject(image, 9)\nndviParams <- list(\n  min = -1,\n  max = 1,\n  palette = c(\"blue\", \"white\", \"green\")\n)\nMap$addLayer(ndvi, ndviParams, \"NDVI image\")\nndvi <- image$normalizedDifference(c(\"B5\", \"B4\"))$rename(\"NDVI\")"},{"path":"the-earth-engine-api.html","id":"mapping-a-function-over-a-collection","chapter":"The Earth Engine API","heading":"Mapping a Function over a Collection","text":"Suppose now want add NDVI every image image collection. way Earth Engine map() function collection. Don’t confuse map() Map object. former method collection, uses map parallel computing sense applying function every element collection. function defines operations applied every element collection. seen simple function R tutorial, now ’re going make function includes Earth Engine functionality. example, copy previous NDVI code function returns input image NDVI band:code might efficient computing NDVI single image, function can used argument map() order add NDVI band every image collection. ’s often useful first test function single image, make sure function behaving expect. ’ve tested function individual image determined want, can map collection:","code":"\naddNDVI <- function(image) {\n  ndvi <- image$normalizedDifference(c(\"B5\", \"B4\"))$rename(\"NDVI\")\n  return(image$addBands(ndvi))\n}\n\n# Test the addNDVI function on a single image.\nndvi <- addNDVI(image)$select(\"NDVI\")\nwithNDVI <- l8$map(addNDVI)"},{"path":"the-earth-engine-api.html","id":"make-a-greenest-pixel-composite","chapter":"The Earth Engine API","heading":"Make a greenest pixel composite","text":"Now ’ve made image collection image NDVI band, can explore new way make composites: qualityMosaic(). may noticed discontinuities Landsat paths, even median pixel composite. Part reason may due differences phenology result images adjacent paths collected different times (specifically, 8 days apart). One way minimize try set pixel values composite roughly phenological stage, example time maximum greenness plants (leaves photosynthetically active). let max greenness defined maximum NDVI, can use qualityMosaic() make composite pixel contains maximum NDVI pixel collection. Now can make use added NDVI band withNDVI collection:result code look something like Figure 9. Comparing Figure 9 median composite shown Figure 6, observe greenest pixel composite indeed much greener. However, close examination water bodies make different problem apparent. Specifically, water bodies now appear cloudy. due way qualityMosaic() method works: location, entire time series examined pixel maximum value NDVI band set composite value. NDVI higher clouds water, water areas get cloudy pixels, vegetated areas appear green NDVI highest vegetation pixel photosynthetically active.Now ’ve seen several ways composite mosaic images Earth Engine. can make recent-value, median, greenest-pixel composites images filtered time place images collection. ’ve learned computations imagery extract information.","code":"\n# Make a \"greenest\" pixel composite.\ngreenest <- withNDVI$qualityMosaic(\"NDVI\")\n\n# Display the result.\nvisParams <- list(bands = c(\"B4\", \"B3\", \"B2\"), max = 0.3)\nMap$addLayer(\n  greenest,\n  visParams,\n  \"Greenest pixel composite\"\n)"},{"path":"global-forest-change.html","id":"global-forest-change","chapter":"Global Forest Change","heading":"Global Forest Change","text":"section requires next libraries:","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()"},{"path":"global-forest-change.html","id":"introduction-to-forest-change-analysis-in-earth-engine","chapter":"Global Forest Change","heading":"Introduction to Forest Change Analysis in Earth Engine","text":"Figure: Forest change estimated Hansen et al. (2013). Global Change, 2000 - 2012 (left); Change Riau, Indonesia, 2000 - 2012 (right)Welcome Google Earth Engine tutorial using Hansen et al. (2013) global forest cover change data Forest Monitoring Action (FORMA, Hammer et al. 2009) data Global Forest Watch. tutorial provides examples use Earth Engine visualize data, compute forest change time statistics within region interest download data results analyses.","code":""},{"path":"global-forest-change.html","id":"license-and-attribution","chapter":"Global Forest Change","heading":"License and Attribution","text":"data described tutorial licensed Creative Commons Attribution 4.0 International License. Please use recommended citation relevant dataset description page.","code":""},{"path":"global-forest-change.html","id":"prerequisites-1","chapter":"Global Forest Change","heading":"Prerequisites","text":"tutorial assumes programming background, although assume willingness learn programming. proceeding, please make sure :Signup Earth Engine. accepted, receive email additional information.Signup Earth Engine. accepted, receive email additional information.Get familiar Earth Engine Rstudio, IDE writing Earth Engine R code Rstudio. Learn .Get familiar Earth Engine Rstudio, IDE writing Earth Engine R code Rstudio. Learn .unfamiliar R, check R Earth Engine tutorial.unfamiliar R, check R Earth Engine tutorial.unfamiliar Earth Engine API, check Introduction Earth Engine API tutorial.unfamiliar Earth Engine API, check Introduction Earth Engine API tutorial.’re familiar R, Earth Engine API Rstudio, get started tutorial.","code":""},{"path":"global-forest-change.html","id":"introduction-to-hansen-et-al.-global-forest-change-data","chapter":"Global Forest Change","heading":"Introduction to Hansen et al. Global Forest Change Data","text":"Hansen et al. (2013) Global Forest Change dataset Earth Engine represents forest change, 30 meters resolution, globally, 2000 2014. Let’s start adding Hansen et al. data map. Either import global forest change data searching “Hansen forest” naming import gfc2014, copy following code Rstudio:Click Run button top Rstudio see something like Figure 1.Figure: Default visualization Hansen et al. (2013) forest change data.Don’t worry, ’ll make look better soon. (Learn default image visualizations Earth Engine). end section, ’ll image looks something like Figure 2, green represents study detected forest year 2000, red estimated forest loss study period, blue forest gain period, magenta areas forest lost gained, non-forest areas masked.Figure: Custom visualization Hansen et al. (2013) forest change data.Recall multi-band image added map, first three bands image chosen red, green, blue, respectively, stretched according data type band. reason image looks red first three bands treecover2000, loss, gain. treecover2000 band expressed percent values much higher loss (green) gain (blue) binary ({0, 1}). image therefore displays overwhelmingly red.bands Global Forest Change data :display forest cover year 2000 grayscale image, can use treecover2000 band, specified second argument Map.addLayer():results image look something like Figure 3.Figure: Grayscale image year 2000 tree cover South America.’s image uses 3 bands, Landsat bands 5, 4, 3 2015. band combination shows healthy vegetation green soil mauve::result look something like Figure 4.Figure: Landsat 7, year 2015 false color composite South America.One nice visualization Global Forest Change dataset shows forest extent 2000 green, forest loss red, forest gain blue. Specifically, make loss first band (red), treecover2000 second band (green), gain third band (blue):loss gain band values binary, barely visible image, look something like Figure 5.Figure: Year 2000 tree cover South America (green).’d like forest loss show bright red forest gain show bright blue. fix , can use visualization parameter max set range image data stretched. Note max visualization parameter takes list values, corresponding maxima band:result look something like Figure 6.Figure: South America forest loss (red), year 2000 forest cover (green) gain (blue).results image green ’s forest, red ’s forest loss, blue ’s forest gain, magenta ’s gain loss. closer inspection, however, reveals ’s quite right. Instead loss marked red, ’s orange. bright red pixels mix underlying green pixels, producing orange pixels. Similarly pixels ’s forest, loss, gain pink - combination green, bright red bright blue. See Figure 7 illustration.Figure: US Pacific North West forest loss (red), year 2000 cover (green) gain (blue).get image promised beginning tutorial, can create separate images forest, loss, gain, loss gain. Add images map order ’s best display.","code":"\ngfc2014 <- ee$Image('UMD/hansen/global_forest_change_2015')\nMap$addLayer(gfc2014)\nMap$addLayer(gfc2014, list(bands = 'treecover2000'), 'treecover2000')\nMap$addLayer(\n  gfc2014, list(bands = c('last_b50', 'last_b40', 'last_b30')), 'false color')\nMap$addLayer(gfc2014, list(bands = c('loss', 'treecover2000', 'gain')), 'green')\nMap$addLayer(gfc2014, list(\n  bands = c('loss', 'treecover2000', 'gain'),\n  max = c(1, 255, 1)\n), 'forest cover, loss, gain')"},{"path":"global-forest-change.html","id":"palettes","chapter":"Global Forest Change","heading":"Palettes","text":"display image different color, can use palette parameter Map$addLayer() single band images. Palettes let set color scheme image displayed (learn palettes). Recall Earth Engine API tutorial colors palette linearly stretched min max.example, use green palette display forest extent image, use:result look something like Figure 8.Fgiure: Year 2000 forest cover South America.Zooming gives better sense resolution imagery. Figure 9 shows area around Mariscal Estigarribia Paraguay.Figure: Year 2000 treecover around Mariscal Estigarribia Paraguay.image shown Figure 3 bit dark. problem treecover2000 band byte data type ([0, 255]), fact values precentages ([0, 100]). brighten image, can set min /max parameters accordingly. palette stretched extrema.result look something like Figure 9. Note example, max set. min zero default.Figure: Year 2000 forest cover around Mariscal Estigarribia Paraguay, stretched [0, 100].","code":"\nMap$addLayer(gfc2014, list(\n  bands = c('treecover2000'),\n  palette = c('000000', '00FF00')\n), 'forest cover palette')\nMap$addLayer(gfc2014, list(\n  bands = c('treecover2000'),\n  palette = c('000000', '00FF00'),\n  max = 100\n), 'forest cover percent')"},{"path":"global-forest-change.html","id":"masking-3","chapter":"Global Forest Change","heading":"Masking","text":"images shown far big black areas data zero. example, trees ocean. make areas transparent, can mask values. Every pixel Earth Engine value mask. image rendered transparency set mask, zero completely transparent one completely opaque.can mask image . example, mask treecover2000 band , areas forest cover zero transparent:result look something like figure.Figure: Year 2000 tree cover, stretched masked.","code":"\nMap$addLayer(gfc2014$mask(gfc2014), list(\n  bands = c('treecover2000'),\n  palette = c('000000', '00FF00'),\n  max = 100\n), 'forest cover masked')"},{"path":"global-forest-change.html","id":"example","chapter":"Global Forest Change","heading":"Example","text":"’s almost possible make visualization Hansen data like one beginning tutorial. example, ’re putting everything together one small difference. Instead specifying bands parameter Map$addLayer call, ’re creating new images using select():result look something like Figure 11.Figure: Forest loss (red), year 2000 cover (green) gain (blue).Observe three addLayer() calls. addLayer() call adds layer map. Mousing Layers button upper right map reveals layers. layer can turned using checkbox next , opacity layer can affected slider next layer name.’re almost able make image shown start tutorial. However, layer showing pixels loss gain missing. missing need know perform calculations image bands can calculate pixels show loss gain. topic next section.","code":"\ntreeCover <- gfc2014$select(c('treecover2000'))\nlossImage <- gfc2014$select(c('loss'))\ngainImage <- gfc2014$select(c('gain'))\n\n# Add the tree cover layer in green.\nMap$addLayer(treeCover$updateMask(treeCover),\n             list(palette = c('000000', '00FF00'), max = 100), 'Forest Cover')+\n\n# Add the loss layer in red.\nMap$addLayer(lossImage$updateMask(lossImage),\n             list(palette = c('FF0000')), 'Loss')+\n\n# Add the gain layer in blue.\nMap$addLayer(gainImage$updateMask(gainImage),\n             list(palette = c('0000FF')), 'Gain')"},{"path":"global-forest-change.html","id":"quantifying-forest-change","chapter":"Global Forest Change","heading":"Quantifying Forest Change","text":"Let’s start calculation needed create band shows pixels Hansen et al. data show loss gain.Hansen et al. dataset band whose pixels 1 loss occurred 0 otherwise (loss) band 1 gain occurred 0 otherwise (gain). create band pixels loss gain bands 1, can use () logical method images. () method called like image1$(image2) returns image pixels 1 image1 image2 1, 0 elsewhere:result, zoomed Arkansas satellite view, look something like Figure 1.Figure: Pixels forest loss gain Arkansas.Combining example result previous section, ’s now possible recreate figure beginning tutorial:","code":"\n# Load the data and select the bands of interest.\ngfc2014 <- ee$Image('UMD/hansen/global_forest_change_2015')\nlossImage <-gfc2014$select('loss')\ngainImage <- gfc2014$select('gain')\n\n# Use the and() method to create the lossAndGain image.\ngainAndLoss <- gainImage$And(lossImage)\n\n# Show the loss and gain image.\nMap$addLayer(gainAndLoss$updateMask(gainAndLoss),\n             list(palette= 'FF00FF'), 'Gain and Loss')\n# Displaying forest, loss, gain, and pixels where both loss and gain occur.\ngfc2014 <- ee$Image('UMD/hansen/global_forest_change_2015')\nlossImage <- gfc2014$select('loss')\ngainImage <- gfc2014$select('gain')\ntreeCover <- gfc2014$select('treecover2000')\n\n# Use the and() method to create the lossAndGain image.\ngainAndLoss <- gainImage$And(lossImage)\n\n# Add the tree cover layer in green.\nMap$addLayer(treeCover$updateMask(treeCover),\n             list(palette= c('000000', '00FF00'), max= 100), 'Forest Cover')\n\n# Add the loss layer in red.\nMap$addLayer(lossImage$updateMask(lossImage),\n             list(palette= 'FF0000'), 'Loss')\n\n# Add the gain layer in blue.\nMap$addLayer(gainImage$updateMask(gainImage),\n             list(palette= '0000FF'), 'Gain')\n\n# Show the loss and gain image.\nMap$addLayer(gainAndLoss$updateMask(gainAndLoss),\n             list(palette= 'FF00FF'), 'Gain and Loss')"},{"path":"global-forest-change.html","id":"quantifying-forest-change-in-a-region-of-interest","chapter":"Global Forest Change","heading":"Quantifying Forest Change in a Region of Interest","text":"Now ’re familiar bands Hansen et al. dataset, can use concepts learned far compute statistics forest gain loss region interest. ’ll need use vector data (points, lines, polygons). vector dataset represented FeatureCollection Earth Engine. (Learn feature collections)section, ’ll compare total amount forest loss happened within Congo Republic year 2012 amount forest loss happened within country’s protected areas time.learned Earth Engine API tutorial, key method calculating statistics image region reduceRegion(). (Learn reducing image regions.) example, suppose want calculate number pixels estimated represent forest loss study period. purpose, consider following code:example uses ee$Reducer$sum() reducer sum values pixels lossImage within congo feature. lossImage consists pixels value 1 0 (loss loss, respectively), sum values equivalent number pixels loss region.Unfortunately, running script results error.default maximum number pixels reduceRegion() 10 million. error message indicates Congo Republic covers 383 million Landsat pixels. Luckily, reduceRegion() takes many parameters, one (maxPixels) lets control many pixels used computation. Specifying parameter allows computation succeed:expanding object printed console, observe result 4897933 pixels forest lost. can clean printout console bit labeling output getting result interest dictionary returned reduceRegion():","code":"\n# Load country features from Large Scale International Boundary (LSIB) dataset.\ncountries <- ee$FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n\n# Subset the Congo Republic feature from countries.\ncongo <- countries$filter(ee$Filter$eq('country_na', 'Rep of the Congo'))\n\n# Get the forest loss image.\ngfc2014 <- ee$Image('UMD/hansen/global_forest_change_2015')\nlossImage <- gfc2014$select('loss')\n\n# Sum the values of forest loss pixels in the Congo Republic.\nstats <- lossImage$reduceRegion(\n  reducer = ee$Reducer$sum(),\n  geometry = congo,\n  scale = 30\n)\nee$Dictionary$getInfo(stats)\n# Load country features from Large Scale International Boundary (LSIB) dataset.\ncountries <- ee$FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n\n# Subset the Congo Republic feature from countries.\ncongo <- countries$filter(ee$Filter$eq('country_na', 'Rep of the Congo'))\n\n# Get the forest loss image.\ngfc2014 <- ee$Image('UMD/hansen/global_forest_change_2015')\nlossImage <- gfc2014$select('loss')\n\n# Sum the values of forest loss pixels in the Congo Republic.\nstats <- lossImage$reduceRegion(\n  reducer = ee$Reducer$sum(),\n  geometry = congo,\n  scale = 30,\n  maxPixels = 1e9\n)\nee$Dictionary$getInfo(stats)\nprint(paste0(\"pixels representing loss: \", ee$Dictionary$getInfo(stats$get('loss'))))"},{"path":"global-forest-change.html","id":"calculating-pixel-areas","chapter":"Global Forest Change","heading":"Calculating Pixel Areas","text":"’re almost ready answer question much area lost Congo Republic, much protected areas. remaining part convert pixels actual area. conversion important don’t necessarily know size pixels input reduceRegion(). help compute areas, Earth Engine ee$Image$pixelArea() method generates image value pixel pixel’s area square meters. Multiplying loss image area image summing result gives us measure area:Now result 4,372,566,344 square meters lost study period.now ready answer question start section - much forest area lost Congo Republic 2012, much protected areas?output indicates 348,036,295 square meters forest lost Congo Republic 2012, 11,880,976 protected areas, represented World Database Protected Areas table.changes script one just prior addition protected area information changing script looking overall loss looking loss 2012. required two changes. First, ’s new lossIn2012 image 1 loss recorded 2012, 0 otherwise. Second, name band different (lossyear instead loss) property name change print statement.next section, explore advanced methods computing charting forest loss every year, instead just one year section.","code":"\n# Load country features from Large Scale International Boundary (LSIB) dataset.\ncountries <- ee$FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n\n# Subset the Congo Republic feature from countries.\ncongo <- countries$filter(ee$Filter$eq('country_na', 'Rep of the Congo'))\n\n# Get the forest loss image.\ngfc2014 <- ee$Image('UMD/hansen/global_forest_change_2015')\nlossImage <- gfc2014$select('loss')\nareaImage <- lossImage$multiply(ee$Image$pixelArea())\n\n# Sum the values of forest loss pixels in the Congo Republic.\nstats <- areaImage$reduceRegion(\n  reducer = ee$Reducer$sum(),\n  geometry = congo,\n  scale = 30,\n  maxPixels = 1e9\n)\n\nprint(paste0(\"pixels representing loss: \", ee$Dictionary$getInfo(stats$get('loss')), \" square meters\"))# Load country features from Large Scale International Boundary (LSIB) dataset.\ncountries <-  ee$FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n\n# Subset the Congo Republic feature from countries.\ncongo <- ee$Feature(\n  countries\n  $filter(ee$Filter$eq('country_na', 'Rep of the Congo'))\n  $first()\n)\n\n# Subset protected areas to the bounds of the congo feature\n# and other criteria. Clip to the intersection with congo.\nprotectedAreas <- ee$FeatureCollection('WCMC/WDPA/current/polygons')$filter(ee$Filter$And(\n  ee$Filter$bounds(congo$geometry()),\n  ee$Filter$neq('IUCN_CAT', 'VI'),\n  ee$Filter$neq('STATUS', 'proposed'),\n  ee$Filter$lt('STATUS_YR', 2010)\n))\n$map(function(feat){\n  return(congo$intersection(feat))\n})\n\n# Get the loss image.\ngfc2014 <- ee$Image('UMD/hansen/global_forest_change_2015')\nlossIn2012 <- gfc2014$select('lossyear')$eq(12)\nareaImage <- lossIn2012$multiply(ee$Image$pixelArea())\n\n# Calculate the area of loss pixels in the Congo Republic.\nstats <- areaImage$reduceRegion(\n  reducer = ee$Reducer$sum(),\n  geometry = congo$geometry(),\n  scale = 30,\n  maxPixels = 1e9\n)\n\nprint(paste0(\"Area lost in the Congo Republic: \", \n             ee$Dictionary$getInfo(stats$get('lossyear')),\n             \" square meters\")) \n\n# Calculate the area of loss pixels in the protected areas.\nstats <- areaImage$reduceRegion(\n  reducer = ee$Reducer$sum(),\n  geometry = protectedAreas$geometry(),\n  scale = 30,\n  maxPixels = 1e9\n)\n\nprint(paste0(\"Area lost in protected areas: \", \n             ee$Dictionary$getInfo(stats$get('lossyear')), \n             \" square meters\")) "},{"path":"global-forest-change.html","id":"charting-yearly-forest-loss","chapter":"Global Forest Change","heading":"Charting Yearly Forest Loss","text":"","code":""},{"path":"global-forest-change.html","id":"calculating-yearly-forest-loss","chapter":"Global Forest Change","heading":"Calculating Yearly Forest Loss","text":"previous section learned calculate total forest area lost given region interest using reduceRegion method. Instead calculating total loss, helpful compute loss year. way achieve Earth Engine using Grouped Reducer.group output reduceRegion(), can specify grouping band defines groups integer pixel values. following example, slightly modify previous code add lossYear band original image. pixel lossYear band contain values 0 14 - indicating year loss occurred. also change reducer grouped reducer, specifying band index grouping band (1) pixel areas summed grouped according value lossYear band.run code, see yearly forest loss area printed nested list called groups. can format output little make result dictionary, year key loss area value. Notice using format() method convert year values 0-14 2000-2014.","code":"\n# Load country boundaries from LSIB.\ncountries <- ee$FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n# Get a feature collection with just the Congo feature.\ncongo <- countries$filter(ee$Filter$eq('country_co', 'CF'))\n\n# Get the loss image.\n# This dataset is updated yearly, so we get the latest version.\ngfc2017 <- ee$Image('UMD/hansen/global_forest_change_2017_v1_5')\nlossImage <- gfc2017$select('loss')\nlossAreaImage <- lossImage$multiply(ee$Image$pixelArea())\n\nlossYear <- gfc2017$select('lossyear')\nlossByYear <- lossAreaImage$addBands(lossYear)$reduceRegion(\n  reducer = ee$Reducer$sum()$group(\n    groupField = 1\n  ),\n  geometry = congo,\n  scale = 30,\n  maxPixels = 1e9\n)\n\nprint(ee$Dictionary$getInfo(lossByYear)) var statsFormatted = ee.List(lossByYear.get('groups'))\n  .map(function(el) {\n    var d = ee.Dictionary(el);\n    return [ee.Number(d.get('group')).format(\"20%02d\"), d.get('sum')];\n  });\nvar statsDictionary = ee.Dictionary(statsFormatted.flatten());\nprint(statsDictionary);"},{"path":"global-forest-change.html","id":"making-a-chart","chapter":"Global Forest Change","heading":"Making a chart","text":"","code":"var chart = ui.Chart.array.values({\n  array: statsDictionary.values(),\n  axis: 0,\n  xLabels: statsDictionary.keys()\n}).setChartType('ColumnChart')\n  .setOptions({\n    title: 'Yearly Forest Loss',\n    hAxis: {title: 'Year', format: '####'},\n    vAxis: {title: 'Area (square meters)'},\n    legend: { position: \"none\" },\n    lineWidth: 1,\n    pointSize: 3\n  });\nprint(chart);"},{"path":"global-forest-change.html","id":"introduction-to-forest-monitoring-for-action-forma-data","chapter":"Global Forest Change","heading":"Introduction to Forest Monitoring for Action (FORMA) data","text":"FORMA MODIS based 500 x 500 meter twice-monthly deforestation alerting system humid tropical forests. FORMA 500 dataset Earth Engine image alerts starting January 2006 updated monthly. alert time associated single band named alert_date units epoch seconds. Filtering FORMA dates calculating alerts within areas interest two important things can FORMA dataset.","code":""},{"path":"global-forest-change.html","id":"filtering-forma-by-date","chapter":"Global Forest Change","heading":"Filtering FORMA by Date","text":"show just alerts occur 2012, find pixels times first day 2012 first day 2013, expressed seconds since midnight, January 1, 1970:example, forma2012 binary image containing pixels times occurring 2012 (.e. pixels masked).","code":"\n# Convert dates from milliseconds to seconds.\nstart <- ee$Date('2012-01-01')$millis()$divide(1000)\nend <- ee$Date('2013-01-01')$millis()$divide(1000)\n\n# Load the FORMA 500 dataset.\nforma <- ee$Image('FORMA/FORMA_500m')\n\n# Create a binary layer from the dates of interest.\nforma2012 <- forma$gte(start)$And(forma$lte(end))\n\nMap$setCenter(15.87, -0.391, 7)\nMap$addLayer(\n  forma2012$mask(forma2012),\n  list(palette = 'FF0000'),\n  'FORMA alerts in 2012'\n)"},{"path":"global-forest-change.html","id":"counting-forma-alerts-in-a-region-of-interest","chapter":"Global Forest Change","heading":"Counting FORMA Alerts in a Region of Interest","text":"previous section Hansen et al. data, can start counting number FORMA alerts (pixels) area interest. example, count number alerts protected areas Congo Republic 2012, build previous example follows:","code":"\n# Load country features from Large Scale International Boundary (LSIB) dataset.\ncountries <- ee$FeatureCollection('USDOS/LSIB_SIMPLE/2017')\n\n# Subset the Congo Republic feature from countries.\ncongo <- ee$Feature(\n  countries$\n    filter(ee$Filter$eq('country_na', 'Rep of the Congo'))$\n    first()\n)\n\n# Subset protected areas to the bounds of the congo feature\n# and other criteria. Clip to the intersection with congo.\nprotectedAreas <- ee$FeatureCollection('WCMC/WDPA/current/polygons')$\n  filter(ee$Filter$And(\n    ee$Filter$bounds(congo$geometry()),\n    ee$Filter$neq('IUCN_CAT', 'VI'),\n    ee$Filter$neq('STATUS', 'proposed'),\n    ee$Filter$lt('STATUS_YR', 2010)\n  ))$map(function(feat){\n    return(congo$intersection(feat))\n  })\n\n# Display protected areas on the map.\nMap$addLayer(\n  protectedAreas,\n  list(color = '000000'),\n  'Congo Republic protected areas'\n)\n\n# Calculate the number of FORMA pixels in protected\n# areas of the Congo Republic, 2012.\nstats <- forma2012$reduceRegion(\n  reducer = ee$Reducer$sum(),\n  geometry = protectedAreas$geometry(),\n  scale = 500\n)\n\nprint(paste0('Number of FORMA pixels, 2012: ', ee$Dictionary$getInfo(stats$get('constant'))))"},{"path":"global-forest-change.html","id":"counting-forma-alerts-in-several-regions-of-interest","chapter":"Global Forest Change","heading":"Counting FORMA Alerts in Several Regions of Interest","text":"far, ’ve computing statistics single region time. computing statistics multiple regions , can use reduceRegions(). building previous example:Examine object printed console observe output reduceRegions() another FeatureCollection. Note every region collection Congo Republic protected areas now additional property, sum, named reducer. value property output reducer, number 2012 alerts protected areas.","code":"\n\nregionsStats <- forma2012$reduceRegions(\n  collection = protectedAreas,\n  reducer = ee$Reducer$sum(),\n  scale = forma2012$projection()$nominalScale()\n)\n\nprint(ee$Dictionary$getInfo(regionsStats))\n      "},{"path":"global-forest-change.html","id":"comparing-forma-and-hansen-et-al.-datasets","chapter":"Global Forest Change","heading":"Comparing FORMA and Hansen et al. Datasets","text":"compare FORMA Hansen et al. datasets, can use logical operators. (Learn logical operations). Specifically, ’d like make image pixels marked FORMA Hansen et al. data deforestation 1 rest zero. code makes image 2012 displays along predicted deforestation layers:concludes overview forest change datasets Earth Engine. ’re looking forward seeing can !","code":"\n# Convert dates from milliseconds to seconds.\nstart <- ee$Date('2012-01-01')$millis()$divide(1000)\nend <- ee$Date('2013-01-01')$millis()$divide(1000)\nregion <- ee$Geometry$Rectangle(c(-59.81163, -9.43348, -59.27561, -9.22818))\n\n# Load the FORMA 500 dataset.\nforma <- ee$Image('FORMA/FORMA_500m')\n\n# Create a binary layer from the dates of interest.\nforma2012 <- forma$gte(start)$And(forma$lte(end))\n\n# Load Hansen et al. data and get change in 2012.\ngfc <- ee$Image('UMD/hansen/global_forest_change_2015')\ngfc12 <- gfc$select('lossyear')$eq(12)\n\n# Create an image which is one where the datasets\n# both show deforestation and zero elsewhere.\ngfc_forma <- gfc12$eq(1)$And(forma2012$eq(1))\n\n# Display data on the map.\nMap$setCenter(-59.58813, -9.36439, 11)\nMap$addLayer(forma$updateMask(forma), list(palette = '00FF00'), 'Forma (green)')\nMap$addLayer(gfc12$updateMask(gfc12), list(palette = 'FF0000'), 'Hansen (red)')\nMap$addLayer(\n  gfc_forma$updateMask(gfc_forma),\n  list(palette = 'FFFF00'),\n  'Hansen & FORMA (yellow)'\n)"},{"path":"global-surface-water.html","id":"global-surface-water","chapter":"Global Surface Water","heading":"Global Surface Water","text":"section requires next libraries:","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()"},{"path":"global-surface-water.html","id":"introduction-1","chapter":"Global Surface Water","heading":"Introduction","text":"Welcome Google Earth Engine tutorial working global surface water (GSW) dataset. dataset described Nature letter High-resolution mapping global surface water long-term changes. tutorial provides examples use Earth Engine visualize data layers available GSW dataset, presents typical visualizations analyses.tutorial broken sections. Within section, code built gradually short code snippets explanatory text. end section, complete working script presented.","code":""},{"path":"global-surface-water.html","id":"references","chapter":"Global Surface Water","heading":"References","text":"High-resolution mapping global surface water long-term changes (online viewer)\nGet water governance global agenda (Nature editorial)\nGlobal Surface Water Explorer (web application)\nData Users Guide (v2)\nHigh-resolution mapping global surface water long-term changes (online viewer)Get water governance global agenda (Nature editorial)Get water governance global agenda (Nature editorial)Global Surface Water Explorer (web application)Global Surface Water Explorer (web application)Data Users Guide (v2)Data Users Guide (v2)","code":""},{"path":"global-surface-water.html","id":"audience","chapter":"Global Surface Water","heading":"Audience","text":"tutorial assumes familiar concepts presented Earth Engine Rstudio documentation pages worked Earth Engine API tutorial.","code":""},{"path":"global-surface-water.html","id":"license-and-attribution-1","chapter":"Global Surface Water","heading":"License and Attribution","text":"GSW data described tutorial produced Copernicus Programme provided free charge, without restriction use. full license information see Copernicus Regulation.using data layer published map, please include following attribution text:","code":""},{"path":"global-surface-water.html","id":"get-access-to-earth-engine","chapter":"Global Surface Water","heading":"Get access to Earth Engine","text":"Access Earth Engine free, requires signup. get access, please fill Earth Engine signup form apply Evaluator account. granted access receive email within business days instructions.’re familiar Rstudio, get started next section!","code":""},{"path":"global-surface-water.html","id":"water-occurrence-1984-2015","chapter":"Global Surface Water","heading":"Water Occurrence (1984-2015)","text":"GSW dataset contains many data layers present surface water data different ways. start visualizing water occurrence layer, provides summary often surface water occurred entire time-period March 1984 October 2015.section tutorial :add map layer visualizing surface water occurrence,show query values map layer,add custom styling improve visualization,create binary water mask layer using threshold value,center map interesting parts world, andshow refactor script make readable maintainable.","code":""},{"path":"global-surface-water.html","id":"creating-a-basic-visualization","chapter":"Global Surface Water","heading":"Creating a Basic Visualization","text":"Start copying following statements Code Editor:first statement references Earth Engine Image object GSW dataset, stores variable named gsw. second statement selects single layer GSW dataset, stores variable called occurrence. third statement adds occurrence image Rstudio’s interactive map.Click Rstudio’s “Run” button, seconds see map grey coloring along coastlines, similar Figure 1.Figure: Default visualization global surface water occurrence data layer.areas, GSW dataset appears transparent, locations either Landsat images collected (.e. ocean areas) water detected observations 32 years masked .","code":"\ngsw <- ee$Image('JRC/GSW1_0/GlobalSurfaceWater')\noccurrence <- gsw$select('occurrence')\nMap$addLayer(occurrence)"},{"path":"global-surface-water.html","id":"refactoring-to-improve-your-code","chapter":"Global Surface Water","heading":"Refactoring to Improve Your Code","text":"script contains two statements, already opportunity refactor code final script easier read maintain time. Currently, Map$addLayer() statement passes single argument occurrence, Earth Engine image object want display map. However, Map$addLayer() method also allows additional arguments passed . quickly see arguments available, place cursor opening parentheses press keyboard shortcut “Show code suggestions” bring help document addLayer method.keyboard shortcuts show five arguments can passed Map$addLayer: eeObject, visParams, name, shown, opacity. current script passing single variable occurrence interpreted first argument, eeObject. pass variable object additional argument names layer, can refactor code use “named arguments” (eeObject name) passed within method within JSON data structure shown :Run code make sure still works refactoring changes. resulting map remain unchanged.","code":"\nMap$addLayer(eeObject = occurrence, name = 'Water Occurrence (1984-2015)')"},{"path":"global-surface-water.html","id":"adding-visualization-parameters","chapter":"Global Surface Water","heading":"Adding Visualization Parameters","text":"Next, work improving upon default visualization parameters, making water appear gray. Add new statement creates variable VIS_OCCURRENCE pass additional argument addLayer method.visualization parameters stored JSON structure VIS_OCCURRENCE indicate red used minimum value 0% blue maximum value 100%. addition $updateMask(occurrence$divide(100)) causes opacity/transparency pixels set based occurrence value.Run script , view revised results styling changes.Screenshot water occurrence Paraná Delta near Buenos Aires, using transparent red color 0% minimum value endpoint solid blue color maximum value endpoint.water areas now blue! Progress!","code":"\nVIS_OCCURRENCE <- list(\n  min = 0,\n  max = 100,\n  palette = c(\"red\", \"blue\")\n)\nMap$addLayer(\n  eeObject = occurrence$updateMask(occurrence$divide(100)),\n  name = \"Water Occurrence (1984-2015)\",\n  visParams = VIS_OCCURRENCE\n)"},{"path":"global-surface-water.html","id":"creating-a-threshold-layer","chapter":"Global Surface Water","heading":"Creating a Threshold Layer","text":"water occurrence image contains information often water expected using range values 0 100%. However, often useful define binary water layer (.e. “water” vs. “non-water”) based certain percentage occurrence (.e. threshold value). use simple binary layer clean background layer GSW layers can placed. Creating threshold layer can done using following statements, uses threshold value 90% separate water non-water.First define new visualization variable VIS_WATER_MASK holding styling information water mask:calculate water mask layer using greater comparison operator $gt(90) set previously masked areas zero using $unmask() method:finally, add layer map. order layer rendered layers, place following statement Map$addLayer statements.Figure: Screenshot 90% water mask Paraná Delta near Buenos Aires.","code":"\nVIS_WATER_MASK <- list(\n  palette = c(\"white\", \"black\")\n)\n# Create a water mask layer, and set the image mask so that non-water areas\n# are opaque.\nwater_mask <- occurrence$gt(90)$unmask(0)\nMap$addLayer(\n  eeObject = water_mask,\n  visParams = VIS_WATER_MASK,\n  name = \"90% occurrence water mask\"\n)"},{"path":"global-surface-water.html","id":"going-to-interesting-parts-of-the-world","chapter":"Global Surface Water","heading":"Going to Interesting Parts of the World","text":"fun explore world panning zooming around, world large sometimes helps jump directly particular location. series statements provide small sample interesting locations, terms surface water. Just uncomment one statements time, script go location run.just small sample interesting locations. Feel free add !","code":"\n# Uncomment one of the following statements to center the map.\n# Map$setCenter(-90.162, 29.8597, 10)   # New Orleans, USA\n# Map$setCenter(-114.9774, 31.9254, 10) # Mouth of the Colorado River, Mexico\n# Map$setCenter(-111.1871, 37.0963, 11) # Lake Powell, USA\n# Map$setCenter(149.412, -35.0789, 11)  # Lake George, Australia\n# Map$setCenter(105.26, 11.2134, 9)     # Mekong River Basin, SouthEast Asia\n# Map$setCenter(90.6743, 22.7382, 10)   # Meghna River, Bangladesh\n# Map$setCenter(81.2714, 16.5079, 11)   # Godavari River Basin Irrigation Project, India\n# Map$setCenter(14.7035, 52.0985, 12)   # River Oder, Germany & Poland\n# Map$setCenter(-59.1696, -33.8111, 9)  # Buenos Aires, Argentina\nMap$setCenter(-74.4557, -8.4289, 11) # Ucayali River, Peru"},{"path":"global-surface-water.html","id":"refactoring-again","chapter":"Global Surface Water","heading":"Refactoring, again…","text":"move next layer GSW dataset, going little code refactoring. Specifically, group similar statements together, add comments break code sections assets, constants, calculations, centering map adding map layers.final refactored script:next section, explore water occurrence changed time.","code":"\n#############################################################\n# Asset List\n#############################################################\n\ngsw <- ee$Image(\"JRC/GSW1_0/GlobalSurfaceWater\")\noccurrence <- gsw$select(\"occurrence\")\n\n#############################################################\n# Constants\n#############################################################\n\nVIS_OCCURRENCE <- list(\n  min = 0,\n  max = 100,\n  palette = c(\"red\", \"blue\")\n)\n\n\nVIS_WATER_MASK <- list(\n  palette = c(\"white\", \"black\")\n)\n\n#############################################################\n# Calculations\n#############################################################\n\n# Create a water mask layer, and set the image mask so that non-water areas\n# are opaque.\nwater_mask <- occurrence$gt(90)$unmask(0)\n\n#############################################################\n# Initialize Map Location\n#############################################################\n\n# Uncomment one of the following statements to center the map.\n# Map$setCenter(-90.162, 29.8597, 10)   # New Orleans, USA\n# Map$setCenter(-114.9774, 31.9254, 10) # Mouth of the Colorado River, Mexico\n# Map$setCenter(-111.1871, 37.0963, 11) # Lake Powell, USA\n# Map$setCenter(149.412, -35.0789, 11)  # Lake George, Australia\n# Map$setCenter(105.26, 11.2134, 9)     # Mekong River Basin, SouthEast Asia\n# Map$setCenter(90.6743, 22.7382, 10)   # Meghna River, Bangladesh\n# Map$setCenter(81.2714, 16.5079, 11)   # Godavari River Basin Irrigation Project, India\n# Map$setCenter(14.7035, 52.0985, 12)   # River Oder, Germany & Poland\n# Map$setCenter(-59.1696, -33.8111, 9)  # Buenos Aires, Argentina\nMap$setCenter(-74.4557, -8.4289, 11) # Ucayali River, Peru\n\n#############################################################\n# Map Layers\n#############################################################\n\nMap$addLayer(\n  eeObject = water_mask,\n  visParams = VIS_WATER_MASK,\n  name = \"90% occurrence water mask\",\n  shown = FALSE\n) |\nMap$addLayer(\n  eeObject = occurrence$updateMask(occurrence$divide(100)),\n  name = \"Water Occurrence (1984-2015)\",\n  visParams = VIS_OCCURRENCE\n)"},{"path":"global-surface-water.html","id":"water-occurrence-change-intensity","chapter":"Global Surface Water","heading":"Water Occurrence Change Intensity","text":"Water Occurrence Change Intensity data layer provides measure surface water changed two epochs: 1984-1999 2000-2015. layer averages change across homologous pairs months taken two epochs. See Data Users Guide (v2) additional details layer.section tutorial :add styled map layer visualizing water occurrence change intensity, andsummarize change intensity specified region--interest using histogram.","code":""},{"path":"global-surface-water.html","id":"visualization-1","chapter":"Global Surface Water","heading":"Visualization","text":"Similar water occurrence layer, start adding basic visualization occurrence change intensity map improve upon . Occurrence change intensity provided two ways, absolute normalized values. use absolute values tutorial. Start selecting absolute occurrence change intensity layer GSW image:Constants section code, add statement creates new variable defines layer styled. styling shows areas surface water occurrence decreased/increased red/green. Areas surface water occurrence relatively unchanged shown black.end Map Layers section code, add statement adds new layer map.Figure: Screenshot surface water change intensity Ucayali River near Pucallpa, city Amazonian rainforest eastern Peru. Red/green indicates decrease/increase surface water occurrence epochs.","code":"\nchange <- gsw$select(\"change_abs\")\nVIS_CHANGE <- list(\n  min = -50,\n  max = 50,\n  palette = c(\"red\", \"black\", \"limegreen\")\n)\nMap$setCenter(-74.4557, -8.4289, 11) # Ucayali River, Peru\nMap$addLayer(\n  eeObject = change,\n  visParams = VIS_CHANGE,\n  name = \"occurrence change intensity\"\n)"},{"path":"global-surface-water.html","id":"water-class-transition","chapter":"Global Surface Water","heading":"Water Class Transition","text":"water transition layer captures changes three classes water occurrence (water, seasonal water, permanent water) along two additional classes ephemeral water (ephemeral permanent ephemeral seasonal).section tutorial :add map layer visualizing water transition,create grouped reducer summing area transition class within specified region--interest, andcreate chart summarizes area transition class.","code":""},{"path":"global-surface-water.html","id":"basic-visualization","chapter":"Global Surface Water","heading":"Basic Visualization","text":"Asset List section script, add following statement creates single band image object called transition:GSW images contain metadata transition class numbers names, default palette styling transition classes. transition layer added map, visualzation parameters used automatically.bottom Map Layers section script, add following statement adds new map layer displays transition classes:run script, transition layer displayed.Figure: Screenshot Mekong River delta, showing wide variation surface water class transitions.map key transition classes :","code":"\ntransition <- gsw$select(\"transition\")\nMap$setCenter(105.26, 11.2134, 9) # Mekong River Basin, SouthEast Asia\nMap$addLayer(\n  eeObject = transition,\n  name = \"Transition classes (1984-2015)\",\n)"},{"path":"global-surface-water.html","id":"summarizing-area-by-transition-class","chapter":"Global Surface Water","heading":"Summarizing Area by Transition Class","text":"section use geometry polygon tool define region--interest. want analyze new location, want first select delete original polygon create don’t get results combined areas. See Geometry tools section Rstudio information modify geometries.example create new polygon within Mekong River delta.Figure: Mekong River delta Vietnam, region--interest.order calculate area covered parts image, add additional band transition image object identifies size pixel square meters using ee$Image$pixelArea method.resulting image object (area_image_with_transition_class) two band image first band contains area information units square meters (produced ee$Image$pixelArea code> method), second band contains transition class information.summarize class transitions within region interest (roi) using ee$Image$reduceRegion method grouped reducer acts sum area within transition class:","code":"\nroi <- ee$Geometry$Polygon(\n  c(\n    c(105.61356262001948, 10.292654070507828),\n    c(105.96512512001948, 10.514171198992166),\n    c(105.73166564736323, 10.765211642467452),\n    c(105.37735656533198, 10.516871653561891)\n  )\n)\nMap$setCenter(105.26, 11.2134, 9) # Mekong River Basin, SouthEast Asia\nMap$addLayer(\n  eeObject = transition,\n  name = \"Transition classes (1984-2015)\",\n) +\n  Map$addLayer(roi, list(color = \"red\"), \"roi\")\narea_image_with_transition_class <- ee$Image$pixelArea()$addBands(transition)\nreduction_results <- area_image_with_transition_class$reduceRegion(\n  reducer = ee$Reducer$sum()$group(\n    groupField = 1,\n    groupName = \"transition_class_value\"\n  ),\n  geometry = roi,\n  scale = 30,\n  bestEffort = TRUE\n)\n\nprint(ee$Dictionary$getInfo(reduction_results))"},{"path":"video-tutorials-1.html","id":"video-tutorials-1","chapter":"Video Tutorials","heading":"Video Tutorials","text":"","code":""},{"path":"video-tutorials-1.html","id":"tutorials-1","chapter":"Video Tutorials","heading":"Tutorials","text":"video tutorials lectures hands-trainings conducted Earth Engine User Summits Earth Outreach digital events.","code":""},{"path":"video-tutorials-1.html","id":"introduction-to-earth-engine-condensed","chapter":"Video Tutorials","heading":"Introduction to Earth Engine (condensed)","text":"Learn Earth Engine developer advocate Noel Gorelick fast-paced intro.companion slidescode repository","code":""},{"path":"video-tutorials-1.html","id":"hands-on-intermediate-training","chapter":"Video Tutorials","heading":"Hands-on Intermediate Training","text":"Topics covered include classification, spectral unmixing terrain visualization.","code":""},{"path":"video-tutorials-1.html","id":"tables-and-vectors","chapter":"Video Tutorials","heading":"Tables and Vectors","text":"Overview tables vectors Earth Engine. Topics include load, manipulate, display analyze vector tabular data Earth Engine.companion slides","code":""},{"path":"video-tutorials-1.html","id":"importing-and-exporting","chapter":"Video Tutorials","heading":"Importing and Exporting","text":"Topics covered include importing exporting Earth Engine data, command line interface, map publishing.","code":""},{"path":"video-tutorials-1.html","id":"classification","chapter":"Video Tutorials","heading":"Classification","text":"Learn classifiers (supervised unsupervised), training data, test data, dreaded “computed value large” message, awesome linear regression reducer.companion slidesTopics covered include supervised unsupervised classification.","code":""},{"path":"video-tutorials-1.html","id":"machine-learning","chapter":"Video Tutorials","heading":"Machine Learning","text":"","code":""},{"path":"video-tutorials-1.html","id":"machine-learning-best-practices","chapter":"Video Tutorials","heading":"Machine Learning Best Practices","text":"pace modern machine learning, building training neural networks hard. Learn best practices sift overwhelming amount information available focus remote sensing.companion slides","code":""},{"path":"video-tutorials-1.html","id":"neural-segmentation","chapter":"Video Tutorials","heading":"Neural Segmentation","text":"Arguably common application ML earth observation imagery pixel level segmentation regression. neural networks, whole new set techniques possible eclipse existing methods terms generality, come set challenges. Learn applications training regimens ranging supervised fully unsupervised.companion slides","code":""},{"path":"video-tutorials-1.html","id":"arrays-and-matrices","chapter":"Video Tutorials","heading":"Arrays and Matrices","text":"Overview array matrix operations Earth Engine way. Topics include linear modeling, matrix solving, eigen analysis, covariance reducers.companion slides","code":""},{"path":"video-tutorials-1.html","id":"time-series-analysis","chapter":"Video Tutorials","heading":"Time Series Analysis","text":"Overview time series analysis Earth Engine way. Topics covered include linear modeling, auto-correlation, cross-correlation, auto-regressive models smoothing.companion slides","code":""},{"path":"video-tutorials-1.html","id":"earth-engine-and-the-google-cloud-platform","chapter":"Video Tutorials","heading":"Earth Engine and the Google Cloud Platform","text":"Introduction interoperability Earth Engine Google Cloud Platform.companion slides","code":""},{"path":"video-tutorials-1.html","id":"google-maps-api","chapter":"Video Tutorials","heading":"Google Maps API","text":"Create “Hello World” Maps API webpage, learn things like change options (background map type, initial location, etc.), overlay data KML layers, start showcase first Earth Engine maps.companion slides","code":""},{"path":"video-tutorials-1.html","id":"publishing-and-storytelling-with-your-earth-engine-results","chapter":"Video Tutorials","heading":"Publishing and storytelling with your Earth Engine results","text":"Get overview use Google’s geo tools tell stories share data. Topics include Google Earth, Google Maps (APIs), Maps, Tour Builder, Street View.companion slides","code":""},{"path":"video-tutorials-1.html","id":"datasets","chapter":"Video Tutorials","heading":"Datasets","text":"","code":""},{"path":"video-tutorials-1.html","id":"synthetic-aperture-radar-sentinel-1","chapter":"Video Tutorials","heading":"Synthetic Aperture Radar (Sentinel-1)","text":"Take deep dive one unique datasets Earth Engine data catalog. session provides introduction Synthetic Aperture Radar (SAR) data working scripts analyzing Sentinel-1 SAR data.companion slides","code":""},{"path":"how-earth-engine-works.html","id":"how-earth-engine-works","chapter":"How Earth Engine works","heading":"How Earth Engine works","text":"","code":""},{"path":"how-earth-engine-works.html","id":"overview-2","chapter":"How Earth Engine works","heading":"Overview","text":"Earth Engine like GIS ever used ! Earth Engine cloud-based platform, incredibly powerful. also strange wondrous. purpose docs Earth Engine works section demystify potentially surprising behavior may encounter running scripts Rstuio. includes:Distinguishing R objects client Earth Engine objects server. See Client vs. Server.\nlazy computation model. See Deferred Execution.\nEarth Engine handles scale (pixel resolution). See Scale.\nEarth Engine handles map projections. See Projections.\nlazy computation model. See Deferred Execution.Earth Engine handles scale (pixel resolution). See Scale.Earth Engine handles map projections. See Projections.","code":""},{"path":"client-vs-server.html","id":"client-vs-server","chapter":"Client vs Server","heading":"Client vs Server","text":"important distinguish Earth Engine objects R objects primitives might code. can manipulate objects server manipulating client-side “proxy” objects script. can recognize proxy object anything starting ee. Earth Engine proxy objects contain actual data just handles objects server. start, consider client-side R string object (proxy object):Observe console output web browser (called ‘client’ doc) interpreted code run , determining clientString type string. Now suppose want Earth Engine able something string. , need wrap string nice container send Google. container proxy object. ’s example:Observe console output ee$String object, string. specifically, ’s ee$computedObject, means ’s proxy object something server. Think ee$Thing way put thing container sending Google. client doesn’t know ’s container, can find ’s printing :see container looks like, call toString() object:need find ’s container, just print() inspect result console. , reason, need use R running client manipulate whatever container, use getInfo() get contents container assign variable:shouldn’t use getInfo() unless absolutely need . call getInfo() code, Earth Engine open container tell ’s inside, block rest code ’s done. (can optionally provide callback function avoid , better option everything server, possible.)","code":"var clientString = 'I am a String';\nprint(typeof clientString);  // stringvar serverString = ee.String('I am not a String!');\nprint(typeof serverString);  // object\nprint('Is this an EE object?',\n    serverString instanceof ee.ComputedObject);  // trueprint(serverString);  // I am not a Stringprint(serverString.toString());  // ee.String(\"I am not a String!\")var someString = serverString.getInfo();\nvar strings = someString + '  Am I?';\nprint(strings);  // I am not a String!  Am I?"},{"path":"client-vs-server.html","id":"looping","chapter":"Client vs Server","heading":"Looping","text":"client doesn’t know ’s server-side ee$Thing objects, R functionality conditionals -loops work . reason, avoid synchronous calls getInfo(), use server functions extent possible. example, consider following two ways creating list:recommended — client-side -loopRecommended — server-side mappingThe server-side mapping example little silly make list simply ee$List$sequence(1, 8), illustrates important concepts. first concept map() simply applies function everything list. function executed server, client-side functions print() won’t work mapped function. reason, + 1 code replaced equivalent server-side code: ee$Number(n)$add(1). Importantly, n object exists server. function doesn’t know type argument, needs cast ee.Number.’s also worth noting occasionally client-side functionality convenient. example, previous loop used build list wrap server-side object:Realize client-side processing done browser, using machine’s CPU, can less efficient using Earth Engine work server. Also, avoid potentially surprising results, good practice avoid mixing client server functionality scripts. Conditionals section provides example possibly unintended consequences.","code":"var clientList = [];\nfor(var i = 0; i < 8; i++) {\n  clientList.push(i + 1);\n}\nprint(clientList);var serverList = ee.List.sequence(0, 7);\nserverList = serverList.map(function(n) {\n  return ee.Number(n).add(1);\n});\nprint(serverList);var toServerList = ee.List(clientList);"},{"path":"client-vs-server.html","id":"conditionals","chapter":"Client vs Server","heading":"Conditionals","text":"Server-side objects don’t necessarily work client side functions vice versa. example, consider case server-side Boolean variable:Note server-side Boolean results executing method server object. appears client variable print() print() opens container tells ’s inside. However, shown following example, variable behave client-side conditional server-side object. correctly check server-side boolean, use server-side function:recommended — client-side conditionalRecommended — server-side conditional","code":"var myList = ee.List([1, 2, 3]);\nvar serverBoolean = myList.contains(5);\nprint(serverBoolean);  // falsevar clientConditional;\nif (serverBoolean) {\n  clientConditional = true;\n} else {\n  clientConditional = false;\n}\nprint('Should be false:', clientConditional);  // True!var serverConditional = ee.Algorithms.If(serverBoolean, 'True!', 'False!');\nprint('Should be false:', serverConditional);  // False!"},{"path":"client-vs-server.html","id":"client-and-server-functions","chapter":"Client vs Server","heading":"Client and Server Functions","text":"previous sections describe several reasons inefficient illogical mix client server objects functions. objects functions client-side server-side? general, thing initialized ee$Thing server object method object, ee$Thing$method(), server function. contrast, class Rstudio API reference doesn’t start ee client-side well. Examples include print(), Map, Export Chart. Objects functions appear R reference client-side. R literal object create client-side object. noted previously, can use client-side functionality create object, wrap supplying client-side object Earth Engine constructor, example ee$String().","code":""},{"path":"deferred-exacution.html","id":"deferred-exacution","chapter":"Deferred exacution","heading":"Deferred exacution","text":"Client vs. Server doc describes objects referenced script can either client-side server-side. complete script contains objects want use, also set instructions tell Earth Engine . doc describes instructions sent Google processing results sent back web browser (client) display.write script Earth Engine (R), code run directly Earth Engine servers Google. Instead, client library encodes script set JSON objects, sends objects Google waits response. object represents set operations required get particular output, image display client, example. Consider following R code, run Rstudio:first print statement output JSON structure client library uses describe image server Google:second print statement send request Google output POST response Google servers. see response JSON glory, click JSON link right side console, next printed object:Nothing sent Google processing request . example, print() sufficient request result computation. (R, ’s necessary call getInfo() object printed; otherwise request JSON printed). processing done server result explicitly requested.Another example requesting something displaying map Map$addLayer(). request sent Google, tiles necessary display result Rstudio returned. Specifically, position map zoom level determine data get processed turned images can displayed map. pan zoom, note tiles computed lazily. -demand system allows parallelization efficient processing, also means image displayed map produced different inputs depending zoom level location map bounds visible Rstudio. Learn inputs computation determined request Scale doc.","code":"var image = ee.Image('CGIAR/SRTM90_V4');\nvar operation = image.add(10);\nprint(operation.toString());\nprint(operation);ee.Image({\n  \"type\": \"Invocation\",\n  \"arguments\": {\n    \"image1\": {\n      \"type\": \"Invocation\",\n      \"arguments\": {\n        \"id\": \"CGIAR/SRTM90_V4\"\n      },\n      \"functionName\": \"Image.load\"\n    },\n    \"image2\": {\n      \"type\": \"Invocation\",\n      \"arguments\": {\n        \"value\": 10\n      },\n      \"functionName\": \"Image.constant\"\n    }\n  },\n  \"functionName\": \"Image.add\"\n})\n    {\n  \"type\": \"Image\",\n  \"bands\": [\n    {\n      \"id\": \"elevation\",\n      \"data_type\": {\n        \"type\": \"PixelType\",\n        \"precision\": \"int\",\n        \"min\": -32758,\n        \"max\": 32777\n      },\n      \"crs\": \"EPSG:4326\",\n      \"crs_transform\": [\n        0.0008333333535119891,\n        0,\n        -180,\n        0,\n        -0.0008333333535119891,\n        60\n      ]\n    }\n  ]\n}\n    "},{"path":"scale.html","id":"scale","chapter":"Scale","heading":"Scale","text":"section requires next libraries:Understanding Earth Engine handles scale crucial interpreting scientific results obtained Earth Engine. , scale means pixel resolution. Unlike GIS image processing platforms, scale analysis determined output, rather input. Specifically, make request results, image display statistic, example, specify scale data input analysis. concept illustrated Figure 1.Figure: graphic representation image dataset Earth Engine. Dashed lines represent pyramiding policy aggregating 2x2 blocks 4 pixels. Earth Engine uses scale specified output determine appropriate level image pyramid use input.","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()"},{"path":"scale.html","id":"image-pyramids","chapter":"Scale","heading":"Image Pyramids","text":"Image assets Earth Engine exist multiple scales, image pyramids. pyramiding policy (represented dashed lines Figure 1) determines pixel given level pyramid computed aggregation 2x2 block pixels next lower level. continuous valued images, pixel values upper levels pyramid mean pixels next lower level. discrete valued images, pixel values upper levels pyramid sample (usually top left pixel) pixels next lower level.lowest level image pyramid represents image data native resolution, ingested Earth Engine. ingestion, data aggregated (according pyramiding policy) create higher pyramid levels. data aggregated entire image fits within 256x256 pixel tile. use image code, Earth Engine chooses level pyramid closest scale less equal scale specified analysis resamples (using nearest neighbor default) necessary.","code":""},{"path":"scale.html","id":"scale-of-analysis","chapter":"Scale","heading":"Scale of analysis","text":"Scale analysis Earth Engine determined “pull” basis. scale request inputs computation determined output. example, add image map Map$addLayer(), zoom level map Rstudio determines scale inputs requested image pyramid. computations, specify scale argument. example, using NIR band Landsat image, 30 meters native resolution:example, note pixel value constant location (image centroid) varies based scale. due fact different pyramid levels selected different scales. similar scales, nearest neighbor resampling results pixel value returned. important point varying scale, different image inputs requested.Note: avoid ambiguity, always specify scale use function scale parameter.visualize image adding map, Earth Engine determines scale zoom level. Consider following simple example, simply displays Landsat image:map starts zoomed way , native resolution pixels clearly visible. Zooming far enough display pixels, instead display higher levels image pyramid. also worth noting Rstudio map uses maps mercator (EPSG:3857) projection, appropriate level image pyramid also needs reprojected prior display. Learn Earth Engine handles projections projections doc.","code":"\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1/LC08_044034_20140318\")$select(\"B4\")\n\nprintAtScale <- function(scale) {\n  cat(\n    \"Pixel value at \", scale, \" meters scale\",\n    image$reduceRegion(\n      reducer = ee$Reducer$first(),\n      geometry = image$geometry()$centroid(),\n      # The scale determines the pyramid level from which to pull the input\n      scale = scale\n    )$get(\"B4\")$getInfo()\n  )\n}\n\nprintAtScale(10) # 8883\nprintAtScale(30) # 8883\nprintAtScale(50) # 8337\nprintAtScale(70) # 9215\nprintAtScale(200) # 8775\nprintAtScale(500) # 8300\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1/LC08_044034_20140318\")\n\nMap$centerObject(image, 17)\nMap$addLayer(image, list(bands = c(\"B4\", \"B3\", \"B2\"), max = 12000), \"image\")"},{"path":"projections.html","id":"projections","chapter":"Projections","heading":"Projections","text":"section requires next libraries:Earth Engine designed rarely worry map projections computations. scale, projection computations take place determined “pull” basis. Specifically, inputs requested output projection. output may determined function parameter (e.g. crs), Map Rstudio (maps mercator (EPSG:3857) projection), reproject() call. display images Rstudio, inputs requested maps mercator. Consider following simple operation MODIS image, sinusoidal projection:order operations code sample diagrammed Figure 1. Note projection input determined output, specifically maps mercator projection map display Rstudio. projection propagates back sequence operations inputs requested maps mercator, scale determined zoom level map.Figure 1. Flow chart operations corresponding display MODIS image Rstudio map. Projections (left side flow chart) operation determined output. Curved lines indicate flow information reprojection: specifically, output projection scale.Earth Engine, projections specified Coordinate Reference System (CRS crs parameter many methods). can check projection image calling projection() :Note calling nominalScale() ee$Projection returned projection(), can determine native resolution image. native resolution nominal pixel scale meters lowest level image pyramid. band image can different scale /projection, call projection() image least one band doesn’t projection others, may see error like:","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()\n# The input image has a SR-ORG:6974 (sinusoidal) projection.\nimage <- ee$Image(\"MODIS/006/MOD13A1/2014_05_09\")$select(0)\n\n# Normalize the image and add it to the map.\nrescaled <- image$unitScale(-2000, 10000)\nvisParams <- list(min = 0.15, max = 0.7)\nMap$addLayer(rescaled, visParams, \"Rescaled\")\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1/LC08_044034_20140318\")$select(0)\n\n# Projection, crs, and crs_transform\nprint(image$projection()$getInfo())\n\ncat(\"Scale in meters:\", image$projection()$nominalScale()$getInfo())"},{"path":"projections.html","id":"the-default-projection","chapter":"Projections","heading":"The default projection","text":"Unless need computation occur specific projection, generally need specify projection. output ’s ambiguous Earth Engine require specify projection /scale. Ambiguity can result reducing ImageCollection containing images different projections (.e. creating composite). image composite mosaic input images different projections default projection, WGS84 1-degree scale. example:try use image like computation, may see error like:Generally, aggregation 1-degree scale desired intended, Earth Engine gives friendly reminder provide complete specification output.Users often find behavior confusing worry “lost” projection information, pixels aren’t actually computed ’re needed (learn ), point, ’s always output projection accompanies request specified compute composite.vast majority use cases, projection problem actually valuable optimization, allows previewing results zoom level without wait full resolution computation complete. mean output can appear different different zoom levels.optimized display image somehow isn’t sufficient, computation specific projection can forced reprojecting output described following section.","code":"\ncollection <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1\")\nmosaic <- collection$mosaic()\n\nprint(mosaic$projection()$getInfo())"},{"path":"projections.html","id":"reprojecting","chapter":"Projections","heading":"Reprojecting","text":"can force operations performed specific projection reproject() method. Using reproject() results inputs requested projection specified reproject() call. Computations code reproject() call done specified projection. example, force composite produced specific projection:cases require fixed projection include:Computing gradients (e.g. ee$Terrain$gradient ee$Terrain$slope).reduceResolution, want aggregate higher resolution pixels lower resolution.several reasons avoid using reproject() unless absolutely need . Suppose, example, reproject something add map. scale specified reproject() call much smaller zoom level map, Earth Engine request inputs small scale, wide spatial extent. can result much much data requested lead error.eventual output different projection specified reproject() call, result another reprojection. another reason cautious using reproject() code. Consider following example, forces MODIS image first reprojected WGS84, reprojected maps mercator display Rstudio map:Figure diagrams flow operations corresponding simple reprojection example. Note first reprojection explicit, specified reproject() call. second reprojection implicit, performed Earth Engine automatically order display result map. Also observe information projection use propagates back request input.Figure: Flow chart operations corresponding reprojection MODIS image Rstudio map. Curved lines indicate flow information reprojections: specifically, output projection scale.","code":"\n# Some projection that is suitable for your area of interest.\nproj <- ee$Projection(...)\noutput <- collection$reduce(...)$reproject(proj)\n# The input image has a SR-ORG:6974 (sinusoidal) projection.\nimage <- ee$Image(\"MODIS/006/MOD13A1/2014_05_09\")$select(0)\n\n# Operations *before* the reproject call will be done in the projection\n# specified by reproject().  The output results in another reprojection.\nreprojected <- image$\n  unitScale(-2000, 10000)$\n  reproject(\"EPSG:4326\", NULL, 500)\n\nMap$addLayer(reprojected, visParams, \"Reprojected\")"},{"path":"objects-and-methods-overview.html","id":"objects-and-methods-overview","chapter":"Objects and Methods Overview","heading":"Objects and Methods Overview","text":"start journey mastering R, following six chapters help learn foundational components R. expect ’ve already seen many pieces , probably studied deeply. help check existing knowledge, chapter starts quiz; get questions right, feel free skip next chapter!","code":""},{"path":"image.html","id":"image","chapter":"Image","heading":"Image","text":"","code":""},{"path":"image.html","id":"image-overview","chapter":"Image","heading":"Image Overview","text":"mentioned Get Started doc, raster data represented Image objects Earth Engine. Images composed one bands band name, data type, scale, mask projection. image metadata stored set properties.","code":""},{"path":"image.html","id":"eeimage-constructor","chapter":"Image","heading":"ee$Image constructor","text":"Images can loaded pasting Earth Engine asset ID ee$Image constructor. can find image IDs data catalog. example, load JAXA’s ALOS DSM:Note finding image Rstudio search tool equivalent. import asset, image construction code written imports section Rstudio. can also use personal asset ID shown doc.","code":"\nloadedImage <- ee$Image('JAXA/ALOS/AW3D30/V2_2')"},{"path":"image.html","id":"get-an-eeimage-from-an-eeimagecollection","chapter":"Image","heading":"Get an ee$Image from an ee$ImageCollection","text":"standard way get image collection filter collection, filters order decreasing specificity. example, get image Sentinel-2 surface reflectance collection:Note sort filters. Avoid sorting entire collection.","code":"\nee_geom <- ee$Geometry$Point(-70.48, 43.3631)\nfirst <- ee$ImageCollection(\"COPERNICUS/S2_SR\") %>%\n  ee$ImageCollection$filterBounds(ee_geom) %>%\n  ee$ImageCollection$filterDate(\"2019-01-01\", \"2019-12-31\") %>%\n  ee$ImageCollection$sort(\"CLOUDY_PIXEL_PERCENTAGE\") %>%\n  first()\nvizParams <- list(\n  bands<- c(\"B4\", \"B3\", \"B2\"),\n  min<- 0,\n  max<- 2000\n)\nMap$centerObject(first, 11)\nMap$addLayer(first, vizParams, \"first\")"},{"path":"image.html","id":"images-from-cloud-geotiffs","chapter":"Image","heading":"Images from Cloud GeoTIFFs","text":"can use ee$Image$loadGeoTIFF() load images Cloud Optimized GeoTIFFs Google Cloud Storage. example, public Landsat dataset hosted Google Cloud contains GeoTIFF, corresponding band 5 Landsat 8 scene. can load image Cloud Storage using ee$Image$loadGeoTIFF():Note want reload Cloud Optimized GeoTIFF export Earth Engine Cloud Storage, export, set cloudOptimized true described .","code":"\nuri <- 'gs:#gcp-public-data-landsat/LC08/01/001/002/' +\n    'LC08_L1GT_001002_20160817_20170322_01_T2/' +\n    'LC08_L1GT_001002_20160817_20170322_01_T2_B5.TIF'\ncloudImage <- ee$Image$loadGeoTIFF(uri)\nprint(cloudImage)"},{"path":"image.html","id":"constant-images","chapter":"Image","heading":"Constant images","text":"addition loading images ID, can also create images constants, lists suitable Earth Engine objects. following illustrates methods creating images, getting band subsets, manipulating bands:","code":"\n# Create a constant image.\nimage1 <- ee$Image(1)\nprint(image1)\n\n# Concatenate two images into one multi-band image.\nimage2 <- ee$Image(2)\nimage3 <- ee$Image$cat(c(image1, image2))\nprint(image3)\n\n# Create a multi-band image from a list of constants.\nmultiband <- ee$Image(c(1, 2, 3))\nprint(multiband)\n\n# Select and (optionally) rename bands.\nrenamed<- multiband$select(\n  c('constant', 'constant_1', 'constant_2'), ## old names\n  c('band1', 'band2', 'band3')               ## new names\n)\nprint(renamed)\n\n# Add bands to an image.\nimage4 <- image3$addBands(ee$Image(42));\nprint(image4)"},{"path":"image.html","id":"image-visualization","chapter":"Image","heading":"Image Visualization","text":"number ee$Image methods produce RGB visual representations image data, example: visualize(), getThumbURL(), getMap(), getMapId() (used Colab Folium map display) , Map$addLayer() (used Rstudio map display, available Python). default methods assign first three bands red, green blue, respectively. default stretch based type data bands (e.g. floats stretched [0, 1], 16-bit data stretched full range possible values), may may suitable. achieve desired visualization effects, can provide visualization parameters:","code":""},{"path":"image.html","id":"rgb-composites-1","chapter":"Image","heading":"RGB composites","text":"following illustrates use parameters style Landsat 8 image false-color composite:Figure 1. Landsat 8 false color composite San Francisco bay area, California, USA.","code":"\n# Load an image.\nimage <- ee$Image('LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318')\n\n# Define the visualization parameters.\nvizParams <- list(bands<- c('B5', 'B4', 'B3'),\n  min<- 0,\n  max<- 0.5,\n  gamma<- c(0.95, 1.1, 1)\n)\n# Center the map and display the image.\nMap$setCenter(-122.1899, 37.5010, 10); ## San Francisco Bay\nMap$addLayer(image, vizParams, 'false color composite')"},{"path":"image.html","id":"color-palettes-1","chapter":"Image","heading":"Color palettes","text":"display single band image color, set palette parameter color ramp represented list CSS-style color strings. (See reference information). following example illustrates use colors cyan (‘00FFFF’) blue (‘0000FF’) render Normalized Difference Water Index (NDWI) image:example, note min max parameters indicate range pixel values palette applied. Intermediate values linearly stretched.Figure 2. Landsat 8 NDWI, San Francisco bay area, USA. Cyan low values, blue high values.","code":"\n# Load an image.\nimage <- ee$Image('LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318')\n\n# Create an NDWI image, define visualization parameters and display.\nndwi <- image$normalizedDifference(c('B3', 'B5'))\nndwiViz <- list(\n  min<- 0.5, \n  max<- 1, \n  palette<- c('00FFFF', '0000FF')\n)\nMap$addLayer(ndwi, ndwiViz, 'NDWI')"},{"path":"image.html","id":"masking-4","chapter":"Image","heading":"Masking","text":"can use image$updateMask() set opacity individual pixels based pixels mask image non-zero. Pixels equal zero mask excluded computations opacity set 0 display. following example uses NDWI threshold (see Relational Operations section information thresholds) update mask NDWI layer created previously:","code":"\n# Mask the non-watery parts of the image, where NDWI < 0.4.\nndwiMasked <- ndwi$updateMask(ndwi$gte(0.4))\nMap$addLayer(ndwiMasked, ndwiViz, 'NDWI masked')"},{"path":"image.html","id":"visualization-images-1","chapter":"Image","heading":"Visualization images","text":"Use image.visualize() method convert image 8-bit RGB image display export. example, convert false-color composite NDWI 3-band display images, use:","code":"\n# Create visualization layers.\nimageRGB <- image$visualize(list(\n  bands<- c('B5', 'B4', 'B3'), \n  max<- 0.5\n))\n\nndwiRGB <- ndwiMasked$visualize(list(\n  min<- 0.5,\n  max<- 1,\n  palette<- c('00FFFF', '0000FF'))\n)"},{"path":"image.html","id":"mosaicking-2","chapter":"Image","heading":"Mosaicking","text":"can use masking imageCollection.mosaic() (see Mosaicking section information mosaicking) achieve various cartographic effects. mosaic() method renders layers output image according order input collection. following example uses mosaic() combine masked NDWI false color composite obtain new visualization:","code":"\n# Mosaic the visualization layers and display (or export).\nmosaic <- ee$ImageCollection(list(imageRGB, ndwiRGB))$\n  mosaic()\nMap$addLayer(mosaic, {}, 'mosaic')"},{"path":"image.html","id":"clipping","chapter":"Image","heading":"Clipping","text":"image$clip() method useful achieving cartographic effects. following example clips mosaic created previously arbitrary buffer zone around city San Francisco:","code":"\n# Create a circle by drawing a 20000 meter buffer around a point.\nroi <- ee$Geometry$Point(-122.4481, 37.7599)$buffer(20000);\n\n# Display a clipped version of the mosaic.\nMap$addLayer(mosaic$clip(roi))"},{"path":"image.html","id":"rendering-categorical-maps","chapter":"Image","heading":"Rendering categorical maps","text":"Palettes also useful rendering discrete valued maps, example land cover map. case multiple classes, use palette supply different color class. (image$remap() method may useful context, convert arbitrary labels consecutive integers). following example uses palette render land cover categories:","code":"\n# Load 2012 MODIS land cover and select the IGBP classification.\ncover <- ee$Image(\"MODIS/051/MCD12Q1/2012_01_01\")$\n  select(\"Land_Cover_Type_1\")\n\n# Define a palette for the 18 distinct land cover classes.\nigbpPalette <- list(\n  \"aec3d4\", ## water\n  \"152106\", \"225129\", \"369b47\", \"30eb5b\", \"387242\", ## forest\n  \"6a2325\", \"c3aa69\", \"b76031\", \"d9903d\", \"91af40\", ## shrub, grass\n  \"111149\", ## wetlands\n  \"cdb33b\", ## croplands\n  \"cc0013\", ## urban\n  \"33280d\", ## crop mosaic\n  \"d7cdcc\", ## snow and ice\n  \"f7e084\", ## barren\n  \"6f6f6f\" ## tundra\n)\n\n# Specify the min and max labels and the color palette matching the labels.\nMap$setCenter(-99.229, 40.413, 5)\nMap$addLayer(\n  cover,\n  list(min = 0, max = 17, palette = igbpPalette),\n  \"IGBP classification\"\n)"},{"path":"image.html","id":"styled-layer-descriptors","chapter":"Image","heading":"Styled Layer Descriptors","text":"can use Styled Layer Descriptor (SLD) render imagery display. Provide image$sldStyle() XML description symbolization coloring image, specifically RasterSymbolizer element. Learn RasterSymbolizer element . example, render land cover map described Rendering categorical maps section SLD, use:create visualization image color ramp, set type ColorMap ‘ramp’. following example compares ‘interval’ ‘ramp’ types rendering DEM:SLDs also useful stretching pixel values improve visualizations continuous data. example, following code compares results arbitrary linear stretch min-max ‘Normalization’ ‘Histogram’ equalization:Points note reference using SLDs Earth Engine:OGC SLD 1.0 OGC SE 1.1 supported.XML document passed can complete, just RasterSymbolizer element .Bands may selected Earth Engine names index (‘1’, ‘2’, …).Histogram Normalize contrast stretch mechanisms supported floating point imagery.Opacity taken account 0.0 (transparent). Non-zero opacity values treated completely opaque.OverlapBehavior definition currently ignored.ShadedRelief mechanism currently supported.ImageOutline mechanism currently supported.Geometry element ignored.output image histogram_bandname metadata histogram equalization normalization requested.","code":"\ncover <- ee$Image(\"MODIS/051/MCD12Q1/2012_01_01\")$select(\"Land_Cover_Type_1\")\n\n# Define an SLD style of discrete intervals to apply to the image.\nsld_intervals <-\n  \"<RasterSymbolizer>\" +\n  '<ColorMap type=\"intervals\" extended=\"false\">' +\n  '<ColorMapEntry color=\"#aec3d4\" quantity=\"0\" label=\"Water\"/>' +\n  '<ColorMapEntry color=\"#152106\" quantity=\"1\" label=\"Evergreen Needleleaf Forest\"/>' +\n  '<ColorMapEntry color=\"#225129\" quantity=\"2\" label=\"Evergreen Broadleaf Forest\"/>' +\n  '<ColorMapEntry color=\"#369b47\" quantity=\"3\" label=\"Deciduous Needleleaf Forest\"/>' +\n  '<ColorMapEntry color=\"#30eb5b\" quantity=\"4\" label=\"Deciduous Broadleaf Forest\"/>' +\n  '<ColorMapEntry color=\"#387242\" quantity=\"5\" label=\"Mixed Deciduous Forest\"/>' +\n  '<ColorMapEntry color=\"#6a2325\" quantity=\"6\" label=\"Closed Shrubland\"/>' +\n  '<ColorMapEntry color=\"#c3aa69\" quantity=\"7\" label=\"Open Shrubland\"/>' +\n  '<ColorMapEntry color=\"#b76031\" quantity=\"8\" label=\"Woody Savanna\"/>' +\n  '<ColorMapEntry color=\"#d9903d\" quantity=\"9\" label=\"Savanna\"/>' +\n  '<ColorMapEntry color=\"#91af40\" quantity=\"10\" label=\"Grassland\"/>' +\n  '<ColorMapEntry color=\"#111149\" quantity=\"11\" label=\"Permanent Wetland\"/>' +\n  '<ColorMapEntry color=\"#cdb33b\" quantity=\"12\" label=\"Cropland\"/>' +\n  '<ColorMapEntry color=\"#cc0013\" quantity=\"13\" label=\"Urban\"/>' +\n  '<ColorMapEntry color=\"#33280d\" quantity=\"14\" label=\"Crop, Natural Veg. Mosaic\"/>' +\n  '<ColorMapEntry color=\"#d7cdcc\" quantity=\"15\" label=\"Permanent Snow, Ice\"/>' +\n  '<ColorMapEntry color=\"#f7e084\" quantity=\"16\" label=\"Barren, Desert\"/>' +\n  '<ColorMapEntry color=\"#6f6f6f\" quantity=\"17\" label=\"Tundra\"/>' +\n  \"<\/ColorMap>\" +\n  \"<\/RasterSymbolizer>\"\n\nMap$addLayer(\n  cover$sldStyle(sld_intervals),\n  {},\n  \"IGBP classification styled\"\n)# Load SRTM Digital Elevation Model data.\nimage <- ee$Image(\"CGIAR/SRTM90_V4\")\n\n# Define an SLD style of discrete intervals to apply to the image.\nsld_intervals <-\n<<<<<<< HEAD\n  \"<RasterSymbolizer>\" +\n  '<ColorMap type=\"intervals\" extended=\"false\" >' +\n  '<ColorMapEntry color=\"#0000ff\" quantity=\"0\" label=\"0\"/>' +\n  '<ColorMapEntry color=\"#00ff00\" quantity=\"100\" label=\"1-100\" />' +\n  '<ColorMapEntry color=\"#007f30\" quantity=\"200\" label=\"110-200\" />' +\n  '<ColorMapEntry color=\"#30b855\" quantity=\"300\" label=\"210-300\" />' +\n  '<ColorMapEntry color=\"#ff0000\" quantity=\"400\" label=\"310-400\" />' +\n  '<ColorMapEntry color=\"#ffff00\" quantity=\"1000\" label=\"410-1000\" />' +\n  \"<\/ColorMap>\" +\n  \"<\/RasterSymbolizer>\"\n=======\n  '<RasterSymbolizer>' +\n    '<ColorMap type=\"intervals\" extended=\"false\" >' +\n      '<ColorMapEntry color=\"#0000ff\" quantity=\"0\" label=\"0\"/>' +\n      '<ColorMapEntry color=\"#00ff00\" quantity=\"100\" label=\"1-100\" />' +\n      '<ColorMapEntry color=\"#007f30\" quantity=\"200\" label=\"110-200\" />' +\n      '<ColorMapEntry color=\"#30b855\" quantity=\"300\" label=\"210-300\" />' +\n      '<ColorMapEntry color=\"#ff0000\" quantity=\"400\" label=\"310-400\" />' +\n      '<ColorMapEntry color=\"#ffff00\" quantity=\"1000\" label=\"410-1000\" />' +\n    '<\/ColorMap>' +\n  '<\/RasterSymbolizer>'\n>>>>>>> master\n\n# Define an sld style color ramp to apply to the image.\nsld_ramp <-\n  \"<RasterSymbolizer>\" +\n  '<ColorMap type=\"ramp\" extended=\"false\" >' +\n  '<ColorMapEntry color=\"#0000ff\" quantity=\"0\" label=\"0\"/>' +\n  '<ColorMapEntry color=\"#00ff00\" quantity=\"100\" label=\"100\" />' +\n  '<ColorMapEntry color=\"#007f30\" quantity=\"200\" label=\"200\" />' +\n  '<ColorMapEntry color=\"#30b855\" quantity=\"300\" label=\"300\" />' +\n  '<ColorMapEntry color=\"#ff0000\" quantity=\"400\" label=\"400\" />' +\n  '<ColorMapEntry color=\"#ffff00\" quantity=\"500\" label=\"500\" />' +\n  \"<\/ColorMap>\" +\n  \"<\/RasterSymbolizer>\"\n\n# Add the image to the map using both the color ramp and interval schemes.\nMap$setCenter(-76.8054, 42.0289, 8)\nMap$addLayer(\n  image$sldStyle(sld_intervals),\n  {},\n  \"SLD intervals\"\n)\nMap$addLayer(\n  image$sldStyle(sld_ramp),\n  {},\n  \"SLD ramp\"\n)# Load a Landsat 8 raw image.\n<<<<<<< HEAD\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1/LC08_044034_20140318\")\n=======\nimage<- ee$Image('LANDSAT/LC08/C01/T1/LC08_044034_20140318')\n>>>>>>> master\n\n# Define a RasterSymbolizer element with '_enhance_' for a placeholder.\ntemplate_sld <-\n  \"<RasterSymbolizer>\" +\n  \"<ContrastEnhancement><_enhance_/><\/ContrastEnhancement>\" +\n  \"<ChannelSelection>\" +\n  \"<RedChannel>\" +\n  \"<SourceChannelName>B5<\/SourceChannelName>\" +\n  \"<\/RedChannel>\" +\n  \"<GreenChannel>\" +\n  \"<SourceChannelName>B4<\/SourceChannelName>\" +\n  \"<\/GreenChannel>\" +\n  \"<BlueChannel>\" +\n  \"<SourceChannelName>B3<\/SourceChannelName>\" +\n  \"<\/BlueChannel>\" +\n  \"<\/ChannelSelection>\" +\n  \"<\/RasterSymbolizer>\"\n\n# Get SLDs with different enhancements.\nequalize_sld <- template_sld.replace(\"_enhance_\", \"Histogram\")\nnormalize_sld <- template_sld.replace(\"_enhance_\", \"Normalize\")\n\n# Display the results.\nMap$centerObject(image, 10)\nMap$addLayer(image, list(bands = c(\"B5\", \"B4\", \"B3\"), min = 0, max = 15000), \"Linear\")\nMap$addLayer(\n  image.sldStyle(equalize_sld),\n  {},\n  \"Equalized\"\n)\nMap$addLayer(\n  image.sldStyle(normalize_sld),\n  {},\n  \"Normalized\"\n)"},{"path":"image.html","id":"thumbnail-images","chapter":"Image","heading":"Thumbnail images","text":"Use ee$Image.getThumbURL() method generate PNG JPEG thumbnail image ee$Image object. Printing outcome expression ending call getThumbURL() results URL printed. Visiting URL sets Earth Engine servers work generating requested thumbnail --fly. image displayed browser processing completes. can downloaded selecting appropriate options image’s right-click context menu.getThumbURL() method includes parameters, described visualization parameters table . Additionally, takes optional dimensions, region, crs arguments control spatial extent, size, display projection thumbnail.Caution: *'WIDTHxHEIGHT'* dimensions argument can alter original aspect ratio data region extent.single-band image default grayscale unless palette argument supplied. multi-band image default RGB visualization first three bands, unless bands argument supplied. two bands provided, first band map red, second blue, green channel zero filled.following series examples demonstrating various combinations getThumbURL() parameter arguments. Click URLs printed run script view thumbnails.Note: Thumbnail images also available UI elements (Rstudio ), see: ui.Thumbnail.*Note: Thumbnail images also available UI elements (Rstudio ), see: ui.Thumbnail.*Note: getThumbURL intended method producing preview images might include presentations, websites, social media posts. size limitation 100,000,000 pixels browser can timeout complicated requests. want large image complex process, see Exporting Data page.Note: getThumbURL intended method producing preview images might include presentations, websites, social media posts. size limitation 100,000,000 pixels browser can timeout complicated requests. want large image complex process, see Exporting Data page.","code":"\n# Fetch a digital elevation model.\nimage <- ee$Image(\"CGIAR/SRTM90_V4\")\n\n# Request a default thumbnail of the DEM with defined linear stretch.\n# Set masked pixels (ocean) to 1000 so they map as gray.\nthumbnail1 <- image$unmask(1000)$getThumbURL(list(\n  \"min\" = 0,\n  \"max\" = 3000,\n  \"dimensions\" = 500\n))\nprint(\"Default extent:\", thumbnail1)\n\n# Specify region by rectangle, define palette, set larger aspect dimension size.\nthumbnail2 <- image$getThumbURL(list(\n  \"min\" = 0,\n  \"max\" = 3000,\n  \"palette\" = c(\"00A600\", \"63C600\", \"E6E600\", \"E9BD3A\", \"ECB176\", \"EFC2B3\", \"F2F2F2\"),\n  \"dimensions\" = 500,\n  \"region\" = ee$Geometry$Rectangle(c(-84.6, -55.9, -32.9, 15.7))\n))\nprint(\"Rectangle region and palette:\", thumbnail2)\n# Specify region by a linear ring and set display CRS as Web Mercator.\nthumbnail3 <- image$getThumbURL(list(\n  \"min\" = 0,\n  \"max\" = 3000,\n  \"palette\" = c(\"00A600\", \"63C600\", \"E6E600\", \"E9BD3A\", \"ECB176\", \"EFC2B3\", \"F2F2F2\"),\n  \"region\" = ee$Geometry$LinearRing(c(-84.6, 15.7), c(-84.6, -55.9), c(-32.9, -55.9)),\n  \"dimensions\" = 500,\n  \"crs\" = \"EPSG:3857\"\n))\nprint(\"Linear ring region and specified crs\", thumbnail3)"},{"path":"image.html","id":"image-information-and-metadata","chapter":"Image","heading":"Image Information and Metadata","text":"Print image objects explore band names, projection information, properties, metadata. following examples demonstrate printing entire set image metadata well requesting specific metadata elements programmatically.","code":""},{"path":"image.html","id":"getting-metadata","chapter":"Image","heading":"Getting metadata","text":"","code":"# Load an image.\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1/LC08_044034_20140318\")\n\n# Display all metadata.\nprint(\"All metadata:\", image)\n\n# Get information about the bands as a list.\nbandNames <- image$bandNames()\n<<<<<<< HEAD\nprint(\"Band names:\", bandNames)  ## ee$List of band names\n=======\nprint('Band names:', bandNames)  ## ee$List of band names\n>>>>>>> master\n\n# Get projection information from band 1.\nb1proj <- image$select(\"B1\")$projection()\nprint(\"Band 1 projection:\", b1proj)  ## ee$Projection object\n\n# Get scale (in meters) information from band 1.\nb1scale <- image$select(\"B1\")$projection()$nominalScale()\nprint(\"Band 1 scale:\", b1scale)  ## ee$Number\n\n## Note that different bands can have different projections and scale.\nb8scale <- image$select(\"B8\")$projection()$nominalScale()\nprint(\"Band 8 scale:\", b8scale) ## ee$Number\n\n# Get a list of all metadata properties.\nproperties <- image$propertyNames()\nprint(\"Metadata properties:\", properties) ## ee$List of metadata properties\n\n# Get a specific metadata property.\ncloudiness <- image$get(\"CLOUD_COVER\")\nprint(\"CLOUD_COVER:\", cloudiness)  ## ee$Number\n\n# Get version number (ingestion timestamp as microseconds since Unix epoch).\nversion <- image$get(\"system:version\")\nprint(\"Version:\", version) ## ee$Number\nprint(\n  \"Version (as ingestion date):\",\n  ee$Date(ee$Number(version)$divide(1000))\n) ## ee$Date\n\n# Get the timestamp and convert it to a date.\ndate <- ee$Date(image$get(\"system:time_start\"))\nprint(\"Timestamp:\", date) ## ee$Date"},{"path":"image.html","id":"mathematical-operations","chapter":"Image","heading":"Mathematical Operations","text":"Image math can performed using operators like add() subtract(), complex computations couple terms, expression() function provides good alternative. See following sections information operators expressions.","code":""},{"path":"image.html","id":"operators","chapter":"Image","heading":"Operators","text":"Math operators perform basic arithmetic operations image bands. take two inputs: either two images one image constant term, interpreted single-band constant image masked pixels. Operations performed per pixel band.simple example, consider task calculating Normalized Difference Vegetation Index (NDVI) using Landsat imagery, add(), subtract(), divide() operators used:Note: normalized difference operation available shortcut method: normalizedDifference().intersection unmasked pixels two inputs considered returned unmasked, else masked. general, either input one band, used bands input. inputs number bands, names, ’re used pairwise natural order. output bands named longer two inputs, ’re equal length, first input’s order. type output pixels union input types.following example multi-band image subtraction demonstrates bands matched automatically, resulting “change vector” pixel co-occurring band.second part example, squared difference computed using image.pow(2). complete list mathematical operators handling basic arithmetic, trigonometry, exponentiation, rounding, casting, bitwise operations , see API documentation.","code":"\n# Load a 5-year Landsat 7 composite 1999-2003.\nlandsat1999 <- ee$Image(\"LANDSAT/LE7_TOA_5YEAR/1999_2003\")\n\n# Compute NDVI.\nndvi1999 <- landsat1999$select(\"B4\")$subtract(landsat1999$select(\"B3\"))$\n  divide(landsat1999$select(\"B4\")$add(landsat1999$select(\"B3\")))\n# Load a 5-year Landsat 7 composite 2008-2012.\nlandsat2008 <- ee$Image(\"LANDSAT/LE7_TOA_5YEAR/2008_2012\")\n\n# Compute multi-band difference between the 2008-2012 composite and the\n# previously loaded 1999-2003 composite.\ndiff <- landsat2008$subtract(landsat1999)\nMap$addLayer(\n  diff, list(\n    bands = c(\"B4\", \"B3\", \"B2\"),\n    min = -32,\n    max = 32\n  ),\n  \"difference\"\n)\n\n# Compute the squared difference in each band.\nsquaredDifference <- diff$pow(2)\nMap$addLayer(\n  squaredDifference,\n  list(bands:c(\"B4\", \"B3\", \"B2\"), max = 1000), \"squared diff\"\n)"},{"path":"image.html","id":"expresions","chapter":"Image","heading":"Expresions","text":"implement complex mathematical expressions, consider using image.expression(), parses text representation math operation. following example uses expression() compute Enhanced Vegetation Index (EVI):Observe first argument expression() textual representation math operation, second argument dictionary keys variable names used expression values image bands variables mapped. Bands image may referred b(\"band name\") b(index), example b(0), instead providing dictionary. Bands can defined images input using band map dictionary. Note expression() uses “floor division”, discards remainder returns integer two integers divided. example 10 / 20<- 0. change behavior, multiply one operands 1.0: 10 * 1.0 / 20<- 0.5. intersection unmasked pixels considered returned unmasked bands one source image evaluated. Supported expression operators listed following table.Operators expression()","code":"# Load a Landsat 8 image.\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\n\n# Compute the EVI using an expression.\nevi <- image.expression(\n    '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n      'NIR': image.select('B5'),\n      'RED': image.select('B4'),\n      'BLUE': image.select('B2')\n})\n\nMap$centerObject(image, 9)\nMap$addLayer(evi, list(min = -1, max = 1, palette = c(\"FF0000\", \"00FF00\")), \"EVI\")"},{"path":"image.html","id":"relational-conditional-and-boolean-operations","chapter":"Image","heading":"Relational, Conditional, and Boolean Operations","text":"ee$Image objects set relational, conditional, boolean methods constructing decision-making expressions. results methods useful limiting analysis certain pixels regions masking, developing classified maps, value reassignment.","code":""},{"path":"image.html","id":"relational-and-boolean-operators","chapter":"Image","heading":"Relational and boolean operators","text":"Relational methods include:\neq(), gt(), gte(), lt(), lte().Relational methods include:\neq(), gt(), gte(), lt(), lte().Boolean methods include:\n(),(), ().Boolean methods include:\n(),(), ().perform per-pixel comparisons images, use relational operators. extract urbanized areas image, example uses relational operators threshold spectral indices, combining thresholds operator:illustrated example, output relational boolean operators either true (1) false (0). mask 0’s, can mask resultant binary image using selfMask().binary images returned relational boolean operators can used mathematical operators. example creates zones urbanization nighttime lights image using relational operators add():","code":"\n# Load a Landsat 8 image.\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\n\n# Create NDVI and NDWI spectral indices.\nndvi <- image$normalizedDifference(c(\"B5\", \"B4\"))\nndwi <- image$normalizedDifference(c(\"B3\", \"B5\"))\n# Create a binary layer using logical operations.\nbare <- ndvi$lt(0.2)$and(ndwi$lt(0))\n\n# Mask and display the binary layer.\nMap$setCenter(-122.3578, 37.7726, 12)\nMap$setOptions(\"satellite\")\nMap$addLayer(\n  bare$selfMask(),\n  {},\n  \"bare\"\n)\n# Load a 2012 nightlights image.\nnl2012 <- ee$Image(\"NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F182012\")\nlights <- nl2012$select(\"stable_lights\")\n\n# Define arbitrary thresholds on the 6-bit stable lights band.\nzones <- lights$gt(30)$add(lights$gt(55))$add(lights$gt(62))\n\n# Display the thresholded image as three distinct zones near Paris.\npalette <- c(\"000000\", \"0000FF\", \"00FF00\", \"FF0000\")\nMap$setCenter(2.373, 48.8683, 8)\nMap$addLayer(zones, list(min = 0, max = 3, palette = palette), \"development zones\")"},{"path":"image.html","id":"conditional-operators","chapter":"Image","heading":"Conditional operators","text":"Note code previous example equivalent using ternary operator implemented expression():Observe previous expression example, band interest referenced using b() function, rather dictionary variable names. Learn image expressions page. Using either mathematical operators expression produce result.Another way implement conditional operations images () operator. Consider need replace masked pixels data. following example, cloudy pixels replaced pixels cloud-free image using ():example, observe use simpleCloudScore() algorithm. algorithm ranks pixels cloudiness scale 0-100, 100 cloudy. Learn simpleCloudScore() Landsat Algorithms page.","code":"\n# Create zones using an expression, display.\nzonesExp <- nl2012.expression(\n  \"(b('stable_lights') > 62) ? 3\" +\n    \": (b('stable_lights') > 55) ? 2\" +\n    \": (b('stable_lights') > 30) ? 1\" +\n    \": 0\"\n)\nMap$addLayer(\n  zonesExp,\n  list(min = 0, max = 3, palette = palette),\n  \"development zones (ternary)\"\n)\n# Load a cloudy Landsat 8 image.\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20130603\")\nMap$addLayer(\n  image,\n  list(bands = c(\"B5\", \"B4\", \"B3\"), min = 0, max = 0.5),\n  \"original image\"\n)\n\n# Load another image to replace the cloudy pixels.\nreplacement <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20130416\")\n\n# Compute a cloud score band.\ncloud <- ee$Algorithms$Landsat$simpleCloudScore(image)$select(\"cloud\")\n\n# Set cloudy pixels to the other image.\nreplaced <- image$where(cloud$gt(10), replacement)\n\n# Display the result.\nMap$centerObject(image, 9)\nMap$addLayer(\n  replaced,\n  list(bands = c(\"B5\", \"B4\", \"B3\"), min = 0, max = 0.5),\n  \"clouds replaced\"\n)"},{"path":"image.html","id":"convolutions","chapter":"Image","heading":"Convolutions","text":"perform linear convolutions images, use image.convolve(). argument convolve ee.Kernel specified shape weights kernel. pixel image output convolve() linear combination kernel values input image pixels covered kernel. kernels applied band individually. example, might want use low-pass (smoothing) kernel remove high-frequency information. following illustrates 15x15 low-pass kernel applied Landsat 8 image:output convolution low-pass filter look something like Figure 8. Observe arguments kernel determine size coefficients. Specifically, units parameter set pixels, radius parameter specifies number pixels center kernel cover. normalize set true, kernel coefficients sum one. magnitude parameter set, kernel coefficients multiplied magnitude (normalize also true, coefficients sum magnitude). negative value kernel coefficients, setting normalize true make coefficients sum zero.Use kernels achieve desired image processing effect. example uses Laplacian kernel isotropic edge detection:Note format specifier visualization parameters. Earth Engine sends display tiles Rstudio JPEG format efficiency, however edge tiles sent PNG format handle transparency pixels outside image boundary. visual discontinuity results, setting format PNG results consistent display. result convolving Laplacian edge detection kernel look something like Figure 9.also anisotropic edge detection kernels (e.g. Sobel, Prewitt, Roberts), direction can changed kernel$rotate(). low pass kernels include Gaussian kernel kernels various shape uniform weights. create kernels arbitrarily defined weights shape, use ee$Kernel$fixed(). example, code creates 9x9 kernel 1’s zero middle:","code":"# Load and display an image.\n<<<<<<< HEAD\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\nvizParams <- list(\n  bands = c(\"B5\", \"B4\", \"B3\"),\n  max = 0.5\n)\n=======\nimage <- ee$Image('LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318')\nvizParams <- list(bands<- c('B5', 'B4', 'B3'),\n                  max<- 0.5)\n>>>>>>> master\nMap$setCenter(-121.9785, 37.8694, 11)\nMap$addLayer(image, vizParams, \"input image\")\n\n# Define a boxcar or low-pass kernel.\nboxcar <- ee$Kernel$square(list(\n<<<<<<< HEAD\n  radius = 7,\n  units = \"pixels\",\n  normalize = TRUE\n=======\n  radius<- 7,\n  units<- 'pixels', \n  normalize<- TRUE\n>>>>>>> master\n))\n\n# Smooth the image by convolving with the boxcar kernel.\nsmooth <- image$convolve(boxcar)\nMap$addLayer(smooth, list(bands = c(\"B5\", \"B4\", \"B3\"), max = 0.5), \"smoothed\")\n# Define a Laplacian, or edge-detection kernel.\nlaplacian <- ee$Kernel$laplacian8({\n  normalize:false\n})\n\n# Apply the edge-detection kernel.\nedgy <- image$convolve(laplacian)\nMap$addLayer(\n  edgy,\n  list(bands = c(\"B5\", \"B4\", \"B3\"), max = 0.5, format = \"png\"),\n  \"edges\"\n)\n# Create a list of weights for a 9x9 kernel.\nrow <- c(1, 1, 1, 1, 1, 1, 1, 1, 1)\n\n# The center of the kernel is zero.\ncenterRow <- c(1, 1, 1, 1, 0, 1, 1, 1, 1)\n\n# Assemble a list of lists: the 9x9 kernel weights as a 2-D matrix.\nrows <- c(row, row, row, row, centerRow, row, row, row, row)\n\n# Create the kernel from the weights.\nkernel <- ee$Kernel$fixed(9, 9, rows, -4, -4, false)\nprint(kernel)"},{"path":"image.html","id":"morphological-operations","chapter":"Image","heading":"Morphological Operations","text":"Earth Engine implements morphological operations focal operations, specifically focalMax(), focalMin(), focalMedian(), focalMode() instance methods Image class. (shortcuts general reduceNeighborhood(), can input pixels kernel reducer numeric output. See page information reducing neighborhoods). morphological operators useful performing operations erosion, dilation, opening closing. example, perform opening operation, use focalMin() followed focalMax():Note previous example, kernel argument provided morphological operator. pixels covered non-zero elements kernel used computation. iterations argument indicates many times apply operator.","code":"# Load a Landsat 8 image, select the NIR band, threshold, display.\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")$\n  select(4)$gt(0.2)\nMap$setCenter(-122.1899, 37.5010, 13)\nMap$addLayer(\n  image,\n  {},\n  \"NIR threshold\"\n)\n\n# Define a kernel.\nkernel <- ee$Kernel$circle(radius<- 1)\n\n# Perform an erosion followed by a dilation, display.\nopened <- image$\n  focalMin({kernel: kernel, iterations: 2})$\n  focalMax({kernel: kernel, iterations: 2})\nMap.addLayer(opened, {}, 'opened')"},{"path":"image.html","id":"gradients","chapter":"Image","heading":"Gradients","text":"can compute gradient band image image.gradient(). example, following code computes gradient magnitude direction Landsat 8 panchromatic band:","code":"\n# Load a Landsat 8 image and select the panchromatic band.\nimage <- ee$Image('LANDSAT/LC08/C01/T1/LC08_044034_20140318')$select('B8')\n\n# Compute the image gradient in the X and Y directions.\nxyGrad <- image$gradient()\n\n# Compute the magnitude of the gradient.\ngradient <- xyGrad$select('x')$pow(2)$\n  add(xyGrad$select('y')$pow(2))$sqrt()\n\n# Compute the direction of the gradient.\ndirection <- xyGrad$select('y')$atan2(xyGrad$select('x'))\n\n# Display the results.\nMap$setCenter(-122.054, 37.7295, 10);\nMap$addLayer(direction, list(min: -2, max: 2, format: 'png'), 'direction')\nMap$addLayer(gradient, list(min: -7, max: 7, format: 'png'), 'gradient')"},{"path":"image.html","id":"edge-detection","chapter":"Image","heading":"Edge detection","text":"Edge detection applicable wide range image processing tasks. addition edge detection kernels described convolutions section, several specialized edge detection algorithms Earth Engine. Canny edge detection algorithm (Canny 1986) uses four separate filters identify diagonal, vertical, horizontal edges. calculation extracts first derivative value horizontal vertical directions computes gradient magnitude. Gradients smaller magnitude suppressed. eliminate high-frequency noise, optionally pre-filter image Gaussian kernel. example:Note threshold parameter determines minimum gradient magnitude sigma parameter standard deviation (SD) Gaussian pre-filter remove high-frequency noise. line extraction edge detector, Earth Engine implements Hough transform (Duda Hart 1972). Continuing previous example, extract lines Canny detector :Another specialized algorithm Earth Engine zeroCrossing(). zero-crossing defined pixel right, bottom, diagonal bottom-right pixel opposite sign. pixels opposite sign, current pixel set 1 (zero-crossing); otherwise ’s set zero. detect edges, zero-crossings algorithm can applied estimate image second derivative. following demonstrates using zeroCrossing() edge detection:zero-crossings output area near San Francisco, CA airport look something like Figure 11.Figure 11. Zero-crossings output (red) Landsat 8 panchromatic band background area near San Francisco, California airport (right).","code":"# Load a Landsat 8 image, select the panchromatic band.\nimage <- ee.$Image(\"LANDSAT/LC08/C01/T1/LC08_044034_20140318\")$select(\"B8\")\n\n# Perform Canny edge detection and display the result.\ncanny <- ee$Algorithms$CannyEdgeDetector(list(\n<<<<<<< HEAD\n  image = image,\n  threshold = 10,\n  sigma = 1\n))\n=======\n  image<- image, \n  threshold<- 10, \n  sigma<- 1)\n  )\n>>>>>>> master\nMap$setCenter(-122.054, 37.7295, 10)\nMap$addLayer(\n  canny,\n  {},\n  \"canny\"\n)\n# Perform Hough transform of the Canny result and display.\nhough <- ee$Algorithms$HoughTransform(canny, 256, 600, 100)\nMap$addLayer(\n  hough,\n  {},\n  \"hough\"\n)\n# Load a Landsat 8 image, select the panchromatic band.\nimage <- ee$Image('LANDSAT/LC08/C01/T1/LC08_044034_20140318')$select('B8')\nMap$addLayer(image, list(max: 12000))\n\n# Define a \"fat\" Gaussian kernel.\nfat <- ee$Kernel$gaussian(list(\n  radius<- 3,\n  sigma<- 3,\n  units<- 'pixels',\n  normalize<- true,\n  magnitude<- -1)\n)\n\n# Define a \"skinny\" Gaussian kernel.\nskinny <- ee$Kernel$gaussian(list(\n  radius<- 3,\n  sigma<- 1,\n  units<- 'pixels',\n  normalize<- true)\n)\n\n# Compute a difference-of-Gaussians (DOG) kernel.\ndog <- fat$add(skinny)\n\n# Compute the zero crossings of the second derivative, display.\nzeroXings <- image$convolve(dog)$zeroCrossing()\nMap.setCenter(-122.054, 37.7295, 10)\nMap.addLayer(zeroXings$selfMask(), list(palette<- 'FF0000'), 'zero crossings')"},{"path":"image.html","id":"spectral-transformations","chapter":"Image","heading":"Spectral transformations","text":"several spectral transformation methods Earth Engine. include instance methods images normalizedDifference(), unmix(), rgbToHsv() hsvToRgb().","code":""},{"path":"image.html","id":"pan-sharpening","chapter":"Image","heading":"Pan sharpening","text":"Pan sharpening improves resolution multiband image enhancement provided corresponding panchromatic image finer resolution. rgbToHsv() hsvToRgb() methods useful pan sharpening.","code":"# Load a Landsat 8 top-of-atmosphere reflectance image.\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\n\nMap$addLayer(\n<<<<<<< HEAD\n  image,\n  list(bands = c(\"B4\", \"B3\", \"B2\"), min = 0, max = 0.25, gamma = c(1.1, 1.1, 1)),\n  \"rgb\"\n)\n=======\n    image,\n    list(bands<- c('B4', 'B3', 'B2'), min<- 0, max<- 0.25, gamma<- c(1.1, 1.1, 1)),\n    'rgb')\n>>>>>>> master\n\n# Convert the RGB bands to the HSV color space.\nhsv <- image$select(c(\"B4\", \"B3\", \"B2\"))$rgbToHsv()\n\n# Swap in the panchromatic band and convert back to RGB.\nsharpened <- ee$Image$cat(list(hsv$select('hue'), hsv$select('saturation'),image$select('B8')))\n$hsvToRgb()\n\n# Display the pan-sharpened result.\nMap$setCenter(-122.44829, 37.76664, 13);\nMap$addLayer(sharpened,\n             list(min<- 0, max<- 0.25, gamma<- c(1.3, 1.3, 1.3)),\n             'pan-sharpened')"},{"path":"image.html","id":"spectral-unmixing","chapter":"Image","heading":"Spectral unmixing","text":"Spectral unmixing implemented Earth Engine image.unmix() method. (flexible methods, see Array Transformations page). following example unmixing Landsat 5 predetermined urban, vegetation water endmembers:Figure 12. Landsat 5 imagery unmixed urban (red), vegetation (green) water (blue) fractions. San Francisco bay area, California, USA.","code":"# Load a Landsat 5 image and select the bands we want to unmix.\nbands <- C(\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\")\nimage <- ee$Image(\"LANDSAT/LT05/C01/T1/LT05_044034_20080214\")$\n  select(bands)\n<<<<<<< HEAD\nMap$setCenter(-122.1899, 37.5010, 10)\n## San Francisco Bay\nMap$addLayer(image, list(bands = c(\"B4\", \"B3\", \"B2\"), min = 0, max = 128), \"image\")\n=======\nMap$setCenter(-122.1899, 37.5010, 10); ## San Francisco Bay\nMap$addLayer(image, list(bands<- c('B4', 'B3', 'B2'), min<- 0, max<- 128), 'image')\n>>>>>>> master\n\n# Define spectral endmembers.\nurban <- c(88, 42, 48, 38, 86, 115, 59)\nveg <- c(50, 21, 20, 35, 50, 110, 23)\nwater <- c(51, 20, 14, 9, 7, 116, 4)\n\n# Unmix the image.\nfractions <- image$unmix(c(urban, veg, water))\nMap$addLayer(\n  fractions,\n  {},\n  \"unmixed\"\n)"},{"path":"image.html","id":"texture","chapter":"Image","heading":"Texture","text":"Earth Engine several special methods estimating spatial texture. image discrete valued (floating point), can use image$entropy() compute entropy neighborhood:Note NIR band scaled 8-bits prior calling entropy() since entropy computation takes discrete valued inputs. non-zero elements kernel specify neighborhood.Another way measure texture gray-level co-occurrence matrix (GLCM). Using image kernel previous example, compute GLCM-based contrast follows:Many measures texture output image$glcm(). complete reference outputs, see Haralick et al. (1973) Conners et al. (1984).Local measures spatial association Geary’s C (Anselin 1995) can computed Earth Engine using image$neighborhoodToBands(). Using image previous example:example using neighborhood standard deviation compute image texture, see Statistics Image Neighborhoods page.","code":"# Load a high-resolution NAIP image.\nimage <- ee$Image('USDA/NAIP/DOQQ/m_3712213_sw_10_1_20140613')\n\n# Zoom to San Francisco, display.\nMap$setCenter(-122.466123, 37.769833, 17)\nMap$addLayer(image, list(max = 255), 'image')\n\n# Get the NIR band.\nnir <- image$select('N')\n\n# Define a neighborhood with a kernel.\nsquare <- ee$Kernel$square(radius<- 4)\n\n# Compute entropy and display.\nentropy <- nir$entropy(square)\nMap$addLayer(entropy,\n<<<<<<< HEAD\n             list(min = 1, max = 5, palette = c('0000CC', 'CC0000')),\n=======\n             list(min<- 1, max<- 5, palette<- c('0000CC', 'CC0000') ),\n>>>>>>> master\n             'entropy')\n# Compute the gray-level co-occurrence matrix (GLCM), get contrast.\nglcm <- nir$glcmTexture(size<- 4)\ncontrast <- glcm$select('N_contrast')\nMap$addLayer(contrast,\n             list(min<- 0, max<- 1500, palette<- c('0000CC', 'CC0000')),\n             'contrast')# Create a list of weights for a 9x9 kernel.\nrow <- c(1, 1, 1, 1, 1, 1, 1, 1, 1)\n# The center of the kernel is zero.\ncenterRow<- c(1, 1, 1, 1, 0, 1, 1, 1, 1)\n# Assemble a list of lists: the 9x9 kernel weights as a 2-D matrix.\nrows <- c(row, row, row, row, centerRow, row, row, row, row)\n# Create the kernel from the weights.\n# Non-zero weights represent the spatial neighborhood.\nkernel <- ee$Kernel$fixed(9, 9, rows, -4, -4, false)\n\n# Convert the neighborhood into multiple bands.\nneighs <- nir$neighborhoodToBands(kernel)\n\n# Compute local Geary's C, a measure of spatial association.\ngearys <- nir$subtract(neighs)$pow(2)$reduce(ee$Reducer$sum())\n             $divide(Math$pow(9, 2))\nMap$addLayer(gearys,\n             list(min<- 20, max<- 2500, palette<- c('0000CC', 'CC0000')),\n             \"Geary's C\")"},{"path":"image.html","id":"object-based-methods","chapter":"Image","heading":"Object-based methods","text":"Image objects sets connected pixels integer value. Categorical, binned, boolean image data suitable object analysis.Earth Engine offers methods labeling object unique ID, counting number pixels composing objects, computing statistics values pixels intersect objects.connectedComponents(): label object unique identifier.connectedPixelCount(): compute number pixels object.reduceConnectedComponents(): compute statistic pixels object.Caution: results object-based methods depend scale, determined :requested scale output (e.g., Export.image.toAsset() Export.image.toDrive()).functions require scale analysis (e.g., reduceRegions() reduceToVectors()).Map zoom level.Take special note scale determined Map zoom level. Results object-based methods vary viewing inspecting image layers Map, pyramid layer different scale. force desired scale analysis Map exploration, use reproject(). However, strongly recommended use reproject() entire area visible Map requested set scale projection. large extents can cause much data requested, often triggering errors. Within image pyramid-based architecture Earth Engine, scale projection need set operations provide scale crs parameters. See Scale Analysis Reprojecting information.","code":""},{"path":"image.html","id":"thermal-hotspots","chapter":"Image","heading":"Thermal hotspots","text":"following sections provide examples object-based methods applied Landsat 8 surface temperature section building former. Run next snippet generate base image: thermal hotspots (> 303 degrees Kelvin) small region San Francisco.Figure 13. Temperature region San Francisco. Pixels temperature greater 303 degrees Kelvin distinguished color red (thermal hotspots).","code":"# Make an area of interest geometry centered on San Francisco.\npoint <- ee$Geometry$Point(-122.1899, 37.5010)\naoi <- point$buffer(10000)\n\n# Import a Landsat 8 image, subset the thermal band, and clip to the\n# area of interest.\n<<<<<<< HEAD\nkelvin <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")$\n  select(\"B10\", \"kelvin\")$\n  clip(aoi)\n\n# Display the thermal band.\nMap$centerObject(point, 13)\nMap.$addLayer(kelvin, list(min = 288, max = 305), \"Kelvin\")\n=======\nkelvin<- ee.Image('LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318')\n  .select(['B10'], ['kelvin'])\n  .clip(aoi)\n\n# Display the thermal band.\nMap$centerObject(point, 13);\nMap.$addLayer(kelvin, list(min<- 288, max<- 305), 'Kelvin')\n>>>>>>> master\n\n# Threshold the thermal band to set hot pixels as value 1, mask all else.\nhotspots <- kelvin$gt(303)$\n  selfMask()$\n  rename(\"hotspots\")\n\n# Display the thermal hotspots on the Map.\n<<<<<<< HEAD\nMap$addLayer(hotspots, list(palette = \"FF0000\"), \"Hotspots\")\n=======\nMap$addLayer(hotspots, list(palette<- 'FF0000'), 'Hotspots')\n>>>>>>> master"},{"path":"image.html","id":"label-objects","chapter":"Image","heading":"Label objects","text":"Labeling objects often first step object analysis. , connectedComponents() function used identify image objects assign unique ID ; pixels belonging object assigned integer ID value. result copy input image additional “labels” band associating pixels object ID value based connectivity pixels first band image.Figure 14. Thermal hotspot objects labeled styled unique ID.","code":"# Uniquely label the hotspot image objects.\nobjectId <- hotspots$connectedComponents(list(\n<<<<<<< HEAD\n  connectedness = ee$Kernel$plus(1),\n  maxSize = 128\n))\n=======\n  connectedness<- ee.Kernel.plus(1),\n  maxSize<- 128)\n  )\n>>>>>>> master\n\n# Display the uniquely ID'ed objects to the Map.\nMap$addLayer(objectId$randomVisualizer(), null, \"Objects\")"},{"path":"image.html","id":"object-size","chapter":"Image","heading":"Object size","text":"","code":""},{"path":"image.html","id":"number-of-pixels","chapter":"Image","heading":"Number of pixels","text":"Calculate number pixels composing objects using connectedPixelCount() image method. Knowing number pixels object can helpful masking objects size calculating object area. following snippet applies connectedPixelCount() “labels” band objectId image defined previous section.Figure 15. Thermal hotspot objects labeled styled unique ID.","code":"\n# Compute the number of pixels in each object defined by the \"labels\" band.\nobjectSize <- objectId$select('labels')$\n  connectedPixelCount(list(\n     maxSize<- 128, eightConnected<- false)\n     )\n\n# Display object pixel count to the Map.\nMap$addLayer(objectSize, null, 'Object n pixels');"},{"path":"image.html","id":"area","chapter":"Image","heading":"Area","text":"Calculate object area multiplying area single pixel number pixels composing object (determined connectedPixelCount()). Pixel area provided image generated ee$Image$pixelArea().result image pixel object relates area object square meters. example, objectSize image contains single band, multi-band, multiplication operation applied band image.","code":"\n# Get a pixel area image.\npixelArea <- ee$Image$pixelArea()\n\n# Multiply pixel area by the number of pixels in an object to calculate\n# the object area. The result is an image where each pixel\n# of an object relates the area of the object in m^2.\nobjectArea <- objectSize$multiply(pixelArea)\n\n# Display object area to the Map.\nMap$addLayer(objectArea,\n             list(min<- 0, max<- 30000, palette<- c('0000FF', 'FF00FF')),\n             'Object area m^2')"},{"path":"image.html","id":"filter-objects-by-size","chapter":"Image","heading":"Filter objects by size","text":"Object size can used mask condition focus analysis objects certain size (e.g., mask objects small). objectArea image calculated previous step used mask remove objects whose area less one hectare.result copy objectId image objects less one hectare masked .","code":"\n# Threshold the `objectArea` image to define a mask that will mask out\n# objects below a given size (1 hectare in this case).\nareaMask <- objectArea$gte(10000)\n\n# Update the mask of the `objectId` layer defined previously using the\n# minimum area mask just defined.\nobjectId <- objectId$updateMask(areaMask)\nMap$addLayer(objectId, null, 'Large hotspots')"},{"path":"image.html","id":"zonal-statistics","chapter":"Image","heading":"Zonal statistics","text":"reduceConnectedComponents() method applies reducer pixels composing unique objects. following snippet uses calculate mean temperature hotspot objects. reduceConnectedComponents() requires input image band (bands) reduced band defines object labels. , objectID “labels” image band added kelvin temperature image construct suitable input image.Figure 17. Thermal hotspot object pixels summarized styled mean temperature.Note: reduceToVectors() provides similar functionality, except result ee$FeatureCollection, feature collection represents object reduction pixels objects expressed feature property band input image. reduceToVectors() resource intensive, use reduceConnectedComponents() whenever possible. See Raster Vector Conversion information.","code":"\n# Make a suitable image for `reduceConnectedComponents()` by adding a label\n# band to the `kelvin` temperature image.\nkelvin <- kelvin$addBands(objectId$select('labels'))\n\n# Calculate the mean temperature per object defined by the previously added\n# \"labels\" band.\npatchTemp <- kelvin$reduceConnectedComponents(list(\n  reducer<- ee$Reducer$mean(),\n  labelBand<- 'labels')\n)\n\n# Display object mean temperature to the Map.\nMap$addLayer(\n  patchTemp,list(\n    min<- 303, max<- 304, palette<- c('yellow', 'red')),\n  'Mean temperature'\n)"},{"path":"image.html","id":"cumulative-cost-mapping","chapter":"Image","heading":"Cumulative Cost Mapping","text":"Use image$cumulativeCost() compute cost map every pixel contains total cost lowest cost path nearest source location. process useful variety contexts habitat analysis (Adriaensen et al. 2003), watershed delineation (Melles et al. 2011) image segmentation (Falcao et al. 2004). Call cumulative cost function image pixel represents cost per meter traverse . Paths computed pixel’s eight neighbors. Required inputs include source image, non-zero pixel represents potential source (start path), maxDistance (meters) compute paths. algorithm finds cumulative cost paths less maxPixels<- maxDistance/scale length, scale pixel resolution, scale analysis Earth Engine.following example demonstrates computing least-cost paths across land cover image:Figure 18. cumulative cost source pixels, cost determined land cover categories. Low costs black, higher costs white.","code":"\n# A rectangle representing Bangui, Central African Republic.\ngeometry <- ee$Geometry$Rectangle(c(18.5229, 4.3491, 18.5833, 4.4066))\n\n# Create a source image where the geometry is 1, everything else is 0.\nsources <- ee$Image()$toByte()$paint(geometry, 1)\n\n# Mask the sources image with itself.\nsources <- sources$selfMask()\n\n# The cost data is generated from classes in ESA/GLOBCOVER.\ncover <- ee$Image('ESA/GLOBCOVER_L4_200901_200912_V2_3')$select(0)\n\n# Classes 60, 80, 110, 140 have cost 1.\n# Classes 40, 90, 120, 130, 170 have cost 2.\n# Classes 50, 70, 150, 160 have cost 3.\nbeforeRemap <- c(60, 80, 110, 140,\n                40, 90, 120, 130, 170,\n                50, 70, 150, 160)\nafterRemap <- c(1, 1, 1, 1,\n                2, 2, 2, 2, 2,\n                3, 3, 3, 3)\ncost <- cover$remap(beforeRemap, afterRemap, 0)\n\n# Compute the cumulative cost to traverse the land cover.\ncumulativeCost <- cost$cumulativeCost(list(\n  source<- sources,\n  maxDistance<- 80 * 1000)  ## 80 kilometers\n  )\n\n# Display the results\nMap$setCenter(18.71, 4.2, 9)\nMap$addLayer(cover, {}, 'Globcover')\nMap$addLayer(cumulativeCost, list(min<- 0, max<- 5e4), 'accumulated cost')\nMap$addLayer(geometry, list(color<- 'FF0000'), 'source geometry')"},{"path":"image.html","id":"registering-images","chapter":"Image","heading":"Registering Images","text":"Earth Engine image registration algorithm designed final, post-ortho, fine-grained step aligning images. assumed images registered already gone initial alignment stages, already within degrees rotation one another, differ small translations. registration uses “rubber-sheet” technique, allowing local image warping correct orthorectification errors artifacts earlier processing. underlying alignment technique image correlation, bands input reference images must visually similar order algorithm compute accurate alignment.","code":""},{"path":"image.html","id":"image-displacement","chapter":"Image","heading":"Image displacement","text":"two steps registering image: Determining displacement image using displacement(), applying displace(). required inputs pair images register, maximum displacement parameter (maxOffset).displacement() algorithm takes reference image, maximum displacement parameter (maxOffset), two optional parameters modify algorithm behaviour. output displacement image bands dx dy give X Y components (meters) displacement vector pixel.bands calling reference images used matching registration, number bands must exactly equal. input bands must visually similar registration succeed. case, may possible pre-process (e.g. smoothing, edge detection) make appear similar. registration computations performed using multiscale, coarse--fine process, (multiscale) working projections depend three projections supplied algorithm:default projection calling image (Pc)default projection reference image (Pr)output projection (Po)highest resolution working projection (Pw CRS Pr, scale determined coarsest resolution 3 projections, minimize computation. results Pr resampled projection specified input ‘projection’ parameter.output displacement image following bands:dx\n- given reference image pixel location, band contains distance X direction must travelled arrive matching location calling image. Units geodesic meters.dy\n- given reference image pixel location, band contains distance Y direction must travelled arrive matching location calling image. Units geodesic meters.confidence\n- per-pixel estimate displacement confidence (0 low confidence 1 high confidence) based correlation scores regions valid matches found. regions matches found, confidence estimated nearby correlations using Gaussian kernel provide higher weight nearby correlations.following example computes magnitude angle displacement two high-resolution Terra Bella images:","code":"\n# Load the two images to be registered.\nimage1 <- ee$Image('SKYSAT/GEN-A/PUBLIC/ORTHO/MULTISPECTRAL/s01_20150502T082736Z')\nimage2 <- ee$Image('SKYSAT/GEN-A/PUBLIC/ORTHO/MULTISPECTRAL/s01_20150305T081019Z')\n\n# Use bicubic resampling during registration.\nimage1Orig <- image1$resample('bicubic')\nimage2Orig <- image2$resample('bicubic')\n\n# Choose to register using only the 'R' band.\nimage1RedBand <- image1Orig$select('R')\nimage2RedBand <- image2Orig$select('R')\n\n# Determine the displacement by matching only the 'R' bands.\ndisplacement <- image2RedBand.displacement(list(\n  referenceImage<- image1RedBand,\n  maxOffset<- 50.0,\n  patchWidth<- 100.0)\n)\n\n# Compute image offset and direction.\noffset <- displacement$select('dx')$hypot(displacement$select('dy'))\nangle <- displacement$select('dx')$atan2(displacement$select('dy'))\n\n# Display offset distance and angle.\nMap$addLayer(offset, list(min<- 0, max<- 20), 'offset')\nMap$addLayer(angle, list(min<- -Math.PI, max<- Math.PI), 'angle')\nMap$setCenter(37.44,0.58, 15)"},{"path":"image.html","id":"warping-an-image","chapter":"Image","heading":"Warping an image","text":"two ways warp image match another image: displace() register(). displace() algorithm takes displacement image dx dy bands first two bands, warps image accordingly. output image result warping bands input image offsets present displacement image. Using displacements computed previous example:don’t need displacement bands, Earth Engine provides register() method, shortcut calling displacement() followed displace(). example:example, results register() differ results displace(). different set bands used two approaches: register() always uses bands input images, displacement() example used red band feeding result displace(). Note multiple bands used, band variances different -weight high-variance bands, since bands jointly normalized spatial correlation scores combined. illustrates importance selecting band(s) visually similar registering. previous example, use displacement() displace() control bands used compute displacement.","code":"\n# Use the computed displacement to register all original bands.\nregistered <- image2Orig$displace(displacement)\n\n# Show the results of co-registering the images.\nvisParams <- list(bands<- c('R', 'G', 'B'), max<- 4000)\nMap$addLayer(image1Orig, visParams, 'Reference')\nMap$addLayer(image2Orig, visParams, 'Before Registration')\nMap$addLayer(registered, visParams, 'After Registration')\nalsoRegistered <- image2Orig$register(list(\n  referenceImage<- image1Orig,\n  maxOffset<- 50.0,\n  patchWidth<- 100.0)\n  )\nMap.addLayer(alsoRegistered, visParams, 'Also Registered')"},{"path":"imagecollection.html","id":"imagecollection","chapter":"ImageCollection","heading":"ImageCollection","text":"section requires next libraries:","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()"},{"path":"imagecollection.html","id":"imagecollection-overview","chapter":"ImageCollection","heading":"ImageCollection Overview","text":"ImageCollection stack sequence images. ImageCollection can loaded pasting Earth Engine asset ID ImageCollection constructor. can find ImageCollection IDs data catalog. example, load Sentinel-2 surface reflectance collection:collection contains every Sentinel-2 image public catalog. lot. Usually want filter collection shown .addition loading ImageCollection using Earth Engine collection ID, Earth Engine methods create image collections. constructor ee$ImageCollection() convenience method ee$ImageCollection$fromImages() create image collections lists images. can also create new image collections merging existing collections. example:Note example ImageCollection created mapping function returns Image FeatureCollection. Learn mapping Mapping ImageCollection section. Learn feature collections FeatureCollection section.can also create ImageCollection GeoTiffs Cloud Storage. example:Figure 1. ImageCollection GeoTiffs Cloud StorageLearn loading images Cloud GeoTiffs","code":"\nsentinelCollection <- ee$ImageCollection(\"COPERNICUS/S2_SR\")\n# Create arbitrary constant images.\nconstant1 <- ee$Image(1)\nconstant2 <- ee$Image(2)\n\n# Create a collection by giving a list to the constructor.\ncollectionFromConstructor <- ee$ImageCollection(c(constant1, constant2))\nee_print(collectionFromConstructor)\n\n# Create a collection with fromImages().\ncollectionFromImages <- ee$ImageCollection$fromImages(c(ee$Image(3), ee$Image(4)))\nee_print(collectionFromConstructor)\n\n# Merge two collections.\nmergedCollection <- collectionFromConstructor$merge(collectionFromImages)\nee_print(mergedCollection)\n\n# Create a toy FeatureCollection.\nfeatures <- ee$FeatureCollection(\n  ee$Feature(NULL, list(foo = 1)),\n  ee$Feature(NULL, list(foo = 2))\n)\n\n# Create an ImageCollection from the FeatureCollection\n# by mapping a function over the FeatureCollection.\nimages <- features$map(function(feature) {\n  return(ee$Image(ee$Number(feature$get(\"foo\"))))\n})\n\n# Print the resultant collection.\nee_print(images)\n# All the GeoTiffs are in this folder.\nuriBase <- paste0(\n  \"gs://gcp-public-data-landsat/LC08/01/001/002/\", \"LC08_L1GT_001002_20160817_20170322_01_T2/\"\n)\n\n# List of URIs, one for each band.\nuris <- ee$List(\n  list(\n    paste0(uriBase, \"LC08_L1GT_001002_20160817_20170322_01_T2_B2.TIF\"),\n    paste0(uriBase, \"LC08_L1GT_001002_20160817_20170322_01_T2_B3.TIF\"),\n    paste0(uriBase, \"LC08_L1GT_001002_20160817_20170322_01_T2_B4.TIF\"),\n    paste0(uriBase, \"LC08_L1GT_001002_20160817_20170322_01_T2_B5.TIF\")\n  )\n)\n\n# Make a collection from the list of images.\nimages <- uris$map(ee_utils_pyfunc(function(x) ee$Image$loadGeoTIFF(x)))\ncollection <- ee$ImageCollection(images)\n\n# Get an RGB image from the collection of bands.\nrgb <- collection$toBands()$rename(c(\"B2\", \"B3\", \"B4\", \"B5\"))\n\nMap$centerObject(rgb)\nMap$addLayer(\n  eeObject <- rgb,\n  vizParams <- list(\n    bands = c(\"B4\", \"B3\", \"B2\"),\n    min = 0,\n    max = 20000\n  ),\n  name <- \"rgb\"\n)"},{"path":"imagecollection.html","id":"imagecollection-visualization","chapter":"ImageCollection","heading":"ImageCollection Visualization","text":"Images composing ImageCollection can visualized either animation series thumbnails referred “filmstrip”. methods provide quick assessment contents ImageCollection effective medium witnessing spatiotemporal change (Figure 2).getVideoThumbURL() produces animated image seriesgetFilmstripThumbURL() produces thumbnail image seriesThe following sections describe prepare ImageCollection visualization, provide example code collection visualization method, cover several advanced animation techniques.Figure 2. Animation showing three-day progression Atlantic hurricanes September, 2017.","code":""},{"path":"imagecollection.html","id":"collection-preparation","chapter":"ImageCollection","heading":"Collection preparation","text":"Filter, composite, sort, style images within collection display interest emphasize phenomenon. ImageCollection can provided input visualization functions, curated collection consideration inter- intra-annual date ranges, observation interval, regional extent, quality representation can achieve better results.","code":""},{"path":"imagecollection.html","id":"filtering","chapter":"ImageCollection","heading":"Filtering","text":"Filter image collection include relevant data supports purpose visualization. Consider dates, spatial extent, quality, properties specific given dataset.instance, filter Sentinel-2 surface reflectance collection :single date range,serial day--year range,region interest,image property.Chain multiple filters.","code":"\ns2col <- ee$ImageCollection(\"COPERNICUS/S2_SR\") %>%\n  ee$ImageCollection$filterDate(\"2018-01-01\", \"2019-01-01\")\ns2col <- ee$ImageCollection(\"COPERNICUS/S2_SR\") %>%\n  ee$ImageCollection$filter(ee$Filter$calendarRange(171, 242, \"day_of_year\"))\nee_geom <- ee$Geometry$Point(-122.1, 37.2)\ns2col <- ee$ImageCollection(\"COPERNICUS/S2_SR\") %>%\n  ee$ImageCollection$filterBounds(ee_geom)\ns2col <- ee$ImageCollection(\"COPERNICUS/S2_SR\") %>%\n  ee$ImageCollection$filter(ee$Filter$lt(\"CLOUDY_PIXEL_PERCENTAGE\", 50))\nee_geom <- ee$Geometry$Point(-122.1, 37.2)\ns2col <- ee$ImageCollection(\"COPERNICUS/S2_SR\") %>%\n  ee$ImageCollection$filterDate(\"2018-01-01\", \"2019-01-01\") %>%\n  ee$ImageCollection$filterBounds(ee_geom) %>%\n  ee$ImageCollection$filter(\"CLOUDY_PIXEL_PERCENTAGE < 50\")"},{"path":"imagecollection.html","id":"compositing","chapter":"ImageCollection","heading":"Compositing","text":"Composite intra- inter-annual date ranges reduce number images collection improve quality. example, suppose create visualization annual NDVI Africa. One option simply filter MODIS 16-day NDVI collection include 2018 observations.","code":"\nndviCol <- ee$ImageCollection(\"MODIS/006/MOD13A2\") %>%\n  ee$ImageCollection$filterDate(\"2018-01-01\", \"2019-01-01\") %>%\n  ee$ImageCollection$select(\"NDVI\")"},{"path":"imagecollection.html","id":"inter-annual-composite-by-filter-and-reduce","chapter":"ImageCollection","heading":"Inter-annual composite by filter and reduce","text":"Visualization collection shows considerable noise forested regions cloud cover heavy (Figure 3a). better representation can achieved reducing serial date ranges median across years MODIS collection.animation resulting collection less noisy, image represents median 16-day NDVI composite 20+ years data (Figure 3b). See tutorial information animation.","code":"\n# Make a day-of-year sequence from 1 to 365 with a 16-day step.\ndoyList <- ee$List$sequence(1, 365, 16)\n\n# Import a MODIS NDVI collection.\nndviCol <- ee$ImageCollection(\"MODIS/006/MOD13A2\")$select(\"NDVI\")\n\n# Map over the list of days to build a list of image composites.\nmap_over_days <- function(startDoy) {\n  # Ensure that startDoy is a number.\n  startDoy <- ee$Number(startDoy)\n\n  # Filter images by date range; starting with the current startDate and\n  # ending 15 days later. Reduce the resulting image collection by median.\n  ndviCol %>%\n    ee$ImageCollection$filter(\n      ee$Filter$calendarRange(startDoy, startDoy$add(15), \"day_of_year\")\n    ) %>%\n    ee$ImageCollection$reduce(ee$Reducer$median())\n}\nndviCompList <- doyList$map(ee_utils_pyfunc(map_over_days))\n\n# Convert the image List to an ImageCollection.\nndviCol <- ee$ImageCollection$fromImages(ndviCompList)"},{"path":"imagecollection.html","id":"intra-annual-composite-by-filter-and-reduce","chapter":"ImageCollection","heading":"Intra-annual composite by filter and reduce","text":"previous example applies inter-annual compositing. can also helpful composite series intra-annual observations. example, Landsat data collected every sixteen days given scene per sensor, often portion images obscured clouds. Masking clouds compositing several images season can produce cloud-free representation. Consider following example Landsat 5 images July August composited using median year 1985 2011.","code":"\n# Make a day-of-year sequence from 1 to 365 with a 16-day step.\ndoyList <- ee$List$sequence(1, 365, 16)\n\n# Import a MODIS NDVI collection.\nndviCol <- ee$ImageCollection(\"MODIS/006/MOD13A2\")$select(\"NDVI\")\n\n# Map over the list of days to build a list of image composites.\nmap_over_days <- function(startDoy) {\n  # Ensure that startDoy is a number.\n  startDoy <- ee$Number(startDoy)\n\n  # Filter images by date range; starting with the current startDate and\n  # ending 15 days later. Reduce the resulting image collection by median.\n  ndviCol %>%\n    ee$ImageCollection$filter(\n      ee$Filter$calendarRange(startDoy, startDoy$add(15), \"day_of_year\")\n    ) %>%\n    ee$ImageCollection$reduce(ee$Reducer$median())\n}\nndviCompList <- doyList$map(ee_utils_pyfunc(map_over_days))\n\n# Convert the image List to an ImageCollection.\nndviCol <- ee$ImageCollection$fromImages(ndviCompList)\n\n# Assemble a collection of Landsat surface reflectance images for a given\n# region and day-of-year range.\nee_geom <- ee$Geometry$Point(-122.9, 43.6)\nlsCol <- ee$ImageCollection(\"LANDSAT/LT05/C02/T1_L2\") %>%\n  ee$ImageCollection$filterBounds(ee_geom) %>%\n  ee$ImageCollection$filter(ee$Filter$dayOfYear(182, 243)) %>%\n  # Add the observation year as a property to each image.\n  ee$ImageCollection$map(function(img) {\n    img$set(\"year\", ee$Image(img)$date()$get(\"year\"))\n  })\n\n# Define a function to scale the data and mask unwanted pixels.\nmaskL457sr <- function(image) {\n  # Bit 0 - Fill\n  # Bit 1 - Dilated Cloud\n  # Bit 2 - Unused\n  # Bit 3 - Cloud\n  # Bit 4 - Cloud Shadow\n  qaMask <- image$select(\"QA_PIXEL\")$bitwiseAnd(31)$eq(0)\n  saturationMask <- image$select(\"QA_RADSAT\")$eq(0)\n\n  # Apply the scaling factors to the appropriate bands.\n  opticalBands <- image$select(\"SR_B.\")$multiply(0.0000275)$add(-0.2)\n  thermalBand <- image$select(\"ST_B6\")$multiply(0.00341802)$add(149.0)\n\n  # Replace the original bands with the scaled ones and apply the masks.\n  image %>%\n    ee$Image$addBands(opticalBands, NULL, TRUE) %>%\n    ee$Image$addBands(thermalBand, NULL, TRUE) %>%\n    ee$Image$updateMask(qaMask) %>%\n    ee$Image$updateMask(saturationMask)\n}\n\n# Define a list of unique observation years from the image collection.\nyears <- ee$List(lsCol$aggregate_array(\"year\"))$distinct()$sort()\n\n# Map over the list of years to build a list of annual image composites.\nmap_over_year <- function(year) {\n  lsCol %>%\n    # Filter image collection by year.\n    ee$ImageCollection$filterMetadata(\"year\", \"equals\", year) %>%\n    # Apply cloud mask.\n    ee$ImageCollection$map(maskL457sr) %>%\n    # Reduce image collection by median.\n    ee$ImageCollection$reduce(ee$Reducer$median()) %>%\n    # Set composite year as an image property.\n    ee$Image$set(\"year\", year)\n}\nlsCompList <- years$map(ee_utils_pyfunc(map_over_year))\n\n# Convert the image List to an ImageCollection.\nlsCompCol <- ee$ImageCollection$fromImages(lsCompList)"},{"path":"imagecollection.html","id":"intra-annual-composite-by-join-and-reduce","chapter":"ImageCollection","heading":"Intra-annual composite by join and reduce","text":"Note previous two compositing methods map List days years incrementally define new dates filter composite . Applying join another method achieving operation. following snippet, unique year collection defined saveAll join applied identify images correspond given year. Images belonging given year grouped List object stored property respective year representative distinct year collection. Annual composites generated lists reducing ImageCollections defined function mapped distinct year collection.","code":"\n# Assemble a collection of Landsat surface reflectance images for a given\n# region and day-of-year range.\nee_geom <- ee$Geometry$Point(-122.9, 43.6)\nlsCol <- ee$ImageCollection(\"LANDSAT/LT05/C02/T1_L2\") %>%\n  ee$ImageCollection$filterBounds(ee_geom) %>%\n  ee$ImageCollection$filter(ee$Filter$dayOfYear(182, 243)) %>%\n  # Add the observation year as a property to each image.\n  ee$ImageCollection$map(function(img) {\n    return(img$set(\"year\", ee$Image(img)$date()$get(\"year\")))\n  })\n\n# Make a distinct year collection; one image representative per year.\ndistinctYears <- lsCol$distinct(\"year\")$sort(\"year\")\n\n# Define a join filter; one-to-many join on ‘year’ property.\nfilter <- ee$Filter$equals(list(leftField <- \"year\", rightField <- \"year\"))\n\n# Define a join.\njoin <- ee$Join$saveAll(\"year_match\")\n\n# Apply the join; results in 'year_match' property being added to each distinct\n# year representative image. The list includes all images in the collection\n# belonging to the respective year.\njoinCol <- join$apply(distinctYears, lsCol, filter)\n\n# Define a function to scale the data and mask unwanted pixels.\nmaskL457sr <- function(image) {\n  # Bit 0 - Fill\n  # Bit 1 - Dilated Cloud\n  # Bit 2 - Unused\n  # Bit 3 - Cloud\n  # Bit 4 - Cloud Shadow\n  qaMask <- image$select(\"QA_PIXEL\")$bitwiseAnd(31)$eq(0)\n  saturationMask <- image$select(\"QA_RADSAT\")$eq(0)\n\n  # Apply the scaling factors to the appropriate bands.\n  opticalBands <- image$select(\"SR_B.\")$multiply(0.0000275)$add(-0.2)\n  thermalBand <- image$select(\"ST_B6\")$multiply(0.00341802)$add(149.0)\n\n  # Replace the original bands with the scaled ones and apply the masks.\n  return(image$addBands(opticalBands, NULL, TRUE)$\n    addBands(thermalBand, NULL, TRUE)$\n    updateMask(qaMask)$\n    updateMask(saturationMask))\n}\n\n# Map over the distinct years collection to build a list of annual image\n# composites.\nlsCompList <- joinCol$map(function(img) {\n  # Get the list of images belonging to the given year.\n  ee$ImageCollection$fromImages(img$get(\"year_match\")) %>%\n    # Apply cloud mask.\n    ee$ImageCollection$map(maskL457sr) %>%\n    # Reduce image collection by median.\n    ee$ImageCollection$reduce(ee$Reducer$median()) %>%\n    # Set composite year as an image property.\n    ee$ImageCollection$copyProperties(img, list(\"year\"))\n})\n\n# Convert the image List to an ImageCollection.\nlsCompCol <- ee$ImageCollection(lsCompList)"},{"path":"imagecollection.html","id":"same-day-composite-by-join-and-reduce","chapter":"ImageCollection","heading":"Same-day composite by join and reduce","text":"additional case compositing create spatially contiguous image mosaics. Suppose region interest spans two Landsat rows within path objective display image mosaic two images Landsat 8 orbit 2017 2018. , filtering collection path row, join operation used mosaic Landsat images obit, defined acquisition date.","code":"\nlsCol <- ee$ImageCollection(\"LANDSAT/LC08/C02/T1_L2\") %>%\n  ee$ImageCollection$filterDate(\"2017-01-01\", \"2019-01-01\") %>%\n  ee$ImageCollection$filter(\"WRS_PATH == 38 && (WRS_ROW == 28 || WRS_ROW == 29)\") %>%\n  ee$ImageCollection$map(function(img) {\n    date <- img$date()$format(\"YYYY-MM-dd\")\n    return(img$set(\"date\", date))\n  })\n\n# Make a distinct date collection; one image representative per date.\ndistinctDates <- lsCol$distinct(\"date\")$sort(\"date\")\n\n# Define a join filter; one-to-many join on ‘date’ property.\nfilter <- ee$Filter$equals(list(leftField <- \"date\", rightField <- \"date\"))\n\n# Define a join.\njoin <- ee$Join$saveAll(\"date_match\")\n\n# Apply the join; results in 'date_match' property being added to each distinct\n# date representative image. The list includes all images in the collection\n# belonging to the respective date.\njoinCol <- join$apply(distinctDates, lsCol, filter)\n\nlsColMos <- ee$ImageCollection(joinCol$map(function(col) {\n  return(ee$ImageCollection$fromImages(col$get(\"date_match\"))$mosaic())\n}))"},{"path":"imagecollection.html","id":"sorting","chapter":"ImageCollection","heading":"Sorting","text":"Sort collection time ensure proper chronological sequence, order property choice. default, visualization frame series sorted natural order collection. arrangement series can altered using sort collection method, whereby Image property selected sorting either ascending descending order. example, sort time observation, use ubiquitous system:time_start property.perhaps order defined increasing cloudiness, case Sentinel-2 imagery.Order can also defined derived property, mean regional NDVI. , regional NDVI added property image mapped function, followed sort new property.","code":"\nee_geom <- ee$Geometry$Point(-122.1, 37.2)\ns2col <- ee$ImageCollection(\"COPERNICUS/S2_SR\") %>%\n  ee$ImageCollection$filterBounds(ee_geom) %>%\n  ee$ImageCollection$sort(\"system:time_start\")\nee_geom <- ee$Geometry$Point(-122.1, 37.2)\ns2col <- ee$ImageCollection(\"COPERNICUS/S2_SR\") %>%\n  ee$ImageCollection$filterBounds(ee_geom) %>%\n  ee$ImageCollection$sort(\"CLOUDY_PIXEL_PERCENTAGE\")\n# Define an area of interest geometry.\naoi <- ee$Geometry$Point(-122.1, 37.2)$buffer(1e4)\n\n# Filter MODIS NDVI image collection by a date range.\nndviCol <- ee$ImageCollection(\"MODIS/006/MOD13A1\") %>%\n  ee$ImageCollection$filterDate(\"2018-01-01\", \"2019-01-01\") %>%\n  ee$ImageCollection$filterBounds(aoi) %>%\n  ee$ImageCollection$select(\"NDVI\") %>%\n  # Map over the image collection to calculate regional mean NDVI and add\n  # the result to each image as a property.\n  ee$ImageCollection$map(function(img) {\n    meanNdvi <- img$reduceRegion(\n      reducer = ee$Reducer$mean(),\n      geometry = aoi,\n      scale = 500\n    )\n    return(img$set(\"meanNdvi\", meanNdvi$get(\"NDVI\")))\n  }) %>%\n  # Sort the collection by descending regional mean NDVI.\n  ee$ImageCollection$sort(\"meanNdvi\", FALSE)"},{"path":"imagecollection.html","id":"image-visualization-1","chapter":"ImageCollection","heading":"Image visualization","text":"Image visualization transforms numbers colors. three ways control image data represented color collection visualization methods:Provide visualization arguments directly getVideoThumbURL getFilmstripThumbUR.Provide visualization arguments directly getVideoThumbURL getFilmstripThumbUR.Map visualize image method image collection prior application getVideoThumbURL getFilmstripThumbUR.Map visualize image method image collection prior application getVideoThumbURL getFilmstripThumbUR.Map sldStyle image method image collection prior application getVideoThumbURL getFilmstripThumbUR. See Styled Layer Descriptor information.Map sldStyle image method image collection prior application getVideoThumbURL getFilmstripThumbUR. See Styled Layer Descriptor information.examples guide use options 1 2, visualization achieved mapping three image bands multi-band image color channels red, green, blue grading values single band linearly along color palette. Visualization parameters include:\nUse bands argument select band(s) wish visualize. Provide list either one three band names. regard multi-band images, first three bands selected default. Band name order determines color assignment; first, second, third listed bands mapped red, green, blue, respectively.Data range scaling important consideration visualizing images. default, floating point data values 0 1 (inclusive) scaled 0 255 (inclusive). Values outside range forced 0 255 depending whether less 0 greater 1, respectively. regard integer data, full capacity defined type scaled 0 255 (e.g., signed 16-bit data range −32,768 32,767, scales [0, 255], default). Accepting defaults can often result visualizations little contrast image features. Use min max improve contrast emphasize particular data range. good rule thumb set min max values represent 2nd 98th percentile data within area interest. See following example calculating values digital elevation model.palette parameter defines colors represent 8-bit visualization image. applies single-band representations; specifying multi-band image results error. data single-band like visualize single band multi-band image, set forceRgbOutput parameter true (unnecessary palette argument provided). Use min max parameters define range values linearly scale 0 255.Note:\n- provide gain/bias min/max arguments.\n- opacity visualization parameter effect animations, respected filmstrip visualization.\n- Visualizations resulting getVideoThumbURL getFilmstripThumbURL appear black collection images masked .example mapping visualization function single-band image collection follows. MODIS NDVI collection imported, visualization arguments visualization method set, function transforms values RGB image representations mapped NDVI collection.example mapping visualization function multi-band image collection:case, palette argument provided three bands given, define intensity RGB layer. Note examples use min max parameters control values stretched limits 8-bit RGB data.","code":"\n# Import SRTM global elevation model.\ndemImg <- ee$Image(\"USGS/SRTMGL1_003\")\n\n# Define a rectangular area of interest.\naoi <- ee$Geometry$Polygon(c(\n  c(-103.84153083119054, 49.083004219142886),\n  c(-103.84153083119054, 25.06838270664608),\n  c(-85.64817145619054, 25.06838270664608),\n  c(-85.64817145619054, 49.083004219142886)\n))\n\n# Calculate the 2nd and 98th percentile elevation values from rescaled (to\n# 500m) pixels intersecting the area of interest. A Dictionary is returned.\npercentClip <- demImg$reduceRegion(\n  reducer = ee$Reducer$percentile(c(2, 98)),\n  geometry = aoi,\n  scale = 500,\n  maxPixels = 3e7\n)\n\n# Print the regional 2nd and 98th percentile elevation values. Get the\n# dictionary keys and use them to get the values for each percentile summary.\nkeys <- percentClip$keys()\nprint(ee$Number(percentClip$get(keys$get(0)))$round())\nprint(ee$Number(percentClip$get(keys$get(1)))$round())\n# Filter MODIS NDVI image collection by a date range.\nndviCol <- ee$ImageCollection(\"MODIS/006/MOD13A1\") %>%\n  ee$ImageCollection$filterDate(\"2018-01-01\", \"2019-01-01\") %>%\n  ee$ImageCollection$select(\"NDVI\")\n\n# Define visualization arguments.\nvisArgs <- list(\n  min = 0,\n  max = 9000,\n  palette = c(\n    \"FFFFFF\", \"CE7E45\", \"DF923D\", \"F1B555\", \"FCD163\", \"99B718\", \"74A901\",\n    \"66A000\", \"529400\", \"3E8601\", \"207401\", \"056201\", \"004C00\", \"023B01\",\n    \"012E01\", \"011D01\", \"011301\"\n  )\n)\n\n# Define a function to convert an image to an RGB visualization image and copy\n# properties from the original image to the RGB image.\nvisFun <- function(img) {\n  return(img$visualize(visArgs)$copyProperties(img, img$propertyNames()))\n}\n\n# Map over the image collection to convert each image to an RGB visualization\n# using the previously defined visualization function.\nndviColVis <- ndviCol$map(visFun)\n# Assemble a collection of Sentinel-2 surface reflectance images for a given\n# region and date range.\ns2col <- ee$ImageCollection(\"COPERNICUS/S2_SR\") %>%\n  ee$ImageCollection$filterBounds(ee$Geometry$Point(-96.9037, 48.0395)) %>%\n  ee$ImageCollection$filterDate(\"2019-06-01\", \"2019-10-01\")\n\n# Define visualization arguments.\nvisArgs <- list(\n  bands = c(\"B11\", \"B8\", \"B3\"),\n  min = 300,\n  max = 3500\n)\n\n# Define a function to convert an image to an RGB visualization image and copy\n# properties from the original image to the RGB image.\nvisFun <- function(img) {\n  return(img$visualize(visArgs)$copyProperties(img, img$propertyNames()))\n}\n\n# Map over the image collection to convert each image to an RGB visualization\n# using the previously defined visualization function.\ns2colVis <- s2col$map(visFun)"},{"path":"imagecollection.html","id":"video-thumb","chapter":"ImageCollection","heading":"Video thumb","text":"getVideoThumbURL() function generates animation images ImageCollection image represents frame. general workflow producing animation follows:Define Geometry whose bounds determine regional extent animation.Define Geometry whose bounds determine regional extent animation.Define ImageCollection.Define ImageCollection.Consider image visualization: either map image visualization function collection add image visualization arguments set animation arguments.Consider image visualization: either map image visualization function collection add image visualization arguments set animation arguments.Define animation arguments call getVideoThumbURL method.Define animation arguments call getVideoThumbURL method.result getVideoThumbURL URL. Print URL console click start Earth Engine servers generating animation --fly new browser tab. Alternatively, view animation Rstudio console calling ui$Thumbnail function collection corresponding animation arguments. Upon rendering, animation available downloading right clicking selecting appropriate options context menu.following example illustrates generating animation depicting global temperatures course 24 hours. Note example includes visualization arguments along animation arguments, opposed first mapping visualization function ImageCollection. Upon running script, animation similar Figure 4 appear Rstudio console.Figure 4. Hourly surface temperature northern winter solstice represented animated GIF image.Note:\n- maximum number pixels allowed animation 6,553,600 (e.g., 256 x 256 x 100).\n- authorization token process thumbnail lasts 2 hours. expires, anyone authorization token can generate image.","code":"\n# Define an area of interest geometry with a global non-polar extent.\naoi <- ee$Geometry$Polygon(\n  c(c(-179.0, 78.0), c(-179.0, -58.0), c(179.0, -58.0), c(179.0, 78.0))\n)\n\n# Import hourly predicted temperature image collection for northern winter\n# solstice. Note that predictions extend for 384 hours; limit the collection\n# to the first 24 hours.\ntempCol <- ee$ImageCollection(\"NOAA/GFS0P25\") %>%\n  ee$ImageCollection$filterDate(\"2018-12-22\", \"2018-12-23\") %>%\n  ee$ImageCollection$limit(24) %>%\n  ee$ImageCollection$select(\"temperature_2m_above_ground\")\n\n# Define arguments for animation function parameters.\nvideoArgs <- list(\n  dimensions = 768,\n  region = aoi,\n  framesPerSecond = 7,\n  crs = \"EPSG:3857\",\n  min = -40.0,\n  max = 35.0,\n  palette = c(\"blue\", \"purple\", \"cyan\", \"green\", \"yellow\", \"red\")\n)\n\n# Print the animation to the console as a ui.Thumbnail using the above defined\n# arguments. Note that ui.Thumbnail produces an animation when the first input\n# is an ee.ImageCollection instead of an ee$Image.\nprint(ui$Thumbnail(tempCol, videoArgs))\n\n# Alternatively, print a URL that will produce the animation when accessed.\nprint(tempCol$getVideoThumbURL(videoArgs))"},{"path":"imagecollection.html","id":"filmstrip","chapter":"ImageCollection","heading":"Filmstrip","text":"getFilmstripThumbUrl function generates single static image representing concatenation images ImageCollection north-south series. sequence filmstrip frames follow natural order collection.result getFilmstripThumbUrl URL. Print URL console click start Earth Engine servers generating image --fly new browser tab. Upon rendering, image available downloading right clicking selecting appropriate options context menu.following code snippet uses collection video thumb example . Upon running script, filmstrip similar Figure 5 appear Rstudio console.Figure 5. Hourly surface temperature northern winter solstice represented filmstrip PNG image. Note filmstrip divided four sections display; result getFilmstripThumbURL single series collection images joined north-south.","code":"\n# Define an area of interest geometry with a global non-polar extent.\naoi <- ee$Geometry$Polygon(\n  c(c(c(-179.0, 78.0), c(-179.0, -58.0), c(179.0, -58.0), c(179.0, 78.0))), NULL, FALSE\n)\n\n# Import hourly predicted temperature image collection for northern winter\n# solstice. Note that predictions extend for 384 hours; limit the collection\n# to the first 24 hours.\ntempCol <- ee$ImageCollection(\"NOAA/GFS0P25\") %>%\n  ee$ImageCollection$filterDate(\"2018-12-22\", \"2018-12-23\") %>%\n  ee$ImageCollection$limit(24) %>%\n  ee$ImageCollection$select(\"temperature_2m_above_ground\")\n\n# Define arguments for the getFilmstripThumbURL function parameters.\nfilmArgs <- list(\n  dimensions = 128,\n  region = aoi,\n  crs = \"EPSG:3857\",\n  min = -40.0,\n  max = 35.0,\n  palette = c(\"blue\", \"purple\", \"cyan\", \"green\", \"yellow\", \"red\")\n)\n\n# Print a URL that will produce the filmstrip when accessed.\nprint(tempCol$getFilmstripThumbURL(filmArgs))"},{"path":"imagecollection.html","id":"advanced-techniques","chapter":"ImageCollection","heading":"Advanced techniques","text":"following sections describe use clipping, opacity, layer compositing enhance visualizations adding polygon borders, emphasizing regions interest, comparing images within collection.Note following examples section use base ImageCollection defined :","code":"\n# Import hourly predicted temperature image collection for northern winter\n# solstice. Note that predictions extend for 384 hours; limit the collection\n# to the first 24 hours.\ntempCol <- ee$ImageCollection(\"NOAA/GFS0P25\") %>%\n  ee$ImageCollection$filterDate(\"2018-12-22\", \"2018-12-23\") %>%\n  ee$ImageCollection$limit(24) %>%\n  ee$ImageCollection$select(\"temperature_2m_above_ground\")\n\n# Define visualization arguments to control the stretch and color gradient\n# of the data.\nvideoArgs <- list(\n  min = -40.0,\n  max = 35.0,\n  palette = c(\"blue\", \"purple\", \"cyan\", \"green\", \"yellow\", \"red\")\n)\n\n# Convert each image to an RGB visualization image by mapping the visualize\n# function over the image collection using the arguments defined previously.\ntempColVis <- tempCol$map(function(img) {\n  return(img$visualize(visArgs))\n})\n\n# Import country features and filter to South American countries.\nsouthAmCol <- ee$FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\")$\n  filterMetadata(\"wld_rgn\", \"equals\", \"South America\")\n\n# Define animation region (South America with buffer).\nsouthAmAoi <- ee$Geometry$Rectangle(\n  coords = c(-103.6, -58.8, -18.4, 17.4),\n  geodesic = FALSE\n)"},{"path":"imagecollection.html","id":"overlays","chapter":"ImageCollection","heading":"Overlays","text":"Multiple images can overlaid using blend Image method overlapping pixels two images blended based masks (opacity).","code":""},{"path":"imagecollection.html","id":"vector-overlay","chapter":"ImageCollection","heading":"Vector overlay","text":"Adding administrative boundary polygons geometries image can provide valuable spatial context. Consider global daily surface temperature animation (Figure 3). boundaries land ocean somewhat discernible, can made explicit adding polygon overlay countries.Vector data ( Features ) drawn images applying paint method. Features can painted existing image, better practice paint blank image, style , blend result styled image layers. Treating layer visualization stack independently affords control styling.following example demonstrates painting South American country borders blank Image blending result Image global daily temperature collection (Figure 6). overlaid country boundaries distinguish land water provide context patterns temperature.Figure 6. Add vector overlays images collection provide spatial context.","code":"\n# Define an empty image to paint features to.\nempty <- ee$Image()$byte()\n\n# Paint country feature edges to the empty image.\nsouthAmOutline <- empty$\n  paint(\n  featureCollection = southAmCol,\n  color = 1,\n  width = 1\n)$\n\n  # Convert to an RGB visualization image; set line color to black.\n  visualize(list(palette = \"000000\"))\n\n# Map a blend operation over the temperature collection to overlay the country\n# border outline image on all collection images.\ntempColOutline <- tempColVis$map(function(img) {\n  return(img$blend(southAmOutline))\n})\n\n# Define animation region (South America with buffer).\nsouthAmAoi <- ee$Geometry$Rectangle(\n  coords = c(-103.6, -58.8, -18.4, 17.4)\n)\n\n# Define animation arguments.\nvideoArgs <- list(\n  dimensions = 768,\n  region = southAmAoi,\n  framesPerSecond = 7,\n  crs = \"EPSG:3857\"\n)\n\n# Display the animation.\nprint(ui$Thumbnail(tempColOutline, videoArgs))"},{"path":"imagecollection.html","id":"image-overlay","chapter":"ImageCollection","heading":"Image overlay","text":"Several images can overlaid achieve desired style. Suppose want emphasize region interest. can create muted copy image visualization base layer overlay clipped version original visualization. Building previous example, following script produces Figure 7.Figure 7. Emphasize area interest clipping image overlaying muted copy.can also blend image data hillshade base layer indicate terrain give visualization depth (Figure 8).Figure 8. Show terrain overlaying partially transparent image data hillshade layer.","code":"\n# Define an empty image to paint features to.\nempty <- ee$Image()$byte()\n\n# Paint country feature edges to the empty image.\nsouthAmOutline <- empty$paint(featureCollection <- southAmCol, color <- 1, width <- 1)$\n  # Convert to an RGB visualization image; set line color to black.\n  visualize(list(palette = \"000000\"))\n\n# Map a blend operation over the temperature collection to overlay the country\n# border outline image on all collection images.\ntempColOutline <- tempColVis$map(function(img) {\n  return(img$blend(southAmOutline))\n})\n\n# Define a partially opaque grey RGB image to dull the underlying image when\n# blended as an overlay.\ndullLayer <- ee$Image$constant(175)$visualize(list(\n  opacity = 0.6,\n  min = 0,\n  max = 255,\n  forceRgbOutput = TRUE\n))\n\n# Map a two-part blending operation over the country outline temperature\n# collection for final styling.\nfinalVisCol <- tempColOutline$map(function(img) {\n  return(img)$\n    # Blend the dulling layer with the given country outline temperature image.\n    blend(dullLayer)$\n    # Blend a clipped copy of the country outline temperature image with the\n    # dulled background image.\n    blend(img$clipToCollection(southAmCol))\n})\n\n# Define animation region (South America with buffer).\nsouthAmAoi <- ee$Geometry$Rectangle(\n  coords = c(-103.6, -58.8, -18.4, 17.4)\n)\n\n# Define animation arguments.\nvideoArgs <- list(\n  dimensions = 768,\n  region = southAmAoi,\n  framesPerSecond = 7,\n  crs = \"EPSG:3857\"\n)\n\n# Display the animation.\nprint(ui$Thumbnail(finalVisCol, videoArgs))\n# Define a hillshade layer from SRTM digital elevation model.\nhillshade <- ee$Terrain$hillshade(ee$Image(\"USGS/SRTMGL1_003\")$\n  # Exaggerate the elevation to increase contrast in hillshade\n  multiply(100))$\n  # Clip the DEM by South American boundary to clean boundary between\n  # land and ocean.\n  clipToCollection(southAmCol)\n\n# Map a blend operation over the temperature collection to overlay a partially\n# opaque temperature layer on the hillshade layer.\nfinalVisCol <- tempColVis$map(function(img) {\n  return(hillshade$\n    blend(img$clipToCollection(southAmCol)$visualize({\n    opacity <- 0.6\n  })))\n})\n\n# Define animation region (South America with buffer).\nsouthAmAoi <- ee$Geometry$Rectangle(\n  coords = c(-103.6, -58.8, -18.4, 17.4)\n)\n\n# Define animation arguments.\nvideoArgs <- list(\n  dimensions = 768,\n  region = southAmAoi,\n  framesPerSecond = 7,\n  crs = \"EPSG:3857\"\n)\n\n# Display the animation.\nprint(ui$Thumbnail(finalVisCol, videoArgs))"},{"path":"imagecollection.html","id":"transitions","chapter":"ImageCollection","heading":"Transitions","text":"Customize image collection produce animations reveal differences two images within collection using fade, flicker, slide transitions. following examples use base visualization generated following script:","code":"\n# Define an area of interest geometry with a global non-polar extent.\naoi <- ee$Geometry$Polygon(\n  c(c(c(-179.0, 78.0), c(-179.0, -58.0), c(179.0, -58.0), c(179.0, 78.0)))\n)\n\n# Import hourly predicted temperature image collection.\ntemp <- ee$ImageCollection(\"NOAA/GFS0P25\")\n\n# Define a northern summer solstice temperature image.\nsummerSolTemp <- temp$\n  filterDate(\"2018-06-21\", \"2018-06-22\")$\n  filterMetadata(\"forecast_hours\", \"equals\", 12)$\n  first()$\n  select(\"temperature_2m_above_ground\")\n\n# Define a northern winter solstice temperature image.\nwinterSolTemp <- temp$\n  filterDate(\"2018-12-22\", \"2018-12-23\")$\n  filterMetadata(\"forecast_hours\", \"equals\", 12)$\n  first()$\n  select(\"temperature_2m_above_ground\")\n\n# Combine the solstice images into a collection.\ntempCol <- ee$ImageCollection(c(\n  summerSolTemp$set(\"season\", \"summer\"),\n  winterSolTemp$set(\"season\", \"winter\")\n))\n\n# Import international boundaries feature collection.\ncountries <- ee$FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\")\n\n## Define visualization arguments.\nvisArgs <- list(\n  min = -40.0,\n  max = 35.0,\n  palette = c(\"blue\", \"purple\", \"cyan\", \"green\", \"yellow\", \"red\")\n)\n\n# Convert the image data to RGB visualization images.\n# The clip and unmask combination sets ocean pixels to black.\ntempColVis <- tempCol$map(function(img) {\n  return(img$\n    visualize(visArgs)$\n    visualize(visArgs)$\n    unmask(0)$\n    copyProperties(img, img$propertyNames()))\n})"},{"path":"imagecollection.html","id":"flicker","chapter":"ImageCollection","heading":"Flicker","text":"two images collection, case , flicker default representation upon collection animation. Adjust framesPerSecond animation argument speed slow flicker rate. following visualization arguments applied collection produces Figure 9.Figure 9. Example flickering 12pm GMT surface temperature northern winter solstice.","code":"\n# Define arguments for animation function parameters.\nvideoArgs <- list(\n  dimensions = 768,\n  region = aoi,\n  framesPerSecond = 2,\n  crs = \"EPSG:3857\"\n)\n\n# Display animation to the Rstudio console.\nprint(ui$Thumbnail(tempColVis, videoArgs))"},{"path":"imagecollection.html","id":"fade","chapter":"ImageCollection","heading":"Fade","text":"fade transition two layers achieved simultaneously decreasing opacity one layer increasing opacity sequence opacity increments near 0 1 (Figure 10).Figure 10. Example fading 12pm GMT surface temperature summer winter solstice.","code":"\n# Define a sequence of decreasing opacity increments. Note that opacity cannot\n# be 0, so near 1 and 0 are used. Near 1 is needed because a compliment is\n# calculated in a following step that can result in 0 if 1 is an element of the\n# list.\nopacityList <- ee$List$sequence(\n  start = 0.99999,\n  end = 0.00001,\n  count = 20\n)\n\n# Filter the summer and winter solstice images from the collection and set as\n# image objects.\nsummerImg <- tempColVis$filter(ee$Filter$eq(\"season\", \"summer\"))$first()\nwinterImg <- tempColVis$filter(ee$Filter$eq(\"season\", \"winter\"))$first()\n\n# Map over the list of opacity increments to iteratively adjust the opacity of\n# the two solstice images. Returns a list of images.\nimgList <- opacityList$map(function(opacity) {\n  opacityCompliment <- ee$Number(1)$subtract(ee$Number(opacity))\n  winterImgFade <- winterImg$visualize({\n    opacity <- opacity\n  })\n  summerImgFade <- summerImg$visualize({\n    opacity <- opacityCompliment\n  })\n  return(summerImgFade$blend(winterImgFade)$set(\"opacity\", opacity))\n})\n\n# Convert the image list to an image collection; the forward phase.\nfadeForward <- ee$ImageCollection$fromImages(imgList)\n\n# Make a copy of the collection that is sorted by ascending opacity to\n# represent the reverse phase.\nfadeBackward <- fadeForward$sort(list(property <- \"opacity\"))\n\n# Merge the forward and reverse phase frame collections.\nfadeCol <- fadeForward$merge(fadeBackward)\n\n# Define animation arguments.\nvideoArgs <- list(\n  dimensions = 768,\n  region = aoi,\n  framesPerSecond = 2,\n  crs = \"EPSG:3857\"\n)\n\n# Display the animation.\nprint(ui$Thumbnail(fadeCol, videoArgs))"},{"path":"imagecollection.html","id":"slider","chapter":"ImageCollection","heading":"Slider","text":"slider transition progressively shows hides underlying image layer. achieved iteratively adjusting opacity overlying image across range longitudes (Figure 11).Figure 11. Example sliding transition 12pm GMT surface temperature summer winter solstice.","code":"\n# Define a sequence of longitude increments. Start and end are defined by the\n# min and max longitude of the feature to be provided to the region parameter\n# of the animation arguments dictionary.\nlonSeq <- ee$List$sequence(\n  start = -179,\n  end = 179,\n  count = 20\n)\n\n# Define a longitude image.\nlongitude <- ee$Image$pixelLonLat()$select(\"longitude\")\n\n# Filter the summer and winter solstice images from the collection and set as\n# image objects.\nsummerImg <- tempColVis$filter(ee$Filter$eq(\"season\", \"summer\"))$first()\nwinterImg <- tempColVis$filter(ee$Filter$eq(\"season\", \"winter\"))$first()\n\n# Map over the list of longitude increments to iteratively adjust the mask\n# (opacity) of the overlying image layer. Returns a list of images.\nimgList <- lonSeq$map(function(lon) {\n  lon <- ee$Number(lon)\n  mask <- longitude$gt(lon)\n  return(summerImg$blend(winterImg$updateMask(mask))$set(\"lon\", lon))\n})\n\n# Convert the image list to an image collection; concealing phase.\nsliderColForward <- ee$ImageCollection$fromImages(imgList)\n\n# Make a copy of the collection that is sorted by descending longitude to\n# represent the revealing phase.\nsliderColbackward <- sliderColForward$\n  sort(list(\n  property = \"lon\",\n  ascending = FALSE\n))\n\n\n# Merge the forward and backward phase frame collections.\nsliderCol <- sliderColForward$merge(sliderColbackward)\n\n# Define animation arguments.\nvideoArgs <- list(\n  dimensions = 768,\n  region = aoi,\n  framesPerSecond = 25,\n  crs = \"EPSG:3857\"\n)\n\n# Display the animation.\nprint(ui$Thumbnail(sliderCol, videoArgs))"},{"path":"imagecollection.html","id":"imagecollection-information-and-metadata","chapter":"ImageCollection","heading":"ImageCollection Information and Metadata","text":"Images, variety ways get information ImageCollection. collection can printed directly console, console printout limited 5000 elements. Collections larger 5000 images need filtered printing. Printing large collection correspondingly slower. following example shows various ways getting information image collections programmatically:","code":"\n# Load a Landsat 8 ImageCollection for a single path-row.\ncollection <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_TOA\") %>%\n  ee$ImageCollection$filter(ee$Filter$eq(\"WRS_PATH\", 44)) %>%\n  ee$ImageCollection$filter(ee$Filter$eq(\"WRS_ROW\", 34)) %>%\n  ee$ImageCollection$filterDate(\"2014-03-01\", \"2014-08-01\")\nee_print(collection)\n\n# Get the number of images.\ncount <- collection$size()\nprint(\"Count: \", count$getInfo())\n\n# Get the date range of images in the collection.\nrange <- collection$reduceColumns(\n  ee$Reducer$minMax(),\n  list(\"system:time_start\")\n)\n\ncol_min <- eedate_to_rdate(range$get(\"min\"))\ncol_max <- eedate_to_rdate(range$get(\"max\"))\ncat(\"Date range: \", as.character(col_min), as.character(col_max))\n\n# Get statistics for a property of the images in the collection.\nsunStats <- collection$aggregate_stats(\"SUN_ELEVATION\")\ncat(\"Sun elevation statistics: \")\nsunStats$getInfo()\n\n# Sort by a cloud cover property, get the least cloudy image.\nimage <- ee$Image(collection$sort(\"CLOUD_COVER\")$first())\ncat(\"Least cloudy image: \")\nimage$getInfo()\n\n# Limit the collection to the 10 most recent images.\nrecent <- collection$sort(\"system:time_start\", FALSE)$limit(10)\ncat(\"Recent images: \")\nrecent$getInfo()"},{"path":"imagecollection.html","id":"filtering-an-imagecollection","chapter":"ImageCollection","heading":"Filtering an ImageCollection","text":"illustrated Get Started section ImageCollection Information section, Earth Engine provides variety convenience methods filtering image collections. Specifically, many common use cases handled imageCollection$filterDate(), imageCollection$filterBounds(). general purpose filtering, use imageCollection$filter() ee$Filter argument. following example demonstrates convenience methods filter() identify remove images bad registration ImageCollection:Figure 12a. Bad compositeFigure 12b. Good composite","code":"\n# Load Landsat 5 data, filter by date and bounds.\ncollection <- ee$ImageCollection(\"LANDSAT/LT05/C01/T2\") %>%\n  ee$ImageCollection$filterDate(\"1987-01-01\", \"1990-05-01\") %>%\n  ee$ImageCollection$filterBounds(ee$Geometry$Point(25.8544, -18.08874))\n\n# Also filter the collection by the IMAGE_QUALITY property.\nfiltered <- collection %>%\n  ee$ImageCollection$filterMetadata(\"IMAGE_QUALITY\", \"equals\", 9)\n\n# Create two composites to check the effect of filtering by IMAGE_QUALITY.\nbadComposite <- ee$Algorithms$Landsat$simpleComposite(collection, 75, 3)\ngoodComposite <- ee$Algorithms$Landsat$simpleComposite(filtered, 75, 3)\n\n# Display the composites.\nMap$setCenter(25.8544, -18.08874, 13)\nMap$addLayer(\n  eeObject <- badComposite,\n  vizParams <- list(\n    bands = c(\"B3\", \"B2\", \"B1\"),\n    gain = 3.5\n  ),\n  name <- \"bad composite\"\n)\nMap$addLayer(\n  eeObject <- goodComposite,\n  vizParams <- list(\n    bands = c(\"B3\", \"B2\", \"B1\"),\n    gain = 3.5\n  ),\n  name <- \"good composite\"\n)"},{"path":"imagecollection.html","id":"mapping-over-an-imagecollection","chapter":"ImageCollection","heading":"Mapping over an ImageCollection","text":"apply function every Image ImageCollection use imageCollection$map() . argument map() function takes one parameter: ee$Image. example, following code adds timestamp band every image collection:Note predefined function, metadata() method used create new Image value property. discussed Reducing Compositing sections, time band useful linear modeling change making composites.mapped function limited operations can perform. Specifically, can’t modify variables outside function; can’t print anything; can’t use R ‘’ ‘’ statements. However, can use ee$Algorithms$() perform conditional operations mapped function. example:Inspect list images output ImageCollection note condition evaluated () algorithm true, output contains constant image. Although demonstrates server-side conditional function (learn client vs. server Earth Engine page, avoid () general use filters instead.","code":"\n# Load a Landsat 8 collection for a single path-row.\ncollection <- ee$ImageCollection(\"LANDSAT/LC8_L1T_TOA\") %>%\n  ee$ImageCollection$filter(ee$Filter$eq(\"WRS_PATH\", 44)) %>%\n  ee$ImageCollection$filter(ee$Filter$eq(\"WRS_ROW\", 34))\n\n# This function uses a conditional statement to return the image if\n# the solar elevation > 40 degrees.  Otherwise it returns a zero image.\nconditional <- function(image) {\n  return(ee$Algorithms$If(\n    ee$Number(image$get(\"SUN_ELEVATION\"))$gt(40),\n    image,\n    ee$Image(0)\n  ))\n}\n\n# Map the function over the collection, convert to a List and print the result.\nee_print(collection$map(conditional))\n# Load a Landsat 8 collection for a single path-row.\ncollection <- ee$ImageCollection(\"LANDSAT/LC8_L1T_TOA\") %>%\n  ee$ImageCollection$filter(ee$Filter$eq(\"WRS_PATH\", 44)) %>%\n  ee$ImageCollection$filter(ee$Filter$eq(\"WRS_ROW\", 34))\n\n# This function uses a conditional statement to return the image if\n# the solar elevation > 40 degrees.  Otherwise it returns a zero image.\nconditional <- function(image) {\n  return(ee$Algorithms$If(\n    ee$Number(image$get(\"SUN_ELEVATION\"))$gt(40),\n    image,\n    ee$Image(0)\n  ))\n}\n\n# Map the function over the collection, convert to a List and print the result.\nee_print(collection$map(conditional))"},{"path":"imagecollection.html","id":"reducing-an-imagecollection","chapter":"ImageCollection","heading":"Reducing an ImageCollection","text":"composite images ImageCollection, use imageCollection$reduce(). composite images collection single image representing, example, min, max, mean standard deviation images. (See Reducers section information reducers). example, create median value image collection:Figure 13. Median value image collectionAt location output image, band, pixel value median unmasked pixels input imagery (images collection). previous example, median() convenience method following call:Figure 14. Median value image collectionNote band names differ result using reduce() instead convenience method. Specifically, names reducer appended band names.complex reductions also possible using reduce(). example, compute long term linear trend collection, use one linear regression reducers. following code computes linear trend MODIS Enhanced Vegetation Index (EVI):Figure 15. Linear trend MODIS Enhanced Vegetation Index (EVI)Note output reduction example two banded image one band slope linear regression ( scale ) one band intercept ( offset ). Explore API documentation see list reducers available reduce ImageCollection single Image.","code":"\n# Load a Landsat 8 collection for a single path-row.\ncollection <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_TOA\") %>%\n  ee$ImageCollection$filter(ee$Filter$eq(\"WRS_PATH\", 44)) %>%\n  ee$ImageCollection$filter(ee$Filter$eq(\"WRS_ROW\", 34)) %>%\n  ee$ImageCollection$filterDate(\"2014-01-01\", \"2015-01-01\")\n\n# Compute a median image and display.\nmedian <- collection$median()\nMap$setCenter(-122.3578, 37.7726, 12)\nMap$addLayer(\n  eeObject <- median,\n  vizParams <- list(\n    bands = c(\"B4\", \"B3\", \"B2\"),\n    max = 0.3\n  ),\n  name <- \"median\"\n)\n# Reduce the collection with a median reducer.\nmedian <- collection$reduce(ee$Reducer$median())\n\n# Display the median image.\nMap$addLayer(\n  eeObject <- median,\n  vizParams <- list(\n    bands = c(\"B4_median\", \"B3_median\", \"B2_median\"),\n    max = 0.3\n  ),\n  name <- \"also median\"\n)\n# This function adds a band representing the image timestamp.\naddTime <- function(image) {\n  return(image$addBands(image$metadata(\"system:time_start\")$\n    # Convert milliseconds from epoch to years to aid in\n    # interpretation of the following trend calculation.\n    divide(1000 * 60 * 60 * 24 * 365)))\n}\n\n# Load a MODIS collection, filter to several years of 16 day mosaics,\n# and map the time band function over it.\ncollection <- ee$ImageCollection(\"MODIS/006/MYD13A1\")$\n  filterDate(\"2004-01-01\", \"2010-10-31\")$\n  map(addTime)\n\n# Select the bands to model with the independent variable first.\ntrend <- collection$select(c(\"system:time_start\", \"EVI\"))$\n  # Compute the linear trend over time.\n  reduce(ee$Reducer$linearFit())\n\n# Display the trend with increasing slopes in green, decreasing in red.\nMap$setCenter(-96.943, 39.436, 5)\nMap$addLayer(\n  eeObject <- trend,\n  vizParams <- list(\n    min = 0,\n    max = c(-100, 100, 10000),\n    bands = c(\"scale\", \"scale\", \"offset\")\n  ),\n  name <- \"EVI trend\"\n)"},{"path":"imagecollection.html","id":"composites-have-no-projection","chapter":"ImageCollection","heading":"Composites have no projection","text":"Composite images created reducing image collection able produce pixels requested projection therefore fixed output projection. Instead, composites default projection WGS-84 1-degree resolution pixels. Composites default projection computed whatever output projection requested. request occurs displaying composite Rstudio (learn Rstudio sets scale projection), explicitly specifying projection/scale aggregation ReduceRegion Export.","code":""},{"path":"imagecollection.html","id":"compositing-and-mosaicking","chapter":"ImageCollection","heading":"Compositing and Mosaicking","text":"general, compositing refers process combining spatially overlapping images single image based aggregation function. Mosaicking refers process spatially assembling image datasets produce spatially continuous image. Earth Engine, terms used interchangeably, though compositing mosaicking supported. example, consider task compositing multiple images location. example, using one National Agriculture Imagery Program (NAIP) Digital Orthophoto Quarter Quadrangle (DOQQ) different times, following example demonstrates making maximum value composite:Figure 16. Maxium value compositeConsider need mosaic four different DOQQs time, different locations. following example demonstrates using imageCollection$mosaic() :Figure 17. Spatial mosaicNote overlap DOQQs previous example. mosaic() method composites overlapping images according order collection (last top). control source pixels mosaic (composite), use image masks. example, following uses thresholds spectral indices mask image data mosaic:Figure 18. National Agriculture Imagery Program (NAIP) Digital Orthophoto Quarter Quadrangle (DOQQ)make composite maximizes arbitrary band input, use imageCollection$qualityMosaic(). qualityMosaic() method sets pixel composite based image collection maximum value specified band. example, following code demonstrates making greenest pixel composite recent value composite:Use Rstudio Inspector tab check pixel values different locations composites. Observe system:time_start band varies location, indicating different pixels come different times.","code":"\n# Load three NAIP quarter quads in the same location, different times.\nnaip2004_2012 <- ee$ImageCollection(\"USDA/NAIP/DOQQ\") %>%\n  ee$ImageCollection$filterBounds(ee$Geometry$Point(-71.08841, 42.39823)) %>%\n  ee$ImageCollection$filterDate(\"2004-07-01\", \"2012-12-31\") %>%\n  ee$ImageCollection$select(c(\"R\", \"G\", \"B\"))\n\n# Temporally composite the images with a maximum value function.\ncomposite <- naip2004_2012$max()\nMap$setCenter(-71.12532, 42.3712, 12)\nMap$addLayer(\n  eeObject <- composite,\n  visParams <- list(),\n  name <- \"max value composite\"\n)\n# Load four 2012 NAIP quarter quads, different locations.\nnaip2012 <- ee$ImageCollection(\"USDA/NAIP/DOQQ\") %>%\n  ee$ImageCollection$filterBounds(ee$Geometry$Rectangle(-71.17965, 42.35125, -71.08824, 42.40584)) %>%\n  ee$ImageCollection$filterDate(\"2012-01-01\", \"2012-12-31\")\n\n# Spatially mosaic the images in the collection and display.\nmosaic <- naip2012$mosaic()\nMap$setCenter(-71.12532, 42.3712, 12)\nMap$addLayer(\n  eeObject <- mosaic,\n  visParams <- list(),\n  name <- \"spatial mosaic\"\n)\n# Load a NAIP quarter quad, display.\nnaip <- ee$Image(\"USDA/NAIP/DOQQ/m_4207148_nw_19_1_20120710\")\nMap$setCenter(-71.0915, 42.3443, 14)\nMap$setZoom(zoom <- 14)\nMap$addLayer(\n  eeObject <- naip,\n  visParams <- list(),\n  name <- \"NAIP DOQQ\"\n)\n# Create the NDVI and NDWI spectral indices.\nndvi <- naip$normalizedDifference(c(\"N\", \"R\"))\nndwi <- naip$normalizedDifference(c(\"G\", \"N\"))\n\n# Create some binary images from thresholds on the indices.\n# This threshold is designed to detect bare land.\nbare1 <- ndvi$lt(0.2)$And(ndwi$lt(0.3))\n# This detects bare land with lower sensitivity. It also detects shadows.\nbare2 <- ndvi$lt(0.2)$And(ndwi$lt(0.8))\n\n# Define visualization parameters for the spectral indices.\nndviViz <- list(\n  min = -1,\n  max = 1,\n  palette = c(\"FF0000\", \"00FF00\")\n)\nndwiViz <- list(\n  min = 0.5,\n  max = 1,\n  palette = c(\"FF0000\", \"00FF00\")\n)\n\n# Mask and mosaic visualization images.  The last layer is on top.\nmosaic <- ee$ImageCollection(list(\n  # NDWI > 0.5 is water.  Visualize it with a blue palette.\n  ndwi$updateMask(ndwi$gte(0.5))$visualize(ndwiViz),\n  # NDVI > 0.2 is vegetation.  Visualize it with a green palette.\n  ndvi$updateMask(ndvi$gte(0.2))$visualize(ndviViz),\n  # Visualize bare areas with shadow (bare2 but not bare1) as gray.\n  bare2$updateMask(bare2$And(bare1$Not()))$visualize(list(palette <- c(\"AAAAAA\"))),\n  # Visualize the other bare areas as white.\n  bare1$updateMask(bare1)$visualize(list(palette <- c(\"FFFFFF\")))\n))$mosaic()\n\nMap$addLayer(\n  eeObject <- ndwi,\n  visParams <- list(),\n  name <- \"Visualization mosaic\"\n)\n# This function masks clouds in Landsat 8 imagery.\nmaskClouds <- function(image) {\n  scored <- ee$Algorithms$Landsat$simpleCloudScore(image)\n  return(image$updateMask(scored$select(c(\"cloud\"))$lt(20)))\n}\n\n# This function masks clouds and adds quality bands to Landsat 8 images.\naddQualityBands <- function(image) {\n  return(maskClouds(image)$\n    # NDVI\n    addBands(image$normalizedDifference(c(\"B5\", \"B4\")))$\n    addBands(image$metadata(\"system:time_start\")))\n}\n\n# Load a 2014 Landsat 8 ImageCollection.\n# Map the cloud masking and quality band function over the collection.\ncollection <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_TOA\")$\n  filterDate(\"2014-06-01\", \"2014-12-31\")$\n  map(addQualityBands)\n\n# Create a cloud-free, most recent value composite.\nrecentValueComposite <- collection$qualityMosaic(\"system:time_start\")\n\n# Create a greenest pixel composite.\ngreenestPixelComposite <- collection$qualityMosaic(\"nd\")\n\n# Display the results.\nMap$setCenter(-122.374, 37.8239, 12) # San Francisco Bay\nvizParams <- list(\n  bands = c(\"B5\", \"B4\", \"B3\"),\n  min = 0,\n  max = 0.4\n)\nMap$addLayer(\n  eeObject <- recentValueComposite,\n  vizParams <- vizParams,\n  name <- \"recent value composite\"\n)\nMap$addLayer(greenestPixelComposite, vizParams, \"greenest pixel composite\")\n# Compare to a cloudy image in the collection.\ncloudy <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140825\")\nMap$addLayer(\n  eeObject <- cloudy, \n  vizParams <- vizParams, \n  name <- \"cloudy\")"},{"path":"imagecollection.html","id":"iterating-over-an-imagecollection","chapter":"ImageCollection","heading":"Iterating over an ImageCollection","text":"\nAlthough map() applies function every image collection, \nfunction visits every image collection independently. example, suppose \nwant compute cumulative anomaly () time t time\nseries. obtain recursively defined series form =\nf(Imaget, -1), mapping won’t work function\n(f) depends previous result (-1). example, suppose\nwant compute series cumulative Normalized Difference Vegetation Index (NDVI)\nanomaly images relative baseline. Let A0<- 0 \nf(Imaget, -1)<- Imaget + -1\n-1 cumulative anomaly time t-1 \nImaget anomaly time t. Use\nimageCollection.iterate() make recursively defined\nImageCollection. following example, function\naccumulate() takes two parameters: image collection, list\nprevious outputs. call iterate(), anomaly \nadded running sum result added list. final result \npassed ImageCollection constructor get new sequence images:\nCumulative anomaliesCharting sequences indicates whether NDVI stabilizing relative previous disturbances whether NDVI trending new state. Learn charts Earth Engine Charts section.iterated function limited operations can perform. Specifically, can’t modify variables outside function; can’t print anything; can’t use R ‘’ ‘’ statements. results wish collect intermediate information wish carry next iteration must function’s return value. can use ee$Algorithms$() perform conditional operations.","code":"\n# Load MODIS EVI imagery.\ncollection <- ee$ImageCollection(\"MODIS/006/MYD13A1\")$select(\"EVI\")\n\n# Define reference conditions from the first 10 years of data.\nreference <- collection$filterDate(\"2001-01-01\", \"2010-12-31\")$\n  sort(\"system:time_start\", FALSE)\n\n# Compute the mean of the first 10 years.\nmean <- reference$mean()\n\n# Compute anomalies by subtracting the 2001-2010 mean from each image in a\n# collection of 2011-2014 images. Copy the date metadata over to the\n# computed anomaly images in the new collection.\nseries <- collection$filterDate(\"2011-01-01\", \"2014-12-31\")$map(function(image) {\n  return(image$subtract(mean)$set(\"system:time_start\", image$get(\"system:time_start\")))\n})\n\n# Display cumulative anomalies.\nMap$setCenter(-100.811, 40.2, 5)\nMap$addLayer(\n  eeObject <- series$sum(),\n  vizParams <- list(\n    min = -60000,\n    max = 60000,\n    palette = c(\"FF0000\", \"000000\", \"00FF00\")\n  ),\n  name <- \"EVI anomaly\"\n)\n# Get the timestamp from the most recent image in the reference collection.\ntime0 <- reference$first()$get(\"system:time_start\")\n\n# Use imageCollection.iterate() to make a collection of cumulative anomaly over time.\n# The initial value for iterate() is a list of anomaly images already processed.\n# The first anomaly image in the list is just 0, with the time0 timestamp.\nfirst <- ee$List(c(\n  # Rename the first band 'EVI'.\n  ee$Image(0)$set(\"system:time_start\", time0)$select(c(0), c(\"EVI\"))\n))\n\n# This is a function to pass to Iterate().\n# As anomaly images are computed, add them to the list.\naccumulate <- function(image, list) {\n  # Get the latest cumulative anomaly image from the end of the list with\n  # get(-1).  Since the type of the list argument to the function is unknown,\n  # it needs to be cast to a List.  Since the return type of get() is unknown,\n  # cast it to Image.\n  previous <- ee$Image(ee$List(list)$get(-1))\n  # Add the current anomaly to make a new cumulative anomaly image.\n  added <- image$add(previous)$\n    # Propagate metadata to the new image.\n    set(\"system:time_start\", image$get(\"system:time_start\"))\n  # Return the list with the cumulative anomaly inserted.\n  return(ee$List(list)$add(added))\n}\n\n# Create an ImageCollection of cumulative anomaly images by iterating.\n# Since the return type of iterate is unknown, it needs to be cast to a List.\ncumulative <- ee$ImageCollection(ee$List(series$iterate(accumulate, first)))\n\n# Predefine the chart titles.\ntitle <- list(\n  title = \"Cumulative EVI anomaly over time\",\n  hAxis = list(title <- \"Time\"),\n  vAxis = list(title <- \"Cumulative EVI anomaly\")\n)\n\n# Chart some interesting locations.\npt1 <- ee$Geometry$Point(-65.544, -4.894)\nprint(\"Amazon rainforest:\", Chart$image$series(cumulative, pt1, ee$Reducer$first(), 500)$getInfo()$setOptions(title))\n\npt2 <- ee$Geometry$Point(116.4647, 40.1054)\nprint(\"Beijing urbanization:\", Chart$image$series(cumulative, pt2, ee$Reducer$first(), 500)$getInfo()$setOptions(title))\n\npt3 <- ee$Geometry$Point(-110.3412, 34.1982)\nprint(\"Arizona forest disturbance and recovery:\", Chart$image$series(cumulative, pt3, ee$Reducer$first(), 500)$getInfo()$setOptions(title))"},{"path":"geometry.html","id":"geometry","chapter":"Geometry","heading":"Geometry","text":"section requires next libraries:","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()"},{"path":"geometry.html","id":"geometry-overview","chapter":"Geometry","heading":"Geometry Overview","text":"Earth Engine handles vector data Geometry type. GeoJSON spec describes detail type geometries supported Earth Engine, including Point (list coordinates projection), LineString (list points), LinearRing (closed LineString), Polygon (list LinearRings first shell subsequent rings holes). Earth Engine also supports MultiPoint, MultiLineString, MultiPolygon. GeoJSON GeometryCollection also supported, although name MultiGeometry within Earth Engine.","code":""},{"path":"geometry.html","id":"creating-geometry-objects","chapter":"Geometry","heading":"Creating Geometry objects","text":"create Geometry programmatically, provide constructor proper list(s) coordinates. example:previous examples, note distinction LineString LinearRing LinearRing “closed” coordinate start end list.individual Geometry may consist multiple geometries. break multi-part Geometry constituent geometries, use geometry$geometries(). example:","code":"\npoint <- ee$Geometry$Point(c(1.5, 1.5))\n\nlineString <- ee$Geometry$LineString(\n  c(c(-35, -10), c(35, -10), c(35, 10), c(-35, 10))\n)\n\nlinearRing <- ee$Geometry$LinearRing(\n  c(c(-35, -10), c(35, -10), c(35, 10), c(-35, 10), c(-35, -10))\n)\n\nrectangle <- ee$Geometry$Rectangle(c(-40, -20, 40, 20))\n\npolygon <- ee$Geometry$Polygon(c(\n  c(c(-5, 40), c(65, 40), c(65, 60), c(-5, 60), c(-5, 60))\n))\n# Create a multi-part feature.\nmultiPoint <- ee$Geometry$MultiPoint(c(c(-121.68, 39.91), c(-97.38, 40.34)))\n\n# Get the individual geometries as a list.\ngeometries <- multiPoint$geometries()\n\n# Get each individual geometry from the list and print it.\npt1 <- geometries$get(0)\npt2 <- geometries$get(1)\npaste0('Point 1', ee$Geometry$getInfo(pt1))\npaste0('Point 2', ee$Geometry$getInfo(pt2))"},{"path":"geometry.html","id":"geodesic-vs.-planar-geometries","chapter":"Geometry","heading":"Geodesic vs. Planar Geometries","text":"geometry created Earth Engine either geodesic (.e. edges shortest path surface sphere) planar (.e. edges shortest path 2-D Cartesian plane). one planar coordinate system suitable global collections features, Earth Engine’s geometry constructors build geodesic geometries default. make planar geometry, constructors geodesic parameter can set FALSE:Figure 1 shows difference default geodesic polygon result converting polygon planar representation.Figure 1. geodesic polygon (red) planar polygon (black).can convert geodesic planar geometries using ‘ee$Geometry’ constructor.","code":"\nplanarPolygon <- ee$Geometry(polygon, NULL, FALSE)"},{"path":"geometry.html","id":"geometry-visualization-and-information","chapter":"Geometry","heading":"Geometry Visualization and Information","text":"","code":""},{"path":"geometry.html","id":"visualizing-geometries","chapter":"Geometry","heading":"Visualizing geometries","text":"visualize geometry, add map. example:visualizing, see Feature FeatureCollection Visualization.","code":"\n# Create a geodesic polygon.\npolygon <- ee$Geometry$Polygon(c(\n  c(c(-5, 40), c(65, 40), c(65, 60), c(-5, 60), c(-5, 60))\n))\n\n# Create a planar polygon.\nplanarPolygon <- ee$Geometry(polygon, NULL, FALSE)\n\n# Display the polygons by adding them to the map.\nMap$centerObject(polygon)\nMap$addLayer(polygon, list(color<- 'FF0000'), 'geodesic polygon')\nMap$addLayer(planarPolygon, list(color<- '000000'), 'planar polygon')"},{"path":"geometry.html","id":"geometry-information-and-metadata","chapter":"Geometry","heading":"Geometry information and metadata","text":"view information geometry, print . access information programmatically, Earth Engine provides several methods. example, get information polygon created previously, use:Observe perimeter (length) geometry returned meters area returned square meters unless projection specified. default, computation performed WGS84 spheroid result computed meters square meters.","code":"\nprint(paste0(\"Polygon printout: \", ee$Geometry$getInfo(polygon)))\n\n# Print polygon area in square kilometers.\nprint(paste0(\"Polygon area: \", ee$Geometry$getInfo(polygon$area()$divide(1000 * 1000))))\n\n# Print polygon perimeter length in kilometers.\nprint(paste0(\"Polygon perimeter: \", ee$Geometry$getInfo(polygon$perimeter()$divide(1000))))\n\n# Print the geometry as a GeoJSON string.\nprint(paste0(\"Polygon GeoJSON: \", ee$Geometry$getInfo(polygon$toGeoJSONString())))\n\n# Print the GeoJSON 'type'.\nprint(paste0(\"Geometry type: \", ee$Geometry$getInfo(polygon$type())))\n\n# Print the coordinates as lists.\nprint(paste0(\"Polygon coordinates: \", ee$Geometry$getInfo(polygon$coordinates())))\n\n# Print whether the geometry is geodesic.\nprint(paste0(\"Geodesic: \", ee$Geometry$getInfo(polygon$geodesic())))"},{"path":"geometry.html","id":"geometric-operations","chapter":"Geometry","heading":"Geometric Operations","text":"Observe previous example buffer distance specified meters.Supported geometric operations also include relational computations geometries intersection, union, difference, distance, contains, etc. test relations, geometries use “even-odd” rule default. even-odd rule, point inside polygon line point point known outside polygon crosses odd number edges. inside polygon everything inside shell inside hole. simple example, point within circular polygon must cross exactly one edge escape polygon. Geometries can optionally use “left-inside” rule, necessary. Imagine walking points ring order given; inside left.demonstrate difference geometries created “left-inside” rule (evenOdd: FALSE) created “even-odd” rule, following example compares point two different polygons:previous example demonstrates order coordinates provided Polygon constructor affects result left-inside polygon constructed. Specifically, point outside left-inside polygon inside even-odd polygon.following example computes visualizes derived geometries based relationship two polygons:examples, note maxError parameter set one meter geometry operations. maxError maximum allowable error, meters, transformations (projection reprojection) may alter geometry. one geometries different projection , Earth Engine computation spherical coordinate system, projection precision given maxError. can also specify specific projection computation, necessary.","code":"\n# Create a geodesic polygon.\npolygon <- ee$Geometry$Polygon(c(\n  c(c(-5, 40), c(65, 40), c(65, 60), c(-5, 60), c(-5, 60))\n))\n\n# Compute a buffer of the polygon.\nbuffer <- polygon$buffer(1000000)\n\n# Compute the centroid of the polygon.\ncentroid <- polygon$centroid()\n\nMap$addLayer(\n  buffer,\n  {},\n  \"buffer\"\n) +\n  Map$addLayer(\n    centroid,\n    list(color<- \"red\"),\n    \"centroid\"\n  )\n# Create a right-inside polygon.\nholePoly <- ee$Geometry$Polygon(\n  coords<- list(\n    c(-35, -10), c(-35, 10), c(35, 10), c(35, -10), c(-35, -10)\n  ),\n  proj<- \"EPSG:4326\",\n  geodesic<- TRUE,\n  maxError<- 1.,\n  evenOdd<- FALSE\n)\n\n\n# Create an even-odd version of the polygon.\nevenOddPoly <- ee$Geometry(\n  geo_json<- holePoly$getInfo(),\n  opt_proj<- \"EPSG:4326\",\n  opt_evenOdd<- TRUE\n)\n\n# Create a point to test the insideness of the polygon.\npt <- ee$Geometry$Point(c(1.5, 1.5))\n\n# Check insideness with a contains operator.\nprint(holePoly$contains(pt)$getInfo()) # FALSE\nprint(evenOddPoly$contains(pt)$getInfo()) # TRUE\n# Create two circular geometries.\npoly1 <- ee$Geometry$Point(c(-50, 30))$buffer(1e6)\npoly2 <- ee$Geometry$Point(c(-40, 30))$buffer(1e6)\n\n# Display polygon 1 in red and polygon 2 in blue.\nMap$setCenter(-45, 30)\nMap$addLayer(poly1, list(color<- \"FF0000\"), \"poly1\")\nMap$addLayer(poly2, list(color<- \"0000FF\"), \"poly2\")\n# Compute the intersection, display it in green.\nintersection <- poly1$intersection(poly2, ee$ErrorMargin(1))\nMap$addLayer(intersection, list(color<- \"00FF00\"), \"intersection\")\n# Compute the union, display it in magenta.\nunion <- poly1$union(poly2, ee$ErrorMargin(1))\nMap$addLayer(union, list(color<- \"FF00FF\"), \"union\")\n# Compute the difference, display in yellow.\ndiff1 <- poly1$difference(poly2, ee$ErrorMargin(1))\nMap$addLayer(diff1, list(color<- \"FFFF00\"), \"diff1\")\n# Compute symmetric difference, display in black.\nsymDiff <- poly1$symmetricDifference(poly2, ee$ErrorMargin(1))\nMap$addLayer(symDiff, list(color<- \"000000\"), \"symmetric difference\")"},{"path":"feature-featurecollection.html","id":"feature-featurecollection","chapter":"Feature & FeatureCollection","heading":"Feature & FeatureCollection","text":"section requires next libraries:","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()"},{"path":"feature-featurecollection.html","id":"feature-overview","chapter":"Feature & FeatureCollection","heading":"Feature Overview","text":"Feature Earth Engine defined GeoJSON Feature. Specifically, Feature object geometry property storing Geometry object (NULL) properties property storing dictionary properties.","code":""},{"path":"feature-featurecollection.html","id":"creating-feature-objects","chapter":"Feature & FeatureCollection","heading":"Creating Feature objects","text":"create Feature, provide constructor Geometry (optionally) dictionary properties. example:Geometry, Feature may printed added map inspection visualization:Feature need Geometry may simply wrap dictionary properties. example:example, note dictionary supplied Feature contains computed value. Creating features manner useful exporting long-running computations Dictionary result (e.g. image$reduceRegion()). See FeatureCollections Importing Table Data Exporting guides details.Feature one primary Geometry stored geometry property. Additional geometries may stored properties. Geometry methods intersection buffer also exist Feature convenience getting primary Geometry, applying operation, setting result new primary Geometry. result retain properties Feature method called. also methods getting setting non-geometry properties Feature. example:previous example, note properties can set either key: value pair, list r literal. Also note feature$set() overwrites existing properties.","code":"\n# Create an ee$Geometry.\npolygon <- ee$Geometry$Polygon(\n  c(c(-35, -10), c(35, -10), c(35, 10), c(-35, 10), c(-35, -10))\n)\n\n# Create a Feature from the Geometry.\npolyFeature <- ee$Feature(polygon, list(foo<- 42, bar<- \"tart\"))\nprint(ee$Feature$getInfo(polyFeature))\nMap$addLayer(\n  polyFeature,\n  {},\n  \"feature\"\n)\n# Create a dictionary of properties, some of which may be computed values.\ndict <- list(foo<- ee$Number(8)$add(88), bar<- \"nihao\")\n\n# Create a NULL geometry feature with the dictionary of properties.\nnowhereFeature <- ee$Feature(NULL, dict)\n# Make a feature and set some properties.\nfeature <- ee$Feature(ee$Geometry$Point(c(-122.22599, 37.17605)))$\n  set(\"genus\", \"Sequoia\")$set(\"species\", \"sempervirens\")\n\n# Get a property from the feature.\nspecies <- feature$get(\"species\")\nprint(ee$Feature$getInfo(species))\n\n# Set a new property.\nfeature <- feature$set(\"presence\", 1)\n\n# Overwrite the old properties with a new dictionary.\nnewDict <- list(genus<- \"Brachyramphus\", species<- \"marmoratus\")\nfeature <- feature$set(newDict)\n\n# Check the result.\nprint(ee$Feature$getInfo(feature))"},{"path":"feature-featurecollection.html","id":"featurecollection-overview","chapter":"Feature & FeatureCollection","heading":"FeatureCollection Overview","text":"Groups related features can combined FeatureCollection, enable additional operations entire set filtering, sorting rendering. Besides just simple features (geometry + properties), feature collections can also contain collections.","code":""},{"path":"feature-featurecollection.html","id":"the-featurecollection-constructor","chapter":"Feature & FeatureCollection","heading":"The FeatureCollection constructor","text":"One way create FeatureCollection provide constructor list features. features need geometry type properties. example:Individual geometries can also turned FeatureCollection just one Feature:","code":"\n# Make a list of Features.\nfeatures <- c(\n  ee$Feature(ee$Geometry$Rectangle(30.01, 59.80, 30.59, 60.15), list(name<- \"Voronoi\")),\n  ee$Feature(ee$Geometry$Point(-73.96, 40.781), list(name<- \"Thiessen\")),\n  ee$Feature(ee$Geometry$Point(6.4806, 50.8012), list(name<- \"Dirichlet\"))\n)\n\n# Create a FeatureCollection from the list and print it.\nfromList <- ee$FeatureCollection(features)\nprint(ee$FeatureCollection$getInfo(fromList))\n# Create a FeatureCollection from a single geometry and print it.\nfromGeom <- ee$FeatureCollection(ee$Geometry$Point(16.37, 48.225))\nprint(ee$FeatureCollection$getInfo(fromGeom))"},{"path":"feature-featurecollection.html","id":"table-datasets","chapter":"Feature & FeatureCollection","heading":"Table Datasets","text":"Earth Engine hosts variety table datasets. load table dataset, provide table ID FeatureCollection constructor. example, load TIGER roads data:Note image datasets, can search table datasets import script using Rstudio search tool discover Earth Engine Data Catalog.","code":"\nfc <- ee$FeatureCollection(\"TIGER/2016/Roads\")\nMap$setCenter(-73.9596, 40.7688, 12)\nMap$addLayer(\n  fc,\n  {},\n  \"Census roads\"\n)"},{"path":"feature-featurecollection.html","id":"random-samples","chapter":"Feature & FeatureCollection","heading":"Random Samples","text":"get collection random points specified region, can use:","code":"\n# Define an arbitrary region in which to compute random points.\nregion <- ee$Geometry$Rectangle(-119.224, 34.669, -99.536, 50.064)\n\n# Create 1000 random points in the region.\nrandomPoints <- ee$FeatureCollection$randomPoints(region)\n\n# Display the points.\nMap$centerObject(randomPoints)\nMap$addLayer(\n  randomPoints,\n  {},\n  \"random points\"\n)"},{"path":"feature-featurecollection.html","id":"feature-and-featurecollection-visualization","chapter":"Feature & FeatureCollection","heading":"Feature and FeatureCollection Visualization","text":"images, geometries features, feature collections can added map directly Map$addLayer(). default visualization display vectors solid black lines semi-opaque black fill. render vectors color, specify color parameter. following displays ‘RESOLVE’ ecoregions (Dinerstein et al. 2017) default visualization red:additional display options, use featureCollection$draw(). Specifically, parameters pointRadius strokeWidth control size points lines, respectively, rendered FeatureCollection:output draw() image red, green blue bands set according specified color parameter.control FeatureCollection displayed, use image$paint() FeatureCollection argument. Unlike draw(), outputs three-band, 8-bit display image, image$paint() outputs image specified numeric value ‘painted’ . Alternatively, can supply name property FeatureCollection contains numbers paint. width parameter behaves way: can constant name property number line width. example:Note empty image paint features needs cast prior painting. constant image behaves constant: clamped initialization value. color feature edges values set property features, set color parameter name property numeric values:color width boundaries drawn can set properties. example:width parameter provided, interior features painted:render interior edges features, paint empty image twice:","code":"\n# Load a FeatureCollection from a table dataset: 'RESOLVE' ecoregions.\necoregions <- ee$FeatureCollection(\"RESOLVE/ECOREGIONS/2017\")\n\n# Display as default and with a custom color.\nMap$addLayer(\n  ecoregions,\n  {},\n  \"default display\"\n) |\n  Map$addLayer(\n    ecoregions,\n    list(color<- \"FF0000\"),\n    \"colored\"\n  )\nMap$addLayer(\n  ecoregions$draw(color<- \"006600\", strokeWidth<- 5),\n  {},\n  \"drawn\"\n)\n# Create an empty image into which to paint the features, cast to byte.\nempty <- ee$Image()$byte()\n\n# Paint all the polygon edges with the same number and width, display.\noutline <- empty$paint(\n  featureCollection<- ecoregions,\n  color<- 1,\n  width<- 3\n)\nMap$addLayer(\n  outline,\n  list(palette<- \"FF0000\"),\n  \"edges\"\n)\n# Paint the edges with different colors, display.\noutlines <- empty$paint(\n  featureCollection<- ecoregions,\n  color<- \"BIOME_NUM\",\n  width<- 4\n)\n\npalette <- c(\"FF0000\", \"00FF00\", \"0000FF\")\n\nMap$addLayer(\n  outlines,\n  list(palette<- palette, max<- 14),\n  \"different color edges\"\n)\n# Paint the edges with different colors and widths.\noutlines <- empty$paint(\n  featureCollection<- ecoregions,\n  color<- \"BIOME_NUM\",\n  width<- \"NNH\"\n)\nMap$addLayer(\n  outlines,\n  list(palette<- palette, max<- 14),\n  \"different color, width edges\"\n)\n# Paint the interior of the polygons with different colors.\nfills <- empty$paint(\n  featureCollection<- ecoregions,\n  color<- \"BIOME_NUM\"\n)\nMap$addLayer(\n  fills,\n  list(palette<- palette, max<- 14),\n  \"colored fills\"\n)\n# Paint both the fill and the edges.\nfilledOutlines <- empty$paint(ecoregions, \"BIOME_NUM\")$\n  paint(ecoregions, 0, 2)\n\nMap$addLayer(\n  filledOutlines,\n  list(\n    palette<- c(\"000000\", palette),\n    max<- 14\n  ), \"edges and fills\"\n)"},{"path":"feature-featurecollection.html","id":"featurecollection-information-and-metadata","chapter":"Feature & FeatureCollection","heading":"FeatureCollection Information and Metadata","text":"Methods getting information feature collection metadata image collections. See ImageCollection Information Metadata section details.","code":""},{"path":"feature-featurecollection.html","id":"metadata-aggregation","chapter":"Feature & FeatureCollection","heading":"Metadata aggregation","text":"can use aggregation shortcuts count number features summarize attribute:","code":"\n# Load watersheds from a data table.\nsheds <- ee$FeatureCollection(\"USGS/WBD/2017/HUC06\")$\n  # Filter to the continental US.\n  filterBounds(ee$Geometry$Rectangle(-127.18, 19.39, -62.75, 51.29))$\n  # Convert 'areasqkm' property from string to number.\n  map(function(feature) {\n  num <- ee$Number$parse(feature$get(\"areasqkm\"))\n  return(feature$set(\"areasqkm\", num))\n})\n\n# Display the table and print its first element.\nMap$addLayer(\n  sheds,\n  {},\n  \"watersheds\"\n)\nprint(paste0(\"First watershed\", ee$Number$getInfo(sheds$first())))\n\n# Print the number of watersheds.\nprint(paste0(\"Count: \", ee$Number$getInfo(sheds$size())))\n\n# Print stats for an area property.\nprint(paste0(\"Area stats: \", ee$Number$getInfo(sheds$aggregate_stats(\"areasqkm\"))))"},{"path":"feature-featurecollection.html","id":"column-information","chapter":"Feature & FeatureCollection","heading":"Column information","text":"Knowing names dataypes FeatureCollection columns can helpful (e.g., filtering collection metadata). following example prints column names datatypes collection point features representing protected areas.general purpose FeatureCollection aggregation tools, see Reducing FeatureCollection page.","code":"\n# Import a protected areas point feature collection.\nwdpa <- ee$FeatureCollection(\"WCMC/WDPA/current/points\")\n\n# Fetch collection metadata (`.limit(0)`) and the printed object is a\n# DataFrame where keys are column names and values are datatypes.\nwdpa$limit(0)$getInfo()$column %>% as.data.frame()"},{"path":"feature-featurecollection.html","id":"filtering-a-featurecollection","chapter":"Feature & FeatureCollection","heading":"Filtering a FeatureCollection","text":"Filtering FeatureCollection analogous filtering ImageCollection. (See Filtering ImageCollection section). featureCollection$filterDate(), featureCollection$filterBounds() convenience methods featureCollection$filter() method use applicable ee$Filter. example:","code":"\n# Load watersheds from a data table.\nsheds <- ee$FeatureCollection(\"USGS/WBD/2017/HUC06\")$\n  # Convert 'areasqkm' property from string to number.\n  map(function(feature) {\n  num <- ee$Number$parse(feature$get(\"areasqkm\"))\n  return(feature$set(\"areasqkm\", num))\n})\n\n# Define a region roughly covering the continental US.\ncontinentalUS <- ee$Geometry$Rectangle(-127.18, 19.39, -62.75, 51.29)\n\n# Filter the table geographically: only watersheds in the continental US.\nfiltered <- sheds$filterBounds(continentalUS)\n\n# Check the number of watersheds after filtering for location.\npaste0(\"Count after filter:\", ee$Number$getInfo(filtered$size()))\n# Filter to get only larger continental US watersheds.\nlargeSheds <- filtered$filter(ee$Filter$gt(\"areasqkm\", 25000))\n\n# Check the number of watersheds after filtering for size and location.\npaste0(\"Count after filtering by size:\", ee$Number$getInfo(largeSheds$size()))"},{"path":"feature-featurecollection.html","id":"mapping-over-a-featurecollection","chapter":"Feature & FeatureCollection","heading":"Mapping over a FeatureCollection","text":"apply operation every Feature FeatureCollection, use featureCollection$map(). example, add another area attribute every feature watersheds FeatureCollection, use:previous example, note new property set based computation feature’s geometry. Properties can also set using computation involving existing properties.entirely new FeatureCollection can generated map(). following example converts watersheds centroids:Note subset properties propagated features new collection.","code":"\n# Load watersheds from a data table.\nsheds <- ee$FeatureCollection(\"USGS/WBD/2017/HUC06\")\n\n# This function computes the feature's geometry area and adds it as a property.\naddArea <- function(feature) {\n  return(feature$set(list(lareaHa<- feature$geometry()$area()$divide(100 * 100))))\n}\n\n# Map the area getting function over the FeatureCollection.\nareaAdded <- sheds$map(addArea)\n\n# Print the first feature from the collection with the added property.\nprint(ee$Element$getInfo(areaAdded$first()))\n# This function creates a new feature from the centroid of the geometry.\ngetCentroid <- function(feature) {\n  # Keep this list of properties.\n  keepProperties <- c(\"name\", \"huc6\", \"tnmid\", \"areasqkm\")\n  # Get the centroid of the feature's geometry.\n  centroid <- feature$geometry()$centroid()\n  # Return a new Feature, copying properties from the old Feature.\n  return(ee$Feature(centroid)$copyProperties(feature, keepProperties))\n}\n\n# Map the centroid getting function over the features.\ncentroids <- sheds$map(getCentroid)\n\n# Display the results.\nMap$addLayer(centroids, list(color<- \"FF0000\"), \"centroids\")"},{"path":"feature-featurecollection.html","id":"reducing-a-featurecollection","chapter":"Feature & FeatureCollection","heading":"Reducing a FeatureCollection","text":"aggregate data properties FeatureCollection, use featureCollection$reduceColumns(). example, check area properties watersheds FeatureCollection, code computes Root Mean Square Error (RMSE) relative Earth Engine computed area:example, note return value reduceColumns() dictionary key ‘mean’. get mean, cast result dictionary$get() number ee$Number() trying call sqrt() . information ancillary data structures Earth Engine, see tutorial.overlay features imagery, use featureCollection$reduceRegions(). example, compute volume precipitation continental US watersheds, use reduceRegions() followed map():information reducing feature collections, see Statistics FeatureCollection Columns Vector Raster Conversion.","code":"\n# Load watersheds from a data table and filter to the continental US.\nsheds <- ee$FeatureCollection(\"USGS/WBD/2017/HUC06\")$\n  filterBounds(ee$Geometry$Rectangle(-127.18, 19.39, -62.75, 51.29))\n\n# This function computes the squared difference between an area property\n# and area computed directly from the feature's geometry.\nareaDiff <- function(feature) {\n  # Compute area in sq. km directly from the geometry.\n  area <- feature$geometry()$area()$divide(1000 * 1000)\n  # Compute the differece between computed area and the area property.\n  diff <- area$subtract(ee$Number$parse(feature$get(\"areasqkm\")))\n  # Return the feature with the squared difference set to the 'diff' property.\n  feature$set(\"diff\", diff$pow(2))\n}\n\n\n# Calculate RMSE for population of difference pairs.\nrmse <- ee$Number(\n  # Map the difference function over the collection.\n  sheds$map(areaDiff)$\n    # Reduce to get the mean squared difference.\n    reduceColumns(ee$Reducer$mean(), list(\"diff\"))$\n    get(\"mean\")\n)$\n  # Compute the square root of the mean square to get RMSE.\n  sqrt()\n\n# Print the result.\ncat(\"RMSE=\", ee$Number$getInfo(rmse))\n# Load an image of daily precipitation in mm/day.\nprecip <- ee$Image(ee$ImageCollection(\"NASA/ORNL/DAYMET_V3\")$first())\n\n# Load watersheds from a data table and filter to the continental US.\nsheds <- ee$FeatureCollection(\"USGS/WBD/2017/HUC06\")$\n  filterBounds(ee$Geometry$Rectangle(-127.18, 19.39, -62.75, 51.29))\n\n# Add the mean of each image as new properties of each feature.\nwithPrecip <- precip$reduceRegions(sheds, ee$Reducer$mean())$\n  filter(ee$Filter$notNull(list(\"prcp\")))\n\n# This function computes total rainfall in cubic meters.\nprcpVolume <- function(feature) {\n  # Precipitation in mm/day -> meters -> sq. meters.\n  volume <- ee$Number(feature$get(\"prcp\"))$\n    divide(1000)$multiply(feature$geometry()$area())\n  return(feature$set(\"volume\", volume))\n}\n\nhighVolume <- withPrecip$\n  # Map the function over the collection.\n  map(prcpVolume)$\n  # Sort descending.\n  sort(\"volume\", FALSE)$\n  # Get only the 5 highest volume watersheds.\n  limit(5)$\n  # Extract the names to a list.\n  reduceColumns(ee$Reducer$toList(), list(\"name\"))$get(\"list\")\n\n# Print the resulting FeatureCollection.\nprint(ee$ComputedObject$getInfo(highVolume))"},{"path":"feature-featurecollection.html","id":"vector-to-raster-interpolation","chapter":"Feature & FeatureCollection","heading":"Vector to Raster Interpolation","text":"Interpolation vector raster Earth Engine creates Image FeatureCollection. Specifically, Earth Engine uses numeric data stored property features interpolate values new locations outside features. interpolation results continuous Image interpolated values distance specified.","code":""},{"path":"feature-featurecollection.html","id":"inverse-distance-weighted-interpolation","chapter":"Feature & FeatureCollection","heading":"Inverse Distance Weighted Interpolation","text":"inverse distance weighting (IDW) function Earth Engine based method described Basso et al. (1999). additional control parameter added form decay factor (gamma) inverse distance. parameters include mean standard deviation property interpolate maximum range distance interpolate. following example creates interpolated surface methane concentration fill spatial gaps original raster dataset. FeatureCollection generated sampling two-week methane composite.Note , specified range parameter, interpolation exists 70 kilometers nearest measurement station.","code":"\n# Import two weeks of S5P methane and composite by mean.\nch4 <- ee$ImageCollection(\"COPERNICUS/S5P/OFFL/L3_CH4\")$\n  select(\"CH4_column_volume_mixing_ratio_dry_air\")$\n  filterDate(\"2019-08-01\", \"2019-08-15\")$\n  mean()$\n  rename(\"ch4\")\n\n# Define an area to perform interpolation over.\naoi <-\n  ee$Geometry$Polygon(\n    c(\n      c(-95.68487605978851, 43.09844605027055),\n      c(-95.68487605978851, 37.39358590079781),\n      c(-87.96148738791351, 37.39358590079781),\n      c(-87.96148738791351, 43.09844605027055)\n    ), NULL, FALSE\n  )\n\n# Sample the methane composite to generate a FeatureCollection.\nsamples <- ch4$addBands(ee$Image$pixelLonLat())$\n  sample(\n  region<- aoi, numPixels<- 1500,\n  scale<- 1000, projection<- \"EPSG:4326\"\n)$\n  map(function(sample) {\n  lat <- sample$get(\"latitude\")\n  lon <- sample$get(\"longitude\")\n  ch4 <- sample$get(\"ch4\")\n  return(ee$Feature(ee$Geometry$Point(c(lon, lat)), list(ch4<- ch4)))\n})\n\n# Combine mean and standard deviation reducers for efficiency.\ncombinedReducer <- ee$Reducer$mean()$combine(\n  reducer2<- ee$Reducer$stdDev(),\n  sharedInputs<- TRUE\n)\n\n# Estimate global mean and standard deviation from the points.\nstats <- samples$reduceColumns(\n  reducer<- combinedReducer,\n  selectors<- list(\"ch4\")\n)\n\n# Do the interpolation, valid to 70 kilometers.\ninterpolated <- samples$inverseDistance(\n  range<- 7e4,\n  propertyName<- \"ch4\",\n  mean<- stats$get(\"mean\"),\n  stdDev<- stats$get(\"stdDev\"),\n  gamma<- 0.3\n)\n\n# Define visualization arguments.\nband_viz <- list(\n  min<- 1800,\n  max<- 1900,\n  palette<- c(\n    \"0D0887\", \"5B02A3\", \"9A179B\", \"CB4678\",\n    \"EB7852\", \"FBB32F\", \"F0F921\"\n  )\n)\n\n# Display to map.\nMap$centerObject(aoi, 7)\nMap$addLayer(ch4, band_viz, \"CH4\") |\n  Map$addLayer(interpolated, band_viz, \"CH4 Interpolated\")"},{"path":"feature-featurecollection.html","id":"kriging","chapter":"Feature & FeatureCollection","heading":"Kriging","text":"Kriging interpolation method uses modeled estimate semi-variance create image interpolated values optimal combination values known locations. Kriging estimator requires parameters describe shape semi-variogram fit known data points. parameters illustrated Figure 1.Figure 1. nugget, sill range parameters illustrated idealized variogram function.following example samples sea surface temperature (SST) image random locations, interpolates SST sample using Kriging:size neighborhood perform interpolation specified maxDistance parameter. Larger sizes result smoother output slower computations.","code":"\n# Load an image of sea surface temperature (SST).\nsst <- ee$Image(\"NOAA/AVHRR_Pathfinder_V52_L3/20120802025048\")$\n  select(\"sea_surface_temperature\")$\n  rename(\"sst\")$\n  divide(100)\n\n# Define a geometry in which to sample points\ngeometry <- ee$Geometry$Rectangle(c(-65.60, 31.75, -52.18, 43.12))\n\n# Sample the SST image at 1000 random locations.\nsamples <- sst$addBands(ee$Image$pixelLonLat())$\n  sample(region<- geometry, numPixels<- 1000)$\n  map(function(sample) {\n  lat <- sample$get(\"latitude\")\n  lon <- sample$get(\"longitude\")\n  sst <- sample$get(\"sst\")\n  ee$Feature(ee$Geometry$Point(list(lon, lat)), list(sst<- sst))\n})\n\n# Interpolate SST from the sampled points.\ninterpolated <- samples$kriging(\n  propertyName<- \"sst\",\n  shape<- \"exponential\",\n  range<- 100 * 1000,\n  sill<- 1.0,\n  nugget<- 0.1,\n  maxDistance<- 100 * 1000,\n  reducer<- \"mean\"\n)\n\ncolors <- c(\n  \"00007F\", \"0000FF\", \"0074FF\",\n  \"0DFFEA\", \"8CFF41\", \"FFDD00\",\n  \"FF3700\", \"C30000\", \"790000\"\n)\n\nvis <- list(min<- -3, max<- 40, palette<- colors)\n\nMap$setCenter(-60.029, 36.457, 5)\nMap$addLayer(interpolated, vis, \"Interpolated\") |\n  Map$addLayer(sst, vis, \"Raw SST\") +\n    Map$addLayer(\n      samples,\n      {},\n      \"Samples\",\n      FALSE\n    )"},{"path":"reducer.html","id":"reducer","chapter":"Reducer","heading":"Reducer","text":"section requires next libraries:","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()"},{"path":"reducer.html","id":"reducer-overview","chapter":"Reducer","heading":"Reducer Overview","text":"Reducers way aggregate data time, space, bands, arrays data structures Earth Engine. ee$Reducer class specifies data aggregated. reducers class can specify simple statistic use aggregation (e.g. minimum, maximum, mean, median, standard deviation, etc.), complex summary input data (e.g. histogram, linear regression, list). Reductions may occur time ( imageCollection$reduce() )ç, space ( image$reduceRegion() , image$reduceNeighborhood() ), bands ( image$reduce() ), attribute space FeatureCollection ( featureCollection$reduceColumns() FeatureCollection methods start aggregate_).","code":""},{"path":"reducer.html","id":"reducers-have-inputs-and-outputs","chapter":"Reducer","heading":"Reducers have inputs and outputs","text":"Reducers take input dataset produce single output. single input reducer applied multi-band image, Earth Engine automatically replicates reducer applies separately band. result, output image number bands input image; band output reduction pixels corresponding band input data. reducers take tuples input datasets. reducers automatically replicated band. example, ee$Reducer$LinearRegression() takes multiple predictor datasets (representing independent variables regression) particular order (see Regression reducers).reducers produce multiple outputs, example ee$Reducer$minMax(), ee$Reducer$histogram() ee$Reducer$toList(). example:produce output twice number bands inputs, band names output ‘_min’ ‘_max’ appended band name.output type match computation. example, reducer applied ImageCollection Image output. output interpreted pixel value, must use reducers numeric output reduce ImageCollection (reducers like toList() histogram() won’t work).","code":"\n# Load and filter the Sentinel-2 image collection.\ncollection <- ee$ImageCollection(\"COPERNICUS/S2\")$\n  filterDate(\"2016-01-01\", \"2016-12-31\")$\n  filterBounds(ee$Geometry$Point(c(-81.31, 29.90)))\n\n# Reduce the collection$\nextrema <- collection$reduce(ee$Reducer$minMax())"},{"path":"reducer.html","id":"reducers-use-weighted-inputs","chapter":"Reducer","heading":"Reducers use weighted inputs","text":"default, reductions pixel values weighted mask, though behavior can changed (see Weighting section). Pixels mask equal 0 used reduction.","code":""},{"path":"reducer.html","id":"combining-reducers","chapter":"Reducer","heading":"Combining reducers","text":"intent apply multiple reducers inputs, ’s good practice combine() reducers efficiency. Specifically, calling combine() reducer sharedInputs set true result single pass data. example, compute mean standard deviation pixels image, use something like :output, note names reducers appended names inputs distinguish reducer outputs. behavior also applies image outputs, name reducer appended output band names.","code":"\n# Load a Landsat 8 image.\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1/LC08_044034_20140318\")\n\n# Combine the mean and standard deviation reducers.\nreducers <- ee$Reducer$mean()$combine(\n  reducer2<- ee$Reducer$stdDev(),\n  sharedInputs<- TRUE\n)\n\n# Use the combined reducer to get the mean and SD of the image.\nstats <- image$reduceRegion(\n  reducer<- reducers,\n  bestEffort<- TRUE\n)\n\n# Display the dictionary of band means and SDs.\nprint(stats$getInfo())"},{"path":"reducer.html","id":"imagecollection-reductions","chapter":"Reducer","heading":"ImageCollection Reductions","text":"Consider example needing take median time series images represented ImageCollection. reduce ImageCollection, use imageCollection$reduce(). reduces collection images individual image illustrated Figure 1. Specifically, output computed pixel-wise, pixel output composed median value images collection location. get statistics, mean, sum, variance, arbitrary percentile, etc., appropriate reducer selected applied. (See Docs tab Rstudio list reducers currently available). basic statistics like min, max, mean, etc., ImageCollection shortcut methods like min(), max(), mean(), etc. function exactly way calling reduce(), except resultant band names name reducer appended.Figure 1. Illustration ee.Reducer applied ImageCollection.example reducing ImageCollection, consider collection Landsat 5 images, filtered path row. following code uses reduce() reduce collection one Image (median reducer used simply illustrative purposes):returns multi-band Image, pixel median unmasked pixels ImageCollection pixel location. Specifically, reducer repeated band input imagery, meaning median computed independently band. Note band names name reducer appended: ‘B1_median’, ‘B2_median’, etc. output look something like Figure 2.information reducing image collections, see reducing section ImageCollection docs. particular, note images produced reducing ImageCollection projection. means explicitly set scale computations involving computed images output ImageCollection reduction.","code":"\n# Load an image collection, filtered so it's not too much data.\ncollection <- ee$ImageCollection(\"LANDSAT/LT05/C01/T1\")$\n  filterDate(\"2008-01-01\", \"2008-12-31\")$\n  filter(ee$Filter$eq(\"WRS_PATH\", 44))$\n  filter(ee$Filter$eq(\"WRS_ROW\", 34))\n\n# Compute the median in each band, each pixel.\n# Band names are B1_median, B2_median, etc.\nmedian <- collection$reduce(ee$Reducer$median())\n\n# The output is an Image.  Add it to the map.\nvis_param <- list(\n  bands<- c(\"B4_median\", \"B3_median\", \"B2_median\"),\n  gamma<- 1.6\n)\nMap$setCenter(-122.3355, 37.7924, 9)\nMap$addLayer(median, vis_param)"},{"path":"reducer.html","id":"image-reductions","chapter":"Reducer","heading":"Image Reductions","text":"reduce Image, use image$reduce(). Reducing image functions analogous way imageCollection$reduce(), except bands image input reducer rather images collection. output also image number bands equal number reducer outputs. example:","code":"\n# Load an image and select some bands of interest.\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1/LC08_044034_20140318\")$\n  select(c(\"B4\", \"B3\", \"B2\"))\n\n# Reduce the image to get a one-band maximum value image.\nmaxValue <- image$reduce(ee$Reducer$max())\n\n# Display the result.\nMap$centerObject(image, 10)\nMap$addLayer(maxValue, list(max<- 13000), \"Maximum value image\")"},{"path":"reducer.html","id":"statistics-of-an-image-region","chapter":"Reducer","heading":"Statistics of an Image Region","text":"","code":""},{"path":"reducer.html","id":"reduceregion","chapter":"Reducer","heading":"reduceRegion","text":"get statistics pixel values region ee$Image, use image$reduceRegion(). reduces pixels region(s) statistic compact representation pixel data region (e.g. histogram). region represented Geometry, might polygon, containing many pixels, might single point, case one pixel region. either case, illustrated Figure 3, output statistic derived pixels region.Figure 3. illustration ee$Reducer applied image region.example getting pixel statistics region image using reduceRegion(), consider finding mean spectral values 5-year Landsat composite within boundaries Sierra Nevada Coniferous Forest (illustrated Figure 4):force computation, suffices print result, Rstudio display Dictionary console. output look something like:Figure 4. False color composite Landsat image data California Nevada. region reduce shown white.Note example reduction specified providing reducer (ee$Reducer$mean()), geometry (region$geometry()), scale (30 meters) maxPixels maximum number pixels input reducer. scale always specified reduceRegion() calls. complex processing flows, may involve data different sources different scales, scale output unambiguously determined inputs. case, scale defaults 1 degree, generally produces unsatisfactory results. See page information Earth Engine handles scale.two ways set scale: specifying scale parameter, specifying CRS CRS transform. (See glossary information CRS’s CRS transforms). example, meanDictionary reduction () equivalent following:general, specifying scale sufficient results readable code. Earth Engine determines pixels input reducer first rasterizing region. scale specified without CRS, region rasterized image’s native projection scaled specified resolution. CRS scale specified, region rasterized based .","code":"\n# Load input imagery: Landsat 7 5-year composite.\nimage <- ee$Image(\"LANDSAT/LE7_TOA_5YEAR/2008_2012\")\n\n# Load an input region: Sierra Nevada.\nregion <- ee$Feature(ee$FeatureCollection(\"EPA/Ecoregions/2013/L3\")$\n  filter(ee$Filter$eq(\"us_l3name\", \"Sierra Nevada\"))$\n  first())\n\n# Reduce the region. The region parameter is the Feature geometry.\nmeanDictionary <- image$reduceRegion(\n  reducer<- ee$Reducer$mean(),\n  geometry<- region$geometry(),\n  scale<- 30,\n  maxPixels<- 1e9\n)\n\n# The result is a Dictionary.  Print it.\nprint(meanDictionary$getInfo())\nB1: 25.406029716816853\nB2: 23.971497014238988\nB3: 22.91059593763103\nB4: 54.83164133293403\nB5: 38.07655472573677\nB6_VCID_2: 198.93216428012906\nB7: 24.063261634961563\n# As an alternative to specifying scale, specify a CRS and a CRS transform.\n# Make this array by constructing a 4326 projection at 30 meters,\n# then copying the bounds of the composite, from composite.projection().\naffine <- c(0.00026949458523585647, 0, -180, 0, -0.00026949458523585647, 86.0000269494563)\n\n# Perform the reduction, print the result.\nprint(image$reduceRegion(\n  reducer<- ee$Reducer$mean(),\n  geometry<- region$geometry(),\n  crs<- \"EPSG:4326\",\n  crsTransform<- affine,\n  maxPixels<- 1e9\n)$getInfo())"},{"path":"reducer.html","id":"pixels-in-the-region","chapter":"Reducer","heading":"Pixels in the region","text":"Pixels determined region (weighted) according following rules, applied specified scale projection:Unweighted reducers (e.g. ee$Reducer$count() ee$Reducer$mean()$unweighted()): pixels included centroid region image’s mask non-zero.Weighted reducers (e.g. ee$Reducer$mean()): pixels included least (approximately) 0.5% pixel region image’s mask non-zero; weight minimum image’s mask (approximate) fraction pixel covered region.maxPixels parameter needed get computation succeed. parameter left example, error returned.multiple options get past errors: increase maxPixels, example, increase scale, set bestEffort true, automatically computes new (larger) scale maxPixels exceeded. specify maxPixels, default value used.","code":""},{"path":"reducer.html","id":"statistics-of-image-regions","chapter":"Reducer","heading":"Statistics of Image Regions","text":"get image statistics multiple regions stored FeatureCollection, can use image.reduceRegions() reduce multiple regions . input reduceRegions() Image FeatureCollection. output another FeatureCollection reduceRegions() output set properties Feature. example, means Landsat 7 annual composite bands feature geometry added properties input features:Observe new properties, keyed band name, added FeatureCollection store mean composite Feature geometry.","code":"\n# Load input imagery: Landsat 7 5-year composite.\nimage <- ee$Image(\"LANDSAT/LE7_TOA_5YEAR/2008_2012\")\n\n# Load a FeatureCollection of counties in Maine.\nmaineCounties <- ee$FeatureCollection(\"TIGER/2016/Counties\")$\n  filter(ee$Filter$eq(\"STATEFP\", \"23\"))\n\n# Add reducer output to the Features in the collection.\nmaineMeansFeatures <- image$reduceRegions(\n  collection<- maineCounties,\n  reducer<- ee$Reducer$mean(),\n  scale<- 30\n)\n\n# Print the first feature, to illustrate the result.\nprint(ee$Feature(maineMeansFeatures$first())$\n  select(image$bandNames())$\n  getInfo())"},{"path":"reducer.html","id":"statistics-of-image-neighborhoods","chapter":"Reducer","heading":"Statistics of Image Neighborhoods","text":"Rather specifying region perform reduction, also possible specify neighborhood apply reducer. reduce image neighborhoods, use image$reduceNeighborhood(). case, reduction occur sliding window input image, window size shape specified ee.Kernel. output reduceNeighborhood() another image, pixel value representing output reduction neighborhood around pixel input image. Figure 5 illustrates type reduction.Figure 5. Illustration reduceNeighborhood(), reducer applied kernel.example, consider using National Agriculture Imagery Program (NAIP) imagery quantify landscape differences resulting logging California redwood forests. Specifically, use standard deviation (SD) neighborhood represent difference texture logged area (SW image Figure 2) protected area (NE image Figure 2). example, get texture NAIP Normalized Difference Vegetation Index (NDVI) image, use reduceNeighborhood() compute SD neighborhood defined kernel:pixel non-zero kernel value included computation. kernel weights used default, though can change behavior inputWeight argument. input image reduceNeighborhood() output compared Figure 6.","code":"\n# Define a region in the redwood forest.\nredwoods <- ee$Geometry$Rectangle(-124.0665, 41.0739, -123.934, 41.2029)\n\n# Load input NAIP imagery and build a mosaic.\nnaipCollection <- ee$ImageCollection(\"USDA/NAIP/DOQQ\")$\n  filterBounds(redwoods)$\n  filterDate(\"2012-01-01\", \"2012-12-31\")\n\nnaip <- naipCollection$mosaic()\n\n# Compute NDVI from the NAIP imagery.\nnaipNDVI <- naip$normalizedDifference(c(\"N\", \"R\"))\n\n# Compute standard deviation (SD) as texture of the NDVI.\ntexture <- naipNDVI$reduceNeighborhood(\n  reducer<- ee$Reducer$stdDev(),\n  kernel<- ee$Kernel$circle(7)\n)\n\n# Display the results.\nMap$centerObject(redwoods, 12)\nMap$addLayer(\n  naip,\n  {},\n  \"NAIP input imagery\"\n)\nMap$addLayer(\n  naipNDVI,\n  list(min<- -1, max<- 1, palette<- c(\"FF0000\", \"00FF00\")),\n  \"NDVI\"\n)\nMap$addLayer(\n  texture,\n  list(min<- 0, max<- 0.3),\n  \"SD of NDVI\"\n)"},{"path":"reducer.html","id":"statistics-of-featurecollection-columns","chapter":"Reducer","heading":"Statistics of FeatureCollection Columns","text":"reduce properties features FeatureCollection, use featureCollection$reduceColumns(). Consider following toy example:Note inputs weighted according specified weight property.complex example, consider FeatureCollection US census blocks census data attributes. variables interest total population total housing units. can get sum(s) supplying summing reducer argument reduceColumns() printing result:output Dictionary representing aggregated property according specified reducer.Note example uses notNull() filter include features non-null entries selected properties collection reduced. good practice check null entries catch unexpected missing data avoid errors resulting calculations include null values.Also note unlike imageCollection$reduce(), reducers automatically repeated band, reducers FeatureCollection must explicitly repeated using repeat(). Specifically, repeat reducer m times m inputs.","code":"\n# Make a toy FeatureCollection.\naFeatureCollection <- ee$FeatureCollection(c(\n  ee$Feature(NULL, list(foo<- 1, weight<- 1)),\n  ee$Feature(NULL, list(foo<- 2, weight<- 2)),\n  ee$Feature(NULL, list(foo<- 3, weight<- 3))\n))\n\n# Compute a weighted mean and display it.\nprint(aFeatureCollection$reduceColumns(\n  reducer<- ee$Reducer$mean(),\n  selectors<- list(\"foo\"),\n  weightSelectors<- list(\"weight\")\n)$getInfo())\n# Load US cenus data as a FeatureCollection.\ncensus <- ee$FeatureCollection(\"TIGER/2010/Blocks\")\n\n# Filter the collection to include only Benton County, OR.\nbenton <- census$filter(\n  ee$Filter$And(\n    ee$Filter$eq(\"statefp10\", \"41\"),\n    ee$Filter$eq(\"countyfp10\", \"003\")\n  )\n)\n\n# Display Benton County cenus blocks.\nMap$setCenter(-123.27, 44.57, 13)\nMap$addLayer(benton)\n\n# Compute sums of the specified properties.\nproperties <- c(\"pop10\", \"housing10\")\n\nsums <- benton$\n  filter(ee$Filter$notNull(properties))$\n  reduceColumns(\n    reducer<- ee$Reducer$sum()$`repeat`(2),\n    selectors<- properties\n)\n\n# Print the resultant Dictionary.\nprint(sums$getInfo())"},{"path":"reducer.html","id":"raster-to-vector-conversion","chapter":"Reducer","heading":"Raster to Vector Conversion","text":"convert Image (raster) FeatureCollection (vector) data type, use image$reduceToVectors(). primary mechanism vectorization Earth Engine, can useful generating regions input types reducer. reduceToVectors() method creates polygon edges (optionally centroids bounding boxes instead) boundary homogeneous groups connected pixels.example, consider 2012 nightlights image Japan. Let nightlights digital number serve proxy development intensity. Define zones using arbitrary thresholds nightlights, combine zones single-band image, vectorize zones using reduceToVectors():Note first band input used identify homogeneous regions remaining bands reduced according provided reducer, output added property resultant vectors. geometry parameter specifies extent vectors created. general, good practice specify minimal zone create vectors. also good practice specify scale crs avoid ambiguity. output type ‘polygon’ polygons formed homogeneous zones four-connected neighbors (.e. eightConnected false). last two parameters, labelProperty reducer, specify output polygons receive property zone label mean nightlights band(s), respectively.mapped result look something like Tokyo area shown Figure 1. Inspection output polygons indicates polygon property storing label zone ({1, 2, 3}) mean nightlights band, since mean reducer specified.Figure 7. Zones nightlights Tokyo, Japan area. Vector boundaries displayed black.","code":"\n# Load a Japan boundary from the Large Scale International Boundary dataset.\njapan <- ee$FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\")$\n  filter(ee$Filter$eq(\"country_na\", \"Japan\"))\n\n# Load a 2012 nightlights image, clipped to the Japan border.\nnl2012 <- ee$Image(\"NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F182012\")$\n  select(\"stable_lights\")$\n  clipToCollection(japan)\n\n# Define arbitrary thresholds on the 6-bit nightlights image.\nzones <- nl2012$gt(30)$add(nl2012$gt(55))$add(nl2012$gt(62))\nzones <- zones$updateMask(zones$neq(0))\n\n# Convert the zones of the thresholded nightlights to vectors.\nvectors <- zones$addBands(nl2012)$reduceToVectors(\n  geometry<- japan,\n  crs<- nl2012$projection(),\n  scale<- 1000,\n  geometryType<- \"polygon\",\n  eightConnected<- FALSE,\n  labelProperty<- \"zone\",\n  reducer<- ee$Reducer$mean()\n)\n\n# Make a display image for the vectors, add it to the map.\ndisplay <- ee$Image(0)$updateMask(0)$paint(vectors, \"000000\", 3)\n\n# Display the thresholds.\nMap$setCenter(139.6225, 35.712, 9)\nMap$addLayer(\n  zones,\n  list(min<- 1, max<- 3, palette<- c(\"0000FF\", \"00FF00\", \"FF0000\")),\n  \"raster\"\n) +\n  Map$addLayer(\n    display,\n    list(palette<- \"000000\"),\n    \"vectors\"\n  )"},{"path":"reducer.html","id":"vector-to-raster-conversion","chapter":"Reducer","heading":"Vector to Raster Conversion","text":"Vector raster conversion Earth Engine handled featureCollection$reduceToImage() method. method assigns pixels feature value specified property. example uses counties data create image representing land area county:Specify reducer indicate aggregate properties overlapping features. previous example, since overlap, ee$Reducer$first() sufficient. example, pre-filter data eliminate nulls can turned image. output look something like Figure 8, maps color gradient county size. Like image-outputting reducers Earth Engine, scale dynamically set output. case, scale corresponds zoom level Rstudio.Figure 8. result reduceToImage() using ‘ALAND’ (land area) property ‘TIGER/2018/Counties’ FeatureCollection.","code":"\n# Load a collection of US counties.\ncounties <- ee$FeatureCollection(\"TIGER/2018/Counties\")\n\n# Make an image out of the land area attribute.\nlandAreaImg <- counties$\n  filter(ee$Filter$notNull(list(\"ALAND\")))$\n  reduceToImage(\n  properties<- list(\"ALAND\"),\n  reducer<- ee$Reducer$first()\n)\n\n# Display the county land area image.\nMap$setCenter(-99.976, 40.38, 5)\nMap$addLayer(landAreaImg, list(\n  min<- 3e8,\n  max<- 1.5e10,\n  palette<- c(\"FCFDBF\", \"FDAE78\", \"EE605E\", \"B63679\", \"711F81\", \"2C105C\")\n))"},{"path":"reducer.html","id":"grouped-reductions-and-zonal-statistics","chapter":"Reducer","heading":"Grouped Reductions and Zonal Statistics","text":"can get statistics zone Image FeatureCollection using reducer$group() group output reducer value specified input. example, compute total population number housing units state, example groups output reduction census block FeatureCollection follows:groupField argument index input selectors array contains codes group, groupName argument specifies name property store value grouping variable. Since reducer automatically repeated input, repeat(2) call needed.group output image$reduceRegions() can specify grouping band defines groups integer pixel values. type computation sometimes called “zonal statistics” zones specified grouping band statistic determined reducer. following example, change nightlights United States grouped land cover category:Note example, groupField index band containing zones group output. first band index 0, second index 1, etc.","code":"\n# Load a collection of US census blocks.\nblocks <- ee$FeatureCollection(\"TIGER/2010/Blocks\")\n\n# Compute sums of the specified properties, grouped by state code.\nsums <- blocks$\n  filter(ee$Filter$And(\n  ee$Filter$neq(\"pop10\", list()),\n  ee$Filter$neq(\"housing10\", list())\n))$\n  reduceColumns(\n  selectors<- c(\"pop10\", \"housing10\", \"statefp10\"),\n  reducer<- ee$Reducer$sum()$`repeat`(2)$group(\n    groupField<- 2,\n    groupName<- \"state-code\"\n  )\n)\n\n# Print the resultant Dictionary.\nprint(sums$getInfo())\n# Load a region representing the United States\nregion <- ee$FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\")$\n  filter(ee$Filter$eq(\"country_na\", \"United States\"))\n\n# Load MODIS land cover categories in 2001.\nlandcover <- ee$Image(\"MODIS/051/MCD12Q1/2001_01_01\")$\n  select(\"Land_Cover_Type_1\")\n\n# Load nightlights image inputs.\nnl2001 <- ee$Image(\"NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F152001\")$\n  select(\"stable_lights\")\nnl2012 <- ee$Image(\"NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F182012\")$\n  select(\"stable_lights\")\n\n# Compute the nightlights decadal difference, add land cover codes.\nnlDiff <- nl2012$subtract(nl2001)$addBands(landcover)\n\n# Grouped a mean 'reducer': change of nightlights by land cover category.\nmeans <- nlDiff$reduceRegion(\n  reducer<- ee$Reducer$mean()$group(\n    groupField<- 1,\n    groupName<- \"code\"\n  ),\n  geometry<- region$geometry(),\n  scale<- 1000,\n  maxPixels<- 1e8\n)\n\n# Print the resultant Dictionary.\nprint(means$getInfo())"},{"path":"reducer.html","id":"weighted-reductions","chapter":"Reducer","heading":"Weighted Reductions","text":"default, reducers applied imagery weight inputs according mask value. relevant context fractional pixels created operations clip(). Adjust behavior calling unweighted() reducer. Using unweighted reducer forces pixels region weight. following example illustrates pixel weighting can affect reducer output:difference results due pixels edge region receiving weight one result calling unweighted() reducer.order obtain explicitly weighted output, preferable set weights explicitly splitWeights() called reducer. reducer modified splitWeights() takes two inputs, second input weight. following example illustrates splitWeights() computing weighted mean Normalized Difference Vegetation Index (NDVI) region, weights given cloud score (cloudier, lower weight):Observe cloudWeight needs added band prior calling reduceRegion(). result indicates estimated mean NDVI higher result decreasing weight cloudy pixels.","code":"\n# Load a Landsat 8 input image.\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1/LC08_044034_20140318\")\n\n# Creat an arbitrary region.\ngeometry <- ee$Geometry$Rectangle(-122.496, 37.532, -121.554, 37.538)\n\n# Make an NDWI image$  It will have one band named 'nd'.\nndwi <- image$normalizedDifference(c(\"B3\", \"B5\"))\n\n# Compute the weighted mean of the NDWI image clipped to the region.\nweighted <- ndwi$clip(geometry)$\n  reduceRegion(\n  reducer<- ee$Reducer$sum(),\n  geometry<- geometry,\n  scale<- 30\n)$get(\"nd\")\n\n# Compute the UN-weighted mean of the NDWI image clipped to the region.\nunweighted <- ndwi$clip(geometry)$\n  reduceRegion(\n  reducer<- ee$Reducer$sum()$unweighted(),\n  geometry<- geometry,\n  scale<- 30\n)$get(\"nd\")\n\n# Observe the difference between weighted and unweighted reductions.\ncat(\"weighted:\", unlist(weighted$getInfo()))\ncat(\"unweighted\", unlist(unweighted$getInfo()))\n# Load an input Landsat 8 image.\nimage <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_186059_20130419\")\n\n# Compute cloud score and reverse it such that the highest\n# weight (100) is for the least cloudy pixels.\ncloudWeight <- ee$Image(100)$subtract(\n  ee$Algorithms$Landsat$simpleCloudScore(image)$select(list(\"cloud\"))\n)\n\n# Compute NDVI and add the cloud weight band.\nndvi <- image$normalizedDifference(c(\"B5\", \"B4\"))$addBands(cloudWeight)\n\n# Define an arbitrary region in a cloudy area.\nregion <- ee$Geometry$Rectangle(9.9069, 0.5981, 10.5, 0.9757)\n\n# Use a mean reducer.\nreducer <- ee$Reducer$mean()\n\n# Compute the unweighted mean.\nunweighted <- ndvi$select(list(\"nd\"))$reduceRegion(reducer, region, 30)\n\n# compute mean weighted by cloudiness.\nweighted <- ndvi$reduceRegion(reducer$splitWeights(), region, 30)\n\n# Observe the difference as a result of weighting by cloudiness.\ncat(\"unweighted:\", unlist(unweighted$getInfo()))\ncat(\"weighted:\", unlist(weighted$getInfo()))"},{"path":"reducer.html","id":"linear-regression","chapter":"Reducer","heading":"Linear Regression","text":"Earth Engine several methods performing linear regression using reducers:\n- ee$Reducer$linearFit()\n- ee$Reducer$linearRegression()\n- ee$Reducer$robustLinearRegression()\n- ee$Reducer$ridgeRegression()simplest linear regression reducer linearFit() computes least squares estimate linear function one variable constant term. flexible approach linear modelling, use one linear regression reducers allow variable number independent dependent variables. linearRegression() implements ordinary least squares regression(OLS). robustLinearRegression() uses cost function based regression residuals iteratively de-weight outliers data (O’Leary, 1990). ridgeRegression() linear regression L2 regularization.Regression analysis methods suitable reducing ee$ImageCollection, ee$Image, ee$FeatureCollection, ee$List objects. following examples demonstrate application . Note linearRegression(), robustLinearRegression(), ridgeRegression() input output structures, linearFit() expects two-band input (X followed Y) ridgeRegression() additional parameter (lambda, optional) output (pValue).","code":""},{"path":"reducer.html","id":"eeimagecollection","chapter":"Reducer","heading":"ee$ImageCollection","text":"","code":""},{"path":"reducer.html","id":"linearfit","chapter":"Reducer","heading":"linearFit()","text":"data set two-band input image, first band independent variable second band dependent variable. following example shows estimation linear trend future precipitation (2006 NEX-DCP30 data) projected climate models. dependent variable projected precipitation independent variable time, added prior calling linearFit():Observe output contains two bands, ‘offset’ (intercept) ‘scale’ (‘scale’ context refers slope line confused scale parameter input many reducers, spatial scale). result, areas increasing trend blue, decreasing trend red trend green look something like Figure 9.Figure 9. output linearFit() applied projected precipitation. Areas projected increased precipitation shown blue decreased precipitation red.","code":"\n# This function adds a time band to the image.\ncreateTimeBand <- function(image) {\n  image$addBands(image$metadata(\"system:time_start\")$divide(1e18))\n}\n\n# createTimeBand<- function(image) .\n#   # Scale milliseconds by a large constant to avoid very small slope.\n#   # in the linear regression output.\n#   image$addBands(image$metadata('system:time_start')$divide(1e18).\n\n# Load the input image 'collection': projected climate data.\ncollection <- ee$ImageCollection(\"NASA/NEX-DCP30_ENSEMBLE_STATS\")$\n  filter(ee$Filter$eq(\"scenario\", \"rcp85\"))$\n  filterDate(ee$Date(\"2006-01-01\"), ee$Date(\"2050-01-01\"))$\n  map(createTimeBand)\n\n# Reduce the collection with the linear fit reducer.\n# Independent variable are followed by dependent variables.\nlinearFit <- collection$select(c(\"system:time_start\", \"pr_mean\"))$\n  reduce(ee$Reducer$linearFit())\n\n# Display the results.\nMap$setCenter(-100.11, 40.38, 5)\nMap$addLayer(\n  eeObject<- linearFit,\n  visParams<- list(min<- 0, max<- c(-0.9, 8e-5, 1), bands<- c(\"scale\", \"offset\", \"scale\")),\n  name<- \"fit\"\n)"},{"path":"reducer.html","id":"linearregression","chapter":"Reducer","heading":"linearRegression()","text":"example, suppose two dependent variables: precipitation maximum temperature, two independent variables: constant time. collection identical previous example, constant band must manually added prior reduction. first two bands input ‘X’ (independent) variables next two bands ‘Y’ (dependent) variables. example, first get regression coefficients, flatten array image extract bands interest:Inspect results discover linearRegression() output equivalent coefficients estimated linearFit() reducer, though linearRegression() output also coefficients dependent variable, tasmax_mean. Robust linear regression coefficients different OLS estimates. example compares coefficients different regression methods specific point.","code":"\n# This function adds a time band to the image.\ncreateTimeBand <- function(image) {\n  # Scale milliseconds by a large constant.\n  image$addBands(image$metadata(\"system:time_start\")$divide(1e18))\n}\n\n# This function adds a constant band to the image.\ncreateConstantBand <- function(image) {\n  ee$Image(1)$addBands(image)\n}\n\n# Load the input image collection: projected climate data.\ncollection <- ee$ImageCollection(\"NASA/NEX-DCP30_ENSEMBLE_STATS\")$\n  filterDate(ee$Date(\"2006-01-01\"), ee$Date(\"2099-01-01\"))$\n  filter(ee$Filter$eq(\"scenario\", \"rcp85\"))$\n  # Map the functions over the collection, to get constant and time bands.\n  map(createTimeBand)$\n  map(createConstantBand)$\n  # Select the predictors and the responses.\n  select(c(\"constant\", \"system:time_start\", \"pr_mean\", \"tasmax_mean\"))\n\n# Compute ordinary least squares regression coefficients.\nlinearRegression <- collection$reduce(\n  ee$Reducer$linearRegression(\n    numX<- 2,\n    numY<- 2\n  )\n)\n\n# Compute robust linear regression coefficients.\nrobustLinearRegression <- collection$reduce(\n  ee$Reducer$robustLinearRegression(\n    numX<- 2,\n    numY<- 2\n  )\n)\n\n# The results are array images that must be flattened for display.\n# These lists label the information along each axis of the arrays.\nbandNames <- list(\n  c(\"constant\", \"time\"), # 0-axis variation.\n  c(\"precip\", \"temp\")\n) # 1-axis variation.\n\n# Flatten the array images to get multi-band images according to the labels.\nlrImage <- linearRegression$select(\"coefficients\")$arrayFlatten(bandNames)\nrlrImage <- robustLinearRegression$select(\"coefficients\")$arrayFlatten(bandNames)\n\n# Display the OLS results.\nMap$setCenter(-100.11, 40.38, 5)\nMap$addLayer(\n  lrImage,\n  list(min<- 0, max<- c(-0.9, 8e-5, 1), bands<- c(\"time_precip\", \"constant_precip\", \"time_precip\")), \"OLS\"\n)\n\n# Compare the results at a specific point:\ncat(\"OLS estimates:\", unlist(lrImage$reduceRegion(\n  reducer<- ee$Reducer$first(),\n  geometry<- ee$Geometry$Point(c(-96.0, 41.0)),\n  scale<- 1000\n)$getInfo()))\n\ncat(\"Robust estimates:\", unlist(rlrImage$reduceRegion(\n  reducer<- ee$Reducer$first(),\n  geometry<- ee$Geometry$Point(c(-96.0, 41.0)),\n  scale<- 1000\n)$getInfo()))"},{"path":"reducer.html","id":"eeimage","chapter":"Reducer","heading":"ee$Image","text":"context ee$Image object, regression reducers can used reduceRegion reduceRegions perform linear regression pixels region(s). following examples demonstrate calculate regression coefficients Landsat bands arbitrary polygon.","code":""},{"path":"reducer.html","id":"linearfit-1","chapter":"Reducer","heading":"linearFit()","text":"guide section describing array data charts shows scatter plot correlation Landsat 8 SWIR1 SWIR2 bands. , linear regression coefficients relationship calculated. dictionary containing properties 'offset' (y-intercept) 'scale' (slope) returned.","code":"\n# Define a rectangle geometry around San Francisco.\nsanFrancisco <- ee$Geometry$Rectangle(c(-122.45, 37.74, -122.4, 37.8))\n\n# Import a Landsat 8 TOA image for this region.\nimg <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\n\n# Subset the SWIR1 and SWIR2 bands. In the regression reducer, independent\n# variables come first followed by the dependent variables. In this case,\n# B5 (SWIR1) is the independent variable and B6 (SWIR2) is the dependent\n# variable.\nimgRegress <- img$select(c(\"B5\", \"B6\"))\n\n# Calculate regression coefficients for the set of pixels intersecting the\n# above defined region using reduceRegion with ee.Reducer.linearFit().\nlinearFit <- imgRegress$reduceRegion(\n  reducer<- ee$Reducer$linearFit(),\n  geometry<- sanFrancisco,\n  scale<- 30\n)\n\n# Inspect the results.\ncat(\"OLS estimates:\", unlist(linearFit$getInfo()))\ncat(\"y-intercept:\", linearFit$get(\"offset\")$getInfo())\ncat(\"Slope:\", linearFit$get(\"scale\")$getInfo())"},{"path":"reducer.html","id":"linearregression-1","chapter":"Reducer","heading":"linearRegression()","text":"analysis previous linearFit section applied , except time ee$Reducer$linearRegression function used. Note regression image constructed three separate images: constant image images representing SWIR1 SWIR2 bands Landsat 8 image. Keep mind can combine set bands construct input image region reduction ee$Reducer$linearRegression, belong source image.dictionary containing properties 'coefficients' 'residuals' returned. 'coefficients' property array dimensions (numX, numY); column contains coefficients corresponding dependent variable. case, array two rows one column; row one, column one y-intercept row two, column one slope. 'residuals' property vector root mean square residuals dependent variable. Extract coefficients casting result array slicing desired elements converting array list selecting coefficients index position.","code":"\n# Define a rectangle geometry around San Francisco.\nsanFrancisco <- ee$Geometry$Rectangle(c(-122.45, 37.74, -122.4, 37.8))\n\n# Import a Landsat 8 TOA image for this region.\nimg <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044034_20140318\")\n\n# Create a new image that is the concatenation of three images: a constant,\n# the SWIR1 band, and the SWIR2 band.\nconstant <- ee$Image(1)\nx<- img$select(\"B5\")\ny<- img$select(\"B6\")\nimgRegress <- ee$Image$cat(constant, xVar, yVar)\n\n# Calculate regression coefficients for the set of pixels intersecting the\n# above defined region using reduceRegion. The numX parameter is set as 2\n# because the constant and the SWIR1 bands are independent variables and they\n# are the first two bands in the stack numY is set as 1 because there is only\n# one dependent variable (SWIR2) and it follows as band three in the stack.\nlinearRegression <- imgRegress$reduceRegion(\n  reducer<- ee$Reducer$linearRegression(\n    numX<- 2,\n    numY<- 1\n  ),\n  geometry<- sanFrancisco,\n  scale<- 30\n)\n\n# Convert the coefficients array to a list.\ncoefList <- ee$Array(linearRegression$get(\"coefficients\"))$toList()\n\n# Extract the y-intercept and slope.\nb0 <- ee$List(coefList$get(0))$get(0) # y-intercept\nb1 <- ee$List(coefList$get(1))$get(0) # slope\n\n# Extract the residuals.\nresiduals <- ee$Array(linearRegression$get(\"residuals\"))$toList()$get(0)\n\n# Inspect the results.\ncat(\"OLS estimates\", unlist(linearRegression$getInfo()))\ncat(\"y-intercept:\", b0$getInfo())\ncat(\"Slope:\", b1$getInfo())\ncat(\"Residuals:\", residuals$getInfo())"},{"path":"reducer.html","id":"eefeaturecollection","chapter":"Reducer","heading":"ee$FeatureCollection","text":"Suppose want know linear relationship Sentinel-2 Landsat 8 SWIR1 reflectance. example, random sample pixels formatted feature collection points used calculate relationship. scatter plot pixel pairs along least squares line best fit generated (Figure 10).Figure 10. Scatter plot least squares linear regression line sample pixels representing Sentinel-2 Landsat 8 SWIR1 TOA reflectance.","code":"\n# Import a Sentinel-2 TOA image.\ns2ImgSwir1 <- ee$Image(\"COPERNICUS/S2/20191022T185429_20191022T185427_T10SEH\")\n\n# Import a Landsat 8 TOA image from 12 days earlier than the S2 image.\nl8ImgSwir1 <- ee$Image(\"LANDSAT/LC08/C01/T1_TOA/LC08_044033_20191010\")\n\n# Get the intersection between the two images - the area of interest (aoi).\naoi <- s2ImgSwir1$geometry()$intersection(l8ImgSwir1$geometry())\n\n# Get a set of 1000 random points from within the aoi. A feature collection\n# is returned.\nsample <- ee$FeatureCollection$randomPoints(\n  region<- aoi,\n  points<- 1000\n)\n\n# Combine the SWIR1 bands from each image into a single image.\nswir1Bands <- s2ImgSwir1$select(\"B11\")$\n  addBands(l8ImgSwir1$select(\"B6\"))$\n  rename(c(\"s2_swir1\", \"l8_swir1\"))\n\n# Sample the SWIR1 bands using the sample point feature collection.\nimgSamp <- swir1Bands$sampleRegions(\n  collection<- sample,\n  scale<- 30\n)$\n  # Add a constant property to each feature to be used as an independent variable.\n  map(function(feature) {\n  feature$set(\"constant\", 1)\n})\n\n# Compute linear regression coefficients. numX is 2 because\n# there are two independent variables: 'constant' and 's2_swir1'. numY is 1\n# because there is a single dependent variable: 'l8_swir1'. Cast the resulting\n# object to an ee.Dictionary for easy access to the properties.\nlinearRegression <- ee$Dictionary(imgSamp$reduceColumns(\n  reducer<- ee$Reducer$linearRegression(\n    numX<- 2,\n    numY<- 1\n  ),\n  selectors<- c(\"constant\", \"s2_swir1\", \"l8_swir1\")\n))\n\n# Convert the coefficients array to a list.\ncoefList <- ee$Array(linearRegression$get(\"coefficients\"))$toList()\n\n# Extract the y-intercept and slope.\nyInt <- ee$List(coefList$get(0))$get(0) # y-intercept\nslope <- ee$List(coefList$get(1))$get(0) # slope\n\n# Gather the SWIR1 values from the point sample into a list of lists.\nprops <- ee$List(c(\"s2_swir1\", \"l8_swir1\"))\nregressionVarsList <- ee$List(imgSamp$reduceColumns(\n  reducer<- ee$Reducer$toList()$`repeat`(props$size()),\n  selectors<- props\n)$get(\"list\"))"},{"path":"reducer.html","id":"eelist","chapter":"Reducer","heading":"ee$List","text":"Columns 2-D ee$List objects can inputs regression reducers. following examples provide simple proofs; independent variable copy dependent variable producing y-intercept equal 0 slope equal 1.","code":""},{"path":"reducer.html","id":"linearfit-2","chapter":"Reducer","heading":"linearFit()","text":"Transpose list variables represented rows converting ee$Array, transposing , converting back ee$List.","code":"\n# Define a list of lists, where columns represent variables. The first column\n# is the independent variable and the second is the dependent variable.\nlistsVarColumns <- ee$List(list(\n  c(1, 1),\n  c(2, 2),\n  c(3, 3),\n  c(4, 4),\n  c(5, 5)\n))\n\n# Compute the least squares estimate of a linear function. Note that an\n# object is returned cast it as an ee.Dictionary to make accessing the\n# coefficients easier.\nlinearFit <- ee$Dictionary(listsVarColumns$reduce(ee$Reducer$linearFit()))\n\n# Inspect the result.\nprint(linearFit$getInfo())\ncat(\"y-intercept:\", linearFit$get(\"offset\")$getInfo())\ncat(\"Slope:\", linearFit$get(\"scale\")$getInfo())\n# If variables in the list are arranged as rows, you'll need to transpose it.\n# Define a list of lists where rows represent variables. The first row is the\n# independent variable and the second is the dependent variable.\nlistsVarRows <- ee$List(list(\n  c(1, 2, 3, 4, 5),\n  c(1, 2, 3, 4, 5)\n))\n\n# Cast the ee.List as an ee.Array, transpose it, and cast back to ee.List.\nlistsVarColumns <- ee$Array(listsVarRows)$transpose()$toList()\n\n# Compute the least squares estimate of a linear function. Note that an\n# object is returned; cast it as an ee.Dictionary to make accessing the\n# coefficients easier.\nlinearFit <- ee$Dictionary(listsVarColumns$reduce(ee$Reducer$linearFit()))\n\n# Inspect the result.\nprint(linearFit$getInfo())\ncat(\"y-intercept:\", linearFit$get(\"offset\")$getInfo())\ncat(\"Slope:\", linearFit$get(\"scale\")$getInfo())"},{"path":"reducer.html","id":"linearregression-2","chapter":"Reducer","heading":"linearRegression()","text":"Application ee$Reducer$linearRegression() similar linearFit() example, except constant independent variable included.","code":"\n# Define a list of lists where columns represent variables. The first column\n# represents a constant term, the second an independent variable, and the third\n# a dependent variable.\nlistsVarColumns <- ee$List(list(\n  c(1, 1, 1),\n  c(1, 2, 2),\n  c(1, 3, 3),\n  c(1, 4, 4),\n  c(1, 5, 5)\n))\n\n# Compute ordinary least squares regression coefficients. numX is 2 because\n# there is one constant term and an additional independent variable. numY is 1\n# because there is only a single dependent variable. Cast the resulting\n# object to an ee.Dictionary for easy access to the properties.\nlinearRegression <- ee$Dictionary(\n  listsVarColumns$reduce(ee$Reducer$linearRegression(\n    numX<- 2,\n    numY<- 1\n  )))\n\n# Convert the coefficients array to a list.\ncoefList <- ee$Array(linearRegression$get('coefficients'))$toList()\n\n# Extract the y-intercept and slope.\nb0 <- ee$List(coefList$get(0))$get(0) # y-intercept\nb1 <- ee$List(coefList$get(1))$get(0) # slope\n\n# Extract the residuals.\nresiduals <- ee$Array(linearRegression$get('residuals'))$toList()$get(0)\n\n# Inspect the results.\ncat('OLS estimates', unlist(linearRegression$getInfo()))\ncat('y-intercept:', b0$getInfo())\ncat('Slope:', b1$getInfo())\ncat('Residuals:', residuals$getInfo())"},{"path":"join.html","id":"join","chapter":"Join","heading":"Join","text":"section requires next libraries:","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()"},{"path":"join.html","id":"join-overview","chapter":"Join","heading":"Join Overview","text":"Joins used combine elements different collections (e.g. ImageCollection FeatureCollection) based condition specified ee$Filter. filter constructed arguments properties collection related . Specifically, leftField specifies property primary collection related rightField secondary collection. type filter (e.g. equals, greaterThanOrEquals, lessThan, etc.) indicates relationship fields. type join indicates one--many one--one relationships elements collections many matches retain. output join produced join$apply() vary according type join.","code":""},{"path":"join.html","id":"simple-joins","chapter":"Join","heading":"Simple Joins","text":"simple join returns elements primary collection match element secondary collection according match condition filter. perform simple join, use ee$Join$simple(). might useful finding common elements among different collections filtering one collection another. example, consider two image collections (might) matching elements, “matching” defined condition specified filter. example, let matching mean image IDs equal. Since matching images collections , use simple join discover set matching images:previous example, observe collections join temporally overlap month. Note join applied, output ImageCollection matching images primary collection.","code":"\n# Load a Landsat 8 image collection at a point of interest.\ncollection <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_TOA\")$\n  filterBounds(ee$Geometry$Point(-122.09, 37.42))\n\n# Define start and end dates with which to filter the collections.\napril <- \"2014-04-01\"\nmay <- \"2014-05-01\"\njune <- \"2014-06-01\"\njuly <- \"2014-07-01\"\n\n# The primary collection is Landsat images from April to June.\nprimary <- collection$filterDate(april, june)\n\n# The secondary collection is Landsat images from May to July.\nsecondary <- collection$filterDate(may, july)\n\n# Use an equals filter to define how the collections match.\nfilter <- ee$Filter$equals(\n  leftField<- \"system:index\",\n  rightField<- \"system:index\"\n)\n\n# Create the join.\nsimpleJoin <- ee$Join$simple()\n\n# Apply the join.\nsimpleJoined <- simpleJoin$apply(primary, secondary, filter)\n\n# Display the result.\ncat(\"Simple join: \", unlist(ee_get_date_ic(simpleJoined)))\nImage LANDSAT/LC8_L1T_TOA/LC80440342014125LGN00 (12 bands)\nImage LANDSAT/LC8_L1T_TOA/LC80440342014141LGN00 (12 bands)\n"},{"path":"join.html","id":"inverted-joins","chapter":"Join","heading":"Inverted Joins","text":"Suppose purpose join retain images primary collection secondary collection. can perform type inverted join using ee$Join$inverted(). Using filter, primary secondary collections defined simple join example, specify inverted join :inverted join contains images April 3 April 19, indicating images present primary collection secondary collection.","code":"\n# Define the join.\ninvertedJoin <- ee$Join$inverted()\n\n# Apply the join.\ninvertedJoined <- invertedJoin$apply(primary, secondary, filter)\n\n# Display the result.\nee_get_date_ic(invertedJoined)\nImage LANDSAT/LC8_L1T_TOA/LC80440342014093LGN00 (12 bands)\nImage LANDSAT/LC8_L1T_TOA/LC80440342014109LGN00 (12 bands)\n"},{"path":"join.html","id":"inner-joins","chapter":"Join","heading":"Inner Joins","text":"enumerate matches elements two collections, use ee$Join$inner(). output inner join FeatureCollection (even joining one ImageCollection another ImageCollection). feature output represents match, matching elements stored two properties feature. example, feature$get('primary') element primary collection matches element secondary collection stored feature$get('secondary'). (Different names properties can specified arguments inner(), ‘primary’ ‘secondary’ defaults). One--many relationships represented multiple features output. element either collection doesn’t match, present output.Join examples using ImageCollection inputs apply without modification FeatureCollection inputs. also possible join FeatureCollection ImageCollection vice versa. Consider following toy example inner join:previous example, notice relationship tables defined filter, indicates fields ‘foo’ ‘bar’ join fields. inner join specified applied collections. Inspect output observe possible match represented one Feature.motivated example, consider joining MODIS ImageCollection objects. MODIS quality data sometimes stored separate collection image data, inner join convenient joining two collections order apply quality data. case, image acquisition times identical, equals filter handles job specifying relationship two collections:make use joined images output FeatureCollection, map() combining function output. example, matching images can stacked together quality bands added image data:Although function mapped FeatureCollection, result ImageCollection. image resultant ImageCollection bands images primary collection (example just ‘EVI’) bands matching image secondary collection (quality bands).","code":"\n# Create the primary collection.\nprimaryFeatures <- ee$FeatureCollection(list(\n  ee$Feature(NULL, list(foo<- 0, label<- \"a\")),\n  ee$Feature(NULL, list(foo<- 1, label<- \"b\")),\n  ee$Feature(NULL, list(foo<- 1, label<- \"c\")),\n  ee$Feature(NULL, list(foo<- 2, label<- \"d\"))\n))\n\n# Create the secondary collection.\nsecondaryFeatures <- ee$FeatureCollection(list(\n  ee$Feature(NULL, list(bar<- 1, label<- \"e\")),\n  ee$Feature(NULL, list(bar<- 1, label<- \"f\")),\n  ee$Feature(NULL, list(bar<- 2, label<- \"g\")),\n  ee$Feature(NULL, list(bar<- 3, label<- \"h\"))\n))\n\n# Use an equals filter to specify how the collections match.\ntoyFilter <- ee$Filter$equals(\n  leftField<- \"foo\",\n  rightField<- \"bar\"\n)\n\n# Define the join.\ninnerJoin <- ee$Join$inner(\"primary\", \"secondary\")\n\n# Apply the join.\ntoyJoin <- innerJoin$apply(primaryFeatures, secondaryFeatures, toyFilter)\n\n# Print the result.\ncat(\"Inner join toy example:\", unlist(toyJoin$getInfo()))\n# Make a date filter to get images in this date range.\ndateFilter <- ee$Filter$date(\"2014-01-01\", \"2014-02-01\")\n\n# Load a MODIS collection with EVI data.\nmcd43a4 <- ee$ImageCollection(\"MODIS/MCD43A4_006_EVI\")$\n  filter(dateFilter)\n\n# Load a MODIS collection with quality data.\nmcd43a2 <- ee$ImageCollection(\"MODIS/006/MCD43A2\")$\n  filter(dateFilter)\n\n# Define an inner join.\ninnerJoin <- ee$Join$inner()\n\n# Specify an equals filter for image timestamps.\nfilterTimeEq <- ee$Filter$equals(\n  leftField<- \"system:time_start\",\n  rightField<- \"system:time_start\"\n)\n\n# Apply the join.\ninnerJoinedMODIS <- innerJoin$apply(mcd43a4, mcd43a2, filterTimeEq)\n\n# Display the join result: a FeatureCollection.\ncat(\"Inner join output:\", unlist(innerJoinedMODIS$getInfo()))\n# Map a function to merge the results in the output FeatureCollection.\njoinedMODIS <- innerJoinedMODIS$map(function(feature) {\n  ee$Image$cat(feature$get(\"primary\"), feature$get(\"secondary\"))\n})\n\n# Print the result of merging.\nee_get_date_ic(joinedMODIS)"},{"path":"join.html","id":"save-all-joins","chapter":"Join","heading":"Save-All Joins","text":"Saving joins one way representing one--many relationships Earth Engine. Unlike inner join, saving join stores matches secondary collection named property features primary collection. save matches, use ee$Join$saveAll(). one--many relationship, saveAll() join stores matching features ee$List. Unmatched elements primary collection dropped. example, suppose need get MODIS imagery acquired within two days Landsat image collection. example uses saveAll() join purpose:example, note secondary MODIS collection pre-filtered chronologically similar primary Landsat collection efficiency. compare Landsat acquisition time MODIS composite time, daily range, filter compares endpoints image timestamps. join defined name property used store list matches Landsat image (‘terra’) optional parameter sort list matches system:time_start propertyInspection result indicates images within primary collection added terra property stores list matching MODIS images.","code":"\n# Load a primary collection: Landsat imagery.\nprimary <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_TOA\")$\n  filterDate(\"2014-04-01\", \"2014-06-01\")$\n  filterBounds(ee$Geometry$Point(-122.092, 37.42))\n\n# Load a secondary collection: MODIS imagery.\nmodSecondary <- ee$ImageCollection(\"MODIS/006/MOD09GA\")$\n  filterDate(\"2014-03-01\", \"2014-07-01\")\n\n# Define an allowable time difference: two days in milliseconds.\ntwoDaysMillis <- 2 * 24 * 60 * 60 * 1000\n\n# Create a time filter to define a match as overlapping timestamps.\ntimeFilter <- ee$Filter$Or(\n  ee$Filter$maxDifference(\n    difference<- twoDaysMillis,\n    leftField<- \"system:time_start\",\n    rightField<- \"system:time_end\"\n  ),\n  ee$Filter$maxDifference(\n    difference<- twoDaysMillis,\n    leftField<- \"system:time_end\",\n    rightField<- \"system:time_start\"\n  )\n)\n\n# Define the join.\nsaveAllJoin <- ee$Join$saveAll(\n  matchesKey<- \"terra\",\n  ordering<- \"system:time_start\",\n  ascending<- TRUE\n)\n\n# Apply the join.\nlandsatModis <- saveAllJoin$apply(primary, modSecondary, timeFilter)\n\n# Display the result.\nee_get_date_ic(landsatModis)"},{"path":"join.html","id":"save-best-joins","chapter":"Join","heading":"Save-Best Joins","text":"save best match element collection, use ee$Join$saveBest(). saveBest() join functions equivalent way saveAll() join, except element primary collection, saves element secondary collection best match. Unmatched elements primary collection dropped. Suppose intention find meteorological image closest time Landsat image primary collection. perform join, ee$Filter must redefined single join condition (combined filters work saveBest() since ambiguous combine ranks multiple sub-Filters):Note saveBest() join defines name property store best match (‘bestImage’) name property store goodness match metric (‘timeDiff’). Inspection results indicates matching DAYMET image added property bestImage Landsat scene primary collection. DAYMET images property timeDiff indicating time difference milliseconds DAYMET image Landsat image, minimum among DAYMET images passing condition filter.","code":"\n# Load a primary collection: Landsat imagery.\nprimary <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_TOA\")$\n  filterDate(\"2014-04-01\", \"2014-06-01\")$\n  filterBounds(ee$Geometry$Point(-122.092, 37.42))\n\n# Load a secondary collection: GRIDMET meteorological data\ngridmet <- ee$ImageCollection(\"IDAHO_EPSCOR/GRIDMET\")\n\n# Define a max difference filter to compare timestamps.\nmaxDiffFilter <- ee$Filter$maxDifference(\n  difference<- 2 * 24 * 60 * 60 * 1000,\n  leftField<- \"system:time_start\",\n  rightField<- \"system:time_start\"\n)\n\n# Define the join.\nsaveBestJoin <- ee$Join$saveBest(\n  matchKey<- \"bestImage\",\n  measureKey<- \"timeDiff\"\n)\n\n# Apply the join.\nlandsatMet <- saveBestJoin$apply(primary, gridmet, maxDiffFilter)\n\n# Print the result.\nee_get_date_ic(landsatMet)"},{"path":"join.html","id":"save-first-joins","chapter":"Join","heading":"Save-First Joins","text":"save first match element collection, use ee$Join$saveFirst(). saveFirst() join functions equivalent way saveAll() join, except element primary collection, simply saves first element secondary collection matching condition specified ee.Filter. Unmatched elements primary collection dropped. Unless sorting property order supplied (saveAll example), first element saved might elements list found saveAll() filter.","code":""},{"path":"join.html","id":"spatial-joins","chapter":"Join","heading":"Spatial Joins","text":"Collections can joined spatial location well property values. join based spatial location, use withinDistance() filter .geo join fields specified. .geo field indicates item’s geometry used compute distance metric. example, consider task finding power plants within 100 kilometers Yosemite National Park, USA. purpose, use filter geometry fields, maximum distance set 100 kilometers using distance parameter:Note previous example joins FeatureCollection another FeatureCollection. saveAll() join sets property (points) feature primary collection stores list points within 100 km feature. distance point feature stored distance property joined point.Spatial joins can also used identify features one collection intersect another. example, consider two feature collections: primary collection containing polygons representing boundaries US states, secondary collection containing point locations representing power plants. Suppose need determine number intersecting state. can accomplished spatial join follows:previous example, note intersects() filter doesn’t store distance withinDistance() filter . output look something like Figure 1.Figure 1. Bar chart showing number power plants intersecting US state.","code":"\n# Load a primary collection: protected areas (Yosemite National Park).\nprimary <- ee$FeatureCollection(\"WCMC/WDPA/current/polygons\")$\n  filter(ee$Filter$eq(\"NAME\", \"Yosemite National Park\"))\n\n# Load a secondary collection: power plants.\npowerPlants <- ee$FeatureCollection(\"WRI/GPPD/power_plants\")\n\n# Define a spatial filter, with distance 100 km.\ndistFilter <- ee$Filter$withinDistance(\n  distance<- 100000,\n  leftField<- \".geo\",\n  rightField<- \".geo\",\n  maxError<- 10\n)\n\n# Define a saveAll join.\ndistSaveAll <- ee$Join$saveAll(\n  matchesKey<- \"points\",\n  measureKey<- \"distance\"\n)\n\n# Apply the join.\nspatialJoined <- distSaveAll$apply(primary, powerPlants, distFilter)\n\n# Print the result.\nprint(spatialJoined$getInfo())\n# Load the primary collection: US state boundaries.\nstates <- ee$FeatureCollection(\"TIGER/2018/States\")\n\n# Load the secondary collection: power plants.\npowerPlants <- ee$FeatureCollection(\"WRI/GPPD/power_plants\")\n\n# Define a spatial filter as geometries that intersect.\nspatialFilter <- ee$Filter$intersects(\n  leftField<- \".geo\",\n  rightField<- \".geo\",\n  maxError<- 10\n)\n\n# Define a save all join.\nsaveAllJoin <- ee$Join$saveAll(\n  matchesKey<- \"power_plants\"\n)\n\n# Apply the join.\nintersectJoined <- saveAllJoin$apply(states, powerPlants, spatialFilter)\n\n# Add power plant count per state as a property.\nintersectJoined <- intersectJoined$map(function(state) {\n  # Get \"power_plant\" intersection list, count how many intersected this state.\n  nPowerPlants <- ee$List(state$get(\"power_plants\"))$size()\n  # Return the state feature with a new property: power plant count.\n  state$set(\"n_power_plants\", nPowerPlants)\n})\n\n# Make a bar chart for the number of power plants per state.\n\n\n# Print the chart to the console."},{"path":"array.html","id":"array","chapter":"Array","heading":"Array","text":"section requires next libraries:","code":"\nlibrary(rgee)\nlibrary(rgeeExtra)\n\nee_Initialize()"},{"path":"array.html","id":"array-overview","chapter":"Array","heading":"Array Overview","text":"Earth Engine represents 1-D vectors, 2-D matrices, 3-D cubes, higher dimensional hypercubes ee$Array type. Arrays flexible data structure, exchange power offer, scale well data structures Earth Engine. problem can solved without using arrays, result computed faster efficiently. problem requires higher dimension model, flexible linear algebra, anything else arrays uniquely suited , can use Array class.","code":""},{"path":"array.html","id":"array-dimension-shape-and-size","chapter":"Array","heading":"Array dimension, shape and size","text":"dimension array refers number axes along underlying data varies. example, 0-D arrays scalar numbers, 1-D arrays vectors, 2-D arrays matrices, 3-D arrays cubes, >3-D arrays hyper-cubes. N-dimensional array, N axes 0 N-1. shape array determined lengths axes. length axis number positions along . array size, number total elements array, equals product axis lengths. value every position every axis must valid number, since sparse ragged arrays currently supported. array’s element type indicates kind number element ; elements array type.","code":""},{"path":"array.html","id":"arrays-and-array-images","chapter":"Array","heading":"Arrays and Array Images","text":"Arrays Earth Engine constructed lists numbers lists lists. degree nesting determines number dimensions. get started simple, motivated example, consider following example Array created Landsat 8 tasseled cap (TC) coefficients (Baig et al., 2014):Confirm 6x6, 2-D Array using length(), return lengths axis:following table illustrates arrangement matrix entries along 0-axis 1-axis:indices left table indicate positions along 0-axis. n-th element within list 0-axis n-th position along 1-axis. example, entry coordinate [3,1] array 0.0849. Suppose ‘greenness’ TC component interest. can get greenness sub-matrix using slice():2-D greenness matrix look something like:Observe start end parameters slice() correspond 0-axis indices displayed table (start inclusive end exclusive).","code":"\n# Create an Array of Tasseled Cap coefficients.\ncoefficients <- ee$Array(list(\n  c(0.3029, 0.2786, 0.4733, 0.5599, 0.508, 0.1872),\n  c(-0.2941, -0.243, -0.5424, 0.7276, 0.0713, -0.1608),\n  c(0.1511, 0.1973, 0.3283, 0.3407, -0.7117, -0.4559),\n  c(-0.8239, 0.0849, 0.4396, -0.058, 0.2013, -0.2773),\n  c(-0.3294, 0.0557, 0.1056, 0.1855, -0.4349, 0.8085),\n  c(0.1079, -0.9023, 0.4119, 0.0575, -0.0259, 0.0252)\n))\n# Print the dimensions.\nprint(coefficients$length()$getInfo()) #    [1]: 6 6\n# Get the 1x6 greenness slice, display it.\ngreenness <- coefficients$slice(axis<- 0, start<- 1, end<- 2, step<- 1)\nprint(greenness$getInfo())\nc(-0.2941,-0.243,-0.5424,0.7276,0.0713,-0.1608)"},{"path":"array.html","id":"array-images","chapter":"Array","heading":"Array Images","text":"get greenness image, matrix multiply bands Landsat 8 image greenness matrix. , first convert multi-band Landsat image “Array Image”, pixel Array band values. example:example, note toArray() converts image array image pixel 1-D vector, entries correspond 6 values corresponding positions bands image. array image 1-D vectors created manner concept 2-D shape. perform 2-D operations matrix multiplication, convert 2-D array per-pixel image toArray(1). pixel 2-D array image, 6x1 matrix band values. see , consider following toy example:Observe array1D vector varies along 0-axis. array2D matrix well, ’s got extra dimension. Calling toArray(1) array image like calling cat(bandVector, 1) every pixel. Using 2-D array image, left multiply image pixel contains 2-D matrix greenness coefficients:result new array image every pixel 1x1 matrix results matrix multiplying 1x6 greenness matrix (left) 6x1 band matrix (right). display purposes, convert regular, one-band image arrayGet():complete example, uses entire coefficients array compute multiple tasseled cap components display result:Note getting bands array image, first get rid extra dimensions project(), convert back regular image arrayFlatten(). output look something like:Figure 1. Tasseled cap components “brightness” (red), “greenness” (green), “wetness” (blue).","code":"\n# Load a Landsat 8 image, select the bands of interest.\nimage <- ee$Image('LANDSAT/LC08/C02/T1_TOA/LC08_044034_20140318')$\n  select(c('B2', 'B3', 'B4', 'B5', 'B6', 'B7'))\n\n# Make an Array Image, with a 1-D Array per pixel.\narrayImage1D <- image$toArray()\n\n# Make an Array Image with a 2-D Array per pixel, 6x1.\narrayImage2D <- arrayImage1D$toArray(1)\narray1D <- ee$Array(c(1, 2, 3)) # 1,2,3\narray2D <- ee$Array$cat(list(array1D), 1) # [[1],[2],[3]]\n# Do a matrix multiplication: 1x6 times 6x1.\n# Cast the greenness Array to an Image prior to multiplication.\ngreennessArrayImage <- ee$Image(greenness)$matrixMultiply(arrayImage2D)\n# Get the result from the 1x1 array in each pixel of the 2-D array image.\ngreennessImage <- greennessArrayImage$arrayGet(c(0, 0))\n\n# Display the input imagery with the greenness result.\nMap$setCenter(-122.3, 37.562, 10)\nMap$addLayer(\n  image,\n  list(bands = c(\"B5\", \"B4\", \"B3\"), min = 0, max = 0.5),\n  \"image\"\n) |\n  Map$addLayer(\n    greennessImage,\n    list(min = -0.1, max = 0.13),\n    \"greenness\"\n  )\n# Define an Array of Tasseled Cap coefficients.\ncoefficients <- ee$Array(list(\n  c(0.3029, 0.2786, 0.4733, 0.5599, 0.508, 0.1872),\n  c(-0.2941, -0.243, -0.5424, 0.7276, 0.0713, -0.1608),\n  c(0.1511, 0.1973, 0.3283, 0.3407, -0.7117, -0.4559),\n  c(-0.8239, 0.0849, 0.4396, -0.058, 0.2013, -0.2773),\n  c(-0.3294, 0.0557, 0.1056, 0.1855, -0.4349, 0.8085),\n  c(0.1079, -0.9023, 0.4119, 0.0575, -0.0259, 0.0252)\n))\n\n# Load a Landsat 8 image, select the bands of interest.\nimage <- ee$Image(\"LANDSAT/LC08/C02/T1_TOA/LC08_044034_20140318\")$\n  select(c(\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"))\n\n# Make an Array Image, with a 1-D Array per pixel.\narrayImage1D <- image$toArray()\n\n# Make an Array Image with a 2-D Array per pixel, 6x1.\narrayImage2D <- arrayImage1D$toArray(1)\n\n# Do a matrix multiplication: 6x6 times 6x1.\ncomponentsImage <- ee$Image(coefficients)$\n  matrixMultiply(arrayImage2D)$\n  # Get rid of the extra dimensions.\n  arrayProject(list(0))$\n  arrayFlatten(\n  list(\n    c(\n      \"brightness\",\n      \"greenness\",\n      \"wetness\",\n      \"fourth\",\n      \"fifth\",\n      \"sixth\"\n    )\n  )\n)\n\n# Display the first three bands of the result and the input imagery.\nvizParams <- list(\n  bands = list(\"brightness\", \"greenness\", \"wetness\"),\n  min = -0.1,\n  max = c(0.5, 0.1, 0.1)\n)\nMap$setCenter(-122.3, 37.562, 10)\nMap$addLayer(\n  image,\n  list(bands = c(\"B5\", \"B4\", \"B3\"), min = 0, max = 0.5),\n  \"image\"\n) |\n  Map$addLayer(\n    componentsImage,\n    vizParams,\n    \"components\"\n  )"},{"path":"array.html","id":"array-transformations","chapter":"Array","heading":"Array Transformations","text":"Earth Engine supports array transformations transpose, inverse pseudo-inverse. example, consider ordinary least squares (OLS) regression time series images. following example, image bands predictors response converted array image, “solved” obtain least squares coefficients estimates three ways. First, assemble image data convert arrays:Note arraySlice() returns images time series range indices specified along bandAxis (1-axis). point, matrix algebra can used solve OLS coefficients:Although method works, inefficient makes difficult read code. better way use pseudoInverse() method (matrixPseudoInverse() array image):readability computational efficiency perspective, best way get OLS coefficients solve() (matrixSolve() array image). solve() function determines best solve system characteristics inputs, using pseudo-inverse overdetermined systems, inverse square matrices special techniques nearly singular matrices:get multi-band image, project array image lower dimensional space, flatten :Examine outputs three methods observe resultant matrix coefficients regardless solver. solve() flexible efficient makes good choice general purpose linear modeling.","code":"\n# This function masks the input with a threshold on the simple cloud score.\ncloudMask <- function(img) {\n  cloudscore <- ee$Algorithms$Landsat$simpleCloudScore(img)$select(\"cloud\")\n  img$updateMask(cloudscore$lt(50))\n}\n\n# This function computes the predictors and the response from the input.\nmakeVariables <- function(img) {\n  # Compute time of the image in fractional years relative to the Epoch.\n  year <- ee$Image(img$date()$difference(ee$Date(\"1970-01-01\"), \"year\"))\n  # Compute the season in radians, one cycle per year.\n  season <- year$multiply(2 * base::pi)\n  # Return an image of the predictors followed by the response.\n  img$select()$\n    addBands(ee$Image(1))$\n    addBands(year$rename(\"t\"))$\n    addBands(season$sin()$rename(\"sin\"))$\n    addBands(season$cos()$rename(\"cos\"))$\n    addBands(image$normalizedDifference()$rename(\"NDVI\"))$\n    toFloat()\n}\n\n\n# Load a Landsat 5 image collection.\ncollection <- ee$ImageCollection(\"LANDSAT/LT05/C01/T1_TOA\")$\n  filterDate(\"2008-04-01\", \"2010-04-01\")$\n  filterBounds(ee$Geometry$Point(-122.2627, 37.8735))$\n  map(cloudMask)$\n  select(c(\"B4\", \"B3\"))$\n  sort(\"system:time_start\", TRUE)\n\n# Define the axes of variation in the collection array.\nimageAxis <- 0\nbandAxis <- 1\n\n# Convert the collection to an array.\narray <- collection$map(makeVariables)$toArray()\n\n# Check the length of the image axis (number of images).\narrayLength <- array$arrayLength(imageAxis)\n\n# Update the mask to ensure that the number of images is greater than or\n# equal to the number of predictors (the linear model is solveable).\narray <- array$updateMask(arrayLength$gt(4))\n\n# Get slices of the array according to positions along the band axis.\npredictors <- array$arraySlice(bandAxis, 0, 4)\nresponse <- array$arraySlice(bandAxis, 4)\n# Compute coefficients the hard way.\ncoefficients1 <- predictors$arrayTranspose()$matrixMultiply(predictors)$\n  matrixInverse()$matrixMultiply(predictors$arrayTranspose())$\n  matrixMultiply(response)\n# Compute coefficients the easy way.\ncoefficients2 <- predictors$matrixPseudoInverse()$\n  matrixMultiply(response)\n# Compute coefficients the easiest way.\ncoefficients3 <- predictors$matrixSolve(response)\n# Turn the results into a multi-band image.\ncoefficientsImage <- coefficients3$\n  # Get rid of the extra dimensions.\n  arrayProject(list(0))$\n  arrayFlatten(list(c(\"constant\", \"trend\", \"sin\", \"cos\")))\n\nprint(coefficientsImage$getInfo())\nMap$setCenter(-122.2627, 37.8735, 10)\nMap$addLayer(coefficientsImage, name = \"coefficientsImage\")"},{"path":"array.html","id":"eigen-analysis","chapter":"Array","heading":"Eigen Analysis","text":"principal components (PC) transform (also known Karhunen-Loeve transform) spectral rotation takes spectrally correlated image data outputs uncorrelated data. PC transform accomplishes diagonalizing input band correlation matrix Eigen-analysis. Earth Engine, use covariance reducer array image eigen() command resultant covariance array. Consider following function purpose (part complete example):input function mean zero image, scale region perform analysis. Note input imagery first needs converted 1-D array image reduced using ee$Reducer$centeredCovariance(). array returned reduction symmetric variance-covariance matrix input. Use eigen() command get eigenvalues eigenvectors covariance matrix. matrix returned eigen() contains eigenvalues 0-th position 1-axis. shown function, use slice() separate eigenvalues eigenvectors. element along 0-axis eigenVectors matrix eigenvector. tasseled cap (TC) example, perform transformation matrix multiplying arrayImage eigenvectors. example, eigenvector multiplication results PC.","code":"\ngetPrincipalComponents <- function(centered, scale, region) {\n  # Collapse the bands of the image into a 1D array per pixel.\n  arrays <- centered$toArray()\n\n  # Compute the covariance of the bands within the region.\n  covar <- arrays$reduceRegion(\n    reducer = ee.Reducer.centeredCovariance(),\n    geometry = region,\n    scale = scale,\n    maxPixels = 1e9\n  )\n\n  # Get the 'array' covariance result and cast to an array.\n  # This represents the band-to-band covariance within the region.\n  covarArray <- ee$Array(covar$get(\"array\"))\n\n  # Perform an eigen analysis and slice apart the values and vectors.\n  eigens <- covarArray$eigen()\n\n  # This is a P-length vector of Eigenvalues.\n  eigenValues <- eigens$slice(1, 0, 1)\n  # This is a PxP matrix with eigenvectors in rows.\n  eigenVectors <- eigens$slice(1, 1)\n\n  # Convert the array image to 2D arrays for matrix computations.\n  arrayImage <- arrays$toArray(1)\n\n  # Left multiply the image array by the matrix of eigenvectors.\n  principalComponents <- ee$Image(eigenVectors)$matrixMultiply(arrayImage)\n\n  # Turn the square roots of the Eigenvalues into a P-band image.\n  sdImage <- ee$Image(eigenValues$sqrt())$\n    arrayProject(list(0))$\n    arrayFlatten(list(getNewBandNames(\"sd\")))\n\n  # Turn the PCs into a P-band image, normalized by SD.\n  principalComponents$\n    # Throw out an an unneeded dimension.\n    arrayProject(list(0))$\n    # Make the one band array image a multi-band image.\n    arrayFlatten(list(getNewBandNames(\"pc\")))$\n    # Normalize the PCs by their SDs.\n    divide(sdImage)\n}"},{"path":"array.html","id":"array-sorting-and-reducing","chapter":"Array","heading":"Array Sorting and Reducing","text":"Array sorting useful obtaining custom quality mosaics involve reducing subset image bands according values different band. following example sorts NDVI, gets mean subset observations collection highest NDVI values:linear modeling example, separate bands interest sort index (NDVI) using arraySlice() along band axis. sort bands interest sort index using arraySort(). pixels sorted descending NDVI, use arraySlice() along imageAxis get 20% highest NDVI pixels. Lastly, apply arrayReduce() along imageAxis mean reducer get mean highest NDVI pixels. final step converts array image back multi-band image display.","code":"\n# Define an arbitrary region of interest as a point.\nroi <- ee$Geometry$Point(-122.26032, 37.87187)\n\n# Use these bands.\nbandNames <- ee$List(c(\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\", \"B10\", \"B11\"))\n\n# Load a Landsat 8 collection.\ncollection <- ee$ImageCollection(\"LANDSAT/LC08/C01/T1_TOA\")$\n  select(bandNames)$\n  filterBounds(roi)$\n  filterDate(\"2014-06-01\", \"2014-12-31\")$\n  map(function(img) ee$Algorithms$Landsat$simpleCloudScore(img))\n\n# Convert the collection to an array.\narray <- collection$toArray()\n\n# Label of the axes.\nimageAxis <- 0\nbandAxis <- 1\n\n# Get the cloud slice and the bands of interest.\nbands <- array$arraySlice(bandAxis, 0, bandNames$length())\nclouds <- array$arraySlice(bandAxis, bandNames$length())\n\n# Sort by cloudiness.\nsorted <- bands$arraySort(clouds)\n\n# Get the least cloudy images, 20% of the total.\nnumImages <- sorted$arrayLength(imageAxis)$multiply(0.2)$int()\nleastCloudy <- sorted$arraySlice(imageAxis, 0, numImages)\n\n# Get the mean of the least cloudy images by reducing along the image axis.\nmean <- leastCloudy$arrayReduce(\n  reducer = ee$Reducer$mean(),\n  axes = list(imageAxis)\n)\n\n# Turn the reduced array image into a multi-band image for display.\nvizParams <- list(\"bands\" = c(\"B5\", \"B4\", \"B2\"), min = 0, max = 0.5)\nmeanImage <- mean$arrayProject(list(bandAxis))$arrayFlatten(list(bandNames))\nMap$centerObject(ee$FeatureCollection(roi), zoom = 12)\nMap$addLayer(meanImage, vizParams, \"Mean Image\")"}]
